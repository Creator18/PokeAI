{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c659fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: State Management & Utilities\n",
    "# ============================================================================\n",
    "# CHANGES:\n",
    "# 1. read_game_state now handles BOTH key formats:\n",
    "#    - Long keys: \"state\", \"palette\", \"tiles\" (old format)\n",
    "#    - Short keys: \"s\", \"p\", \"t\" (Lua teaching/AI format)\n",
    "# 2. Added EXPLORATION_MEMORY_FILE and MODEL_CHECKPOINT_FILE paths\n",
    "# 3. Added TAUGHT_BATTLE_TRANSITIONS_FILE path for battle Markov\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "BASE_PATH = Path(\"C:/Users/HP/Documents/cogai/\")\n",
    "ACTION_FILE = BASE_PATH / \"action.json\"\n",
    "STATE_FILE = BASE_PATH / \"game_state.json\"\n",
    "TAUGHT_TRANSITIONS_FILE = BASE_PATH / \"taught_transitions.json\"\n",
    "TAUGHT_BATTLE_TRANSITIONS_FILE = BASE_PATH / \"taught_battle_transitions.json\"\n",
    "EXPLORATION_MEMORY_FILE = BASE_PATH / \"exploration_memory.json\"\n",
    "MODEL_CHECKPOINT_FILE = BASE_PATH / \"model_checkpoint.json\"\n",
    "TAUGHT_EXPLORATION_FILE = BASE_PATH / \"taught_exploration_memory.json\"\n",
    "TAUGHT_NAV_TARGETS_FILE = BASE_PATH / \"taught_nav_targets.json\"\n",
    "\n",
    "# === MARKOV SIMILARITY WEIGHTS ===\n",
    "MARKOV_IMMEDIATE_WEIGHT = 0.5\n",
    "MARKOV_SEQUENTIAL_WEIGHT = 0.3\n",
    "MARKOV_PARTIAL_WEIGHT = 0.2\n",
    "MARKOV_FAMILIARITY_THRESHOLD = 0.6\n",
    "\n",
    "MARKOV_SEQ_FULL_WEIGHT = 1.0\n",
    "MARKOV_SEQ_MEDIUM_WEIGHT = 0.6\n",
    "MARKOV_SEQ_SHORT_WEIGHT = 0.3\n",
    "\n",
    "MARKOV_POS_EXACT_BONUS = 0.35\n",
    "MARKOV_POS_NEAR_BONUS = 0.25\n",
    "MARKOV_POS_FAR_BONUS = 0.1\n",
    "MARKOV_POS_MAX_DIST = 5\n",
    "\n",
    "# === BATTLE MARKOV WEIGHTS ===\n",
    "BATTLE_MARKOV_ACTION_SEQ_WEIGHT = 0.70\n",
    "BATTLE_MARKOV_PALETTE_WEIGHT = 0.20\n",
    "BATTLE_MARKOV_MENU_STATE_WEIGHT = 0.10\n",
    "BATTLE_MARKOV_THRESHOLD_LOW = 0.35\n",
    "BATTLE_MARKOV_THRESHOLD_HIGH = 0.45\n",
    "\n",
    "EXPECTED_STATE_DIM = 6\n",
    "PALETTE_DIM = 768\n",
    "TILE_DIM = 600\n",
    "\n",
    "def normalize_game_state(raw_state):\n",
    "    if len(raw_state) < 6:\n",
    "        return raw_state\n",
    "    normalized = raw_state.copy()\n",
    "    normalized[0] = raw_state[0] / 255.0\n",
    "    normalized[1] = raw_state[1] / 255.0\n",
    "    normalized[2] = np.clip(raw_state[2], 0, 255)\n",
    "    normalized[3] = 1.0 if raw_state[3] > 0 else 0.0\n",
    "    normalized[4] = 1.0 if raw_state[4] > 0 else 0.0\n",
    "    normalized[5] = int(raw_state[5]) % 4\n",
    "    return normalized\n",
    "\n",
    "def compute_derived_features(current, prev):\n",
    "    if prev is None:\n",
    "        return np.zeros(8)\n",
    "    vel_x = current[0] - prev[0]\n",
    "    vel_y = current[1] - prev[1]\n",
    "    map_changed = 1.0 if abs(current[2] - prev[2]) > 0.5 else 0.0\n",
    "    battle_started = 1.0 if current[3] > prev[3] else 0.0\n",
    "    battle_ended = 1.0 if current[3] < prev[3] else 0.0\n",
    "    menu_opened = 1.0 if current[4] > prev[4] else 0.0\n",
    "    menu_closed = 1.0 if current[4] < prev[4] else 0.0\n",
    "    direction_changed = 1.0 if current[5] != prev[5] else 0.0\n",
    "    return np.array([vel_x, vel_y, map_changed, battle_started, battle_ended,\n",
    "                     menu_opened, menu_closed, direction_changed])\n",
    "\n",
    "def build_learning_state(derived, palette, tiles, in_battle):\n",
    "    if in_battle > 0.5:\n",
    "        state = np.concatenate([derived, palette])\n",
    "    else:\n",
    "        state = np.concatenate([derived, tiles, palette])\n",
    "    noise = np.random.randn(len(state)) * 0.0001\n",
    "    return state + noise\n",
    "\n",
    "def _pad_or_trim(arr, target_dim):\n",
    "    if arr.shape[0] < target_dim:\n",
    "        return np.pad(arr, (0, target_dim - arr.shape[0]))\n",
    "    elif arr.shape[0] > target_dim:\n",
    "        return arr[:target_dim]\n",
    "    return arr\n",
    "\n",
    "def parse_game_state_data(data):\n",
    "    \"\"\"Parse game state dict handling both long and short key formats.\"\"\"\n",
    "    raw = data.get(\"state\") or data.get(\"s\") or []\n",
    "    palette_raw = data.get(\"palette\") or data.get(\"p\") or []\n",
    "    tiles_raw = data.get(\"tiles\") or data.get(\"t\") or []\n",
    "    dead = bool(data.get(\"dead\", False))\n",
    "    return raw, palette_raw, tiles_raw, dead\n",
    "\n",
    "def read_game_state(max_retries=3):\n",
    "    if not STATE_FILE.exists():\n",
    "        return np.zeros(EXPECTED_STATE_DIM), np.zeros(PALETTE_DIM), np.zeros(TILE_DIM), False, (0, 0)\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            with open(STATE_FILE, \"r\") as f:\n",
    "                data = json.loads(f.read())\n",
    "\n",
    "            raw, palette_raw, tiles_raw, dead = parse_game_state_data(data)\n",
    "\n",
    "            raw_x = int(raw[0]) if len(raw) > 0 else 0\n",
    "            raw_y = int(raw[1]) if len(raw) > 1 else 0\n",
    "            raw_position = (raw_x, raw_y)\n",
    "\n",
    "            context_state = normalize_game_state(np.array(raw, dtype=float))\n",
    "            palette_state = np.array(palette_raw, dtype=float) if palette_raw else np.zeros(PALETTE_DIM)\n",
    "            tile_state = np.array(tiles_raw, dtype=float) if tiles_raw else np.zeros(TILE_DIM)\n",
    "\n",
    "            context_state = _pad_or_trim(context_state, EXPECTED_STATE_DIM)\n",
    "            palette_state = _pad_or_trim(palette_state, PALETTE_DIM)\n",
    "            tile_state = _pad_or_trim(tile_state, TILE_DIM)\n",
    "\n",
    "            return context_state, palette_state, tile_state, dead, raw_position\n",
    "\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(0.001)\n",
    "                continue\n",
    "            return np.zeros(EXPECTED_STATE_DIM), np.zeros(PALETTE_DIM), np.zeros(TILE_DIM), False, (0, 0)\n",
    "        except Exception:\n",
    "            return np.zeros(EXPECTED_STATE_DIM), np.zeros(PALETTE_DIM), np.zeros(TILE_DIM), False, (0, 0)\n",
    "\n",
    "def write_action(action_name):\n",
    "    if action_name:\n",
    "        action_name = action_name.upper()\n",
    "    try:\n",
    "        with open(ACTION_FILE, \"w\") as f:\n",
    "            json.dump({\"action\": action_name}, f)\n",
    "            f.flush()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to write action: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04795ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Perceptron Classes\n",
    "# ============================================================================\n",
    "# CHANGES:\n",
    "# 1. Added cluster_activations (deque maxlen=50) for clustering comparison\n",
    "# 2. Entity perceptrons record into cluster_activations on every predict()\n",
    "# ============================================================================\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, kind, action=None, group=None, entity_type=None):\n",
    "        self.kind = kind\n",
    "        self.action = action\n",
    "        self.group = group\n",
    "        self.entity_type = entity_type\n",
    "        \n",
    "        self.utility = 1.0\n",
    "        self.weights = None\n",
    "        \n",
    "        self.eligibility_fast = 0.0\n",
    "        self.eligibility_slow = 0.0\n",
    "        \n",
    "        self.familiarity = 0.0\n",
    "        self.activation_history = deque(maxlen=10)\n",
    "        self.cluster_activations = deque(maxlen=50)  # NEW: longer history for clustering\n",
    "        \n",
    "        self.learning_rate = 0.01\n",
    "        self.prediction_errors = deque(maxlen=50)\n",
    "\n",
    "    def ensure_weights(self, dim):\n",
    "        if self.weights is None:\n",
    "            self.weights = np.random.randn(dim) * 0.001\n",
    "\n",
    "    def predict(self, state):\n",
    "        self.ensure_weights(len(state))\n",
    "        \n",
    "        if len(self.weights) != len(state):\n",
    "            min_dim = min(len(self.weights), len(state))\n",
    "            raw_activation = np.dot(self.weights[:min_dim], state[:min_dim])\n",
    "        else:\n",
    "            raw_activation = np.dot(self.weights, state)\n",
    "        \n",
    "        if self.kind == \"entity\":\n",
    "            novelty_factor = 1.0 / (1.0 + np.sqrt(self.familiarity * 0.5))\n",
    "            decayed_activation = raw_activation * novelty_factor\n",
    "            self.activation_history.append(abs(raw_activation))\n",
    "            self.cluster_activations.append(abs(raw_activation))  # NEW\n",
    "            return decayed_activation\n",
    "        else:\n",
    "            return raw_activation\n",
    "\n",
    "    def adapt_learning_rate(self):\n",
    "        if len(self.prediction_errors) >= 50:\n",
    "            avg_error = np.mean(self.prediction_errors)\n",
    "            \n",
    "            if avg_error < 0.1:\n",
    "                self.learning_rate = max(0.001, self.learning_rate * 0.99)\n",
    "            elif avg_error > 0.5:\n",
    "                self.learning_rate = min(0.05, self.learning_rate * 1.01)\n",
    "\n",
    "    def update(self, state, error, gamma_fast=0.5, gamma_slow=0.95, stagnation=0.0):\n",
    "        self.ensure_weights(len(state))\n",
    "        \n",
    "        if len(self.weights) != len(state):\n",
    "            min_dim = min(len(self.weights), len(state))\n",
    "            state = state[:min_dim]\n",
    "            self.weights = self.weights[:min_dim]\n",
    "        \n",
    "        self.eligibility_fast = gamma_fast * self.eligibility_fast + 1.0\n",
    "        self.eligibility_slow = gamma_slow * self.eligibility_slow + 1.0\n",
    "        \n",
    "        self.adapt_learning_rate()\n",
    "        \n",
    "        fast_update = 0.7 * self.learning_rate * error * state * self.eligibility_fast\n",
    "        slow_update = 0.3 * self.learning_rate * error * state * self.eligibility_slow\n",
    "        self.weights += fast_update + slow_update\n",
    "\n",
    "        if self.kind == \"action\":\n",
    "            if error > 0.01:\n",
    "                if stagnation > 0.5:\n",
    "                    self.utility *= 0.97\n",
    "                elif error > 0.2:\n",
    "                    self.utility = min(self.utility * 1.02, 2.0)\n",
    "                else:\n",
    "                    self.utility *= 0.995\n",
    "            \n",
    "            if self.group == \"move\":\n",
    "                self.utility = np.clip(self.utility, 0.1, 2.0)\n",
    "            else:\n",
    "                self.utility = np.clip(self.utility, 0.01, 2.0)\n",
    "        \n",
    "        if self.kind == \"entity\" and len(self.activation_history) > 0:\n",
    "            recent_avg = np.mean(self.activation_history)\n",
    "            if recent_avg > 0.1:\n",
    "                self.familiarity += 0.03\n",
    "        \n",
    "        if self.kind == \"entity\":\n",
    "            prediction = self.predict(state)\n",
    "            self.prediction_errors.append(abs(prediction - error))\n",
    "\n",
    "\n",
    "class ControlSwapPerceptron(Perceptron):\n",
    "    def __init__(self):\n",
    "        super().__init__(kind=\"control_swap\")\n",
    "        self.swap_history = deque(maxlen=100)\n",
    "        self.confidence = 0.0\n",
    "        \n",
    "    def should_swap(self, state, movement_stagnation):\n",
    "        if self.weights is None:\n",
    "            return False, 0.0\n",
    "        \n",
    "        self.ensure_weights(len(state))\n",
    "        swap_score = np.dot(self.weights, state)\n",
    "        stagnation_factor = np.tanh(movement_stagnation / 5.0)\n",
    "        combined_score = swap_score * 0.7 + stagnation_factor * 0.3\n",
    "        \n",
    "        return combined_score > 0.5, abs(combined_score)\n",
    "    \n",
    "    def record_swap_outcome(self, state, swapped, novelty_gained):\n",
    "        self.swap_history.append((swapped, novelty_gained))\n",
    "        \n",
    "        if len(self.swap_history) >= 20:\n",
    "            recent = list(self.swap_history)[-20:]\n",
    "            successful = sum(1 for swap, nov in recent if swap and nov > 0.2)\n",
    "            self.confidence = successful / 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ad6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3 PART 1: Brain Class - Initialization (All State Variables)\n",
    "# ============================================================================\n",
    "# CHANGES:\n",
    "# 1. Battle thread state variables\n",
    "# 2. Cross-map navigation state variables\n",
    "#    - map_graph, nav_map_chain, nav_chain_index\n",
    "#    - nav_paused, nav_paused_reason, nav_cross_map_target\n",
    "# ============================================================================\n",
    "\n",
    "class Brain:\n",
    "    def __init__(self):\n",
    "        self.perceptrons = []\n",
    "        \n",
    "        self.prev_learning_states = deque(maxlen=50)\n",
    "        self.prev_context_states = deque(maxlen=10)\n",
    "        self.last_positions = deque(maxlen=30)\n",
    "        self.action_history = deque(maxlen=100)\n",
    "        \n",
    "        self.control_mode = \"move\"\n",
    "        self.timestep = 0\n",
    "        self.last_action = None\n",
    "        self.last_direction = 0\n",
    "        \n",
    "        self.MOVE_UTILITY_FLOOR = 0.05\n",
    "        self.INTERACT_UTILITY_FLOOR = 0.15\n",
    "        \n",
    "        # === PERSISTENT EXPLORATION MEMORY ===\n",
    "        self.EXPLORATION_MEMORY_FILE = BASE_PATH / \"exploration_memory.json\"\n",
    "        self.exploration_memory = {}\n",
    "        self.current_map_id = None\n",
    "        self.SAVE_INTERVAL = 100\n",
    "        \n",
    "        self.DIRECTION_NAMES = {0: \"DOWN\", 1: \"UP\", 2: \"LEFT\", 3: \"RIGHT\"}\n",
    "        self.DIRECTION_TO_INT = {\"DOWN\": 0, \"UP\": 1, \"LEFT\": 2, \"RIGHT\": 3}\n",
    "        self.INT_TO_ACTION = {0: \"DOWN\", 1: \"UP\", 2: \"LEFT\", 3: \"RIGHT\"}\n",
    "        \n",
    "        self.DIRECTION_DELTAS_INT = {0: (0, 1), 1: (0, -1), 2: (-1, 0), 3: (1, 0)}\n",
    "        self.ACTION_DELTAS = {\"UP\": (0, -1), \"DOWN\": (0, 1), \"LEFT\": (-1, 0), \"RIGHT\": (1, 0)}\n",
    "        self.DELTA_TO_DIRECTION = {(0, 1): 0, (0, -1): 1, (-1, 0): 2, (1, 0): 3}\n",
    "        \n",
    "        self.load_exploration_memory()\n",
    "        \n",
    "        # === MARKOV TRANSITION SYSTEM (OVERWORLD) ===\n",
    "        self.taught_transitions = []\n",
    "        self.taught_batches = []\n",
    "        self.taught_metadata = {}\n",
    "        self.markov_enabled = True\n",
    "        self.markov_action_count = 0\n",
    "        self.curiosity_action_count = 0\n",
    "        self.last_markov_score = 0.0\n",
    "        self.last_markov_action = None\n",
    "        \n",
    "        # === BATTLE THREAD STATE ===\n",
    "        self.battle_transitions = []\n",
    "        self.battle_sequences = []\n",
    "        self.battle_metadata = {}\n",
    "        self.battle_loaded = False\n",
    "        self.battle_action_count = 0\n",
    "        self.battle_markov_action_count = 0\n",
    "        self.current_battle_id = 0\n",
    "        self.battle_frame_count = 0\n",
    "        self.last_battle_markov_score = 0.0\n",
    "        self.last_battle_markov_action = None\n",
    "        self.in_battle_last_frame = False\n",
    "        self.battle_action_history = deque(maxlen=100)  # separate history, battle actions only\n",
    "        \n",
    "        # === TAUGHT MODEL REFERENCE (read-only, for stagnation blending) ===\n",
    "        self.taught_reference = {\n",
    "            'utilities': {},\n",
    "            'weights': {},\n",
    "            'loaded': False\n",
    "        }\n",
    "        \n",
    "        # === BLEND SYSTEM ===\n",
    "        self.blend_tier = 0\n",
    "        self.last_blend_timestep = 0\n",
    "        self.BLEND_COOLDOWN = 50\n",
    "        self.blend_count = 0\n",
    "        \n",
    "        self.BLEND_RATIOS = {\n",
    "            1: (0.80, 0.20),\n",
    "            2: (0.60, 0.40),\n",
    "            3: (0.40, 0.60)\n",
    "        }\n",
    "        \n",
    "        self.BLEND_TIER_TRIGGERS = {\n",
    "            1: {'pattern_repeats': 3, 'pos_stagnation': 8, 'consecutive': 12},\n",
    "            2: {'pattern_repeats': 6, 'pos_stagnation': 15, 'consecutive': 15},\n",
    "            3: {'pattern_repeats': 10, 'state_stagnation_mult': 2.0}\n",
    "        }\n",
    "        \n",
    "        # === ACTION EXECUTION CONFIRMATION ===\n",
    "        self.pending_action = None\n",
    "        self.pending_action_frames = 0\n",
    "        self.ACTION_CONFIRM_FRAMES = 3\n",
    "        self.last_confirmed_action = None\n",
    "        \n",
    "        # === TILE INTERACTION PROBING ===\n",
    "        self.INTERACTION_VERIFY_FRAMES = 8\n",
    "        self.MIN_SUCCESS_RATE_THRESHOLD = 0.1\n",
    "        self.pending_interaction_verify = None\n",
    "        self.interaction_verify_countdown = 0\n",
    "        \n",
    "        # === MENU ESCAPE B-BOOST ===\n",
    "        self.menu_trap_frames = 0\n",
    "        self.menu_trap_b_boost = 1.0\n",
    "        self.menu_trap_position = None\n",
    "        self.B_BOOST_INCREMENT = 0.15\n",
    "        self.B_BOOST_MAX = 3.0\n",
    "        self.MENU_TRAP_THRESHOLD = 5\n",
    "        self.original_b_utility = None\n",
    "        \n",
    "        # === ADAPTIVE MODE SWAPPING ===\n",
    "        self.DEFAULT_MOVE_TO_INTERACT_THRESHOLD = 15\n",
    "        self.DEFAULT_INTERACT_TO_MOVE_THRESHOLD = 25\n",
    "        self.move_to_interact_threshold = self.DEFAULT_MOVE_TO_INTERACT_THRESHOLD\n",
    "        self.interact_to_move_threshold = self.DEFAULT_INTERACT_TO_MOVE_THRESHOLD\n",
    "        self.THRESHOLD_INCREMENT = 15\n",
    "        self.MAX_THRESHOLD = 150\n",
    "        self.frames_in_current_mode = 0\n",
    "        self.swap_chain_count = 0\n",
    "        self.position_at_mode_swap = None\n",
    "        self.last_map_id = None\n",
    "        self.last_battle_state = None\n",
    "        \n",
    "        # === UNPRODUCTIVE MODE SWAP TRACKING ===\n",
    "        self.UNPRODUCTIVE_SWAP_THRESHOLD = 3\n",
    "        self.unproductive_swap_count = 0\n",
    "        self.utilities_before_swapping = {}\n",
    "        self.swap_chain_active = False\n",
    "        \n",
    "        # === STATE STAGNATION DETECTION ===\n",
    "        self.STATE_STAGNATION_THRESHOLD = 20\n",
    "        self.state_stagnation_count = 0\n",
    "        self.last_context_state_hash = None\n",
    "        self.stagnation_initiator_action = None\n",
    "        self.STAGNATION_INITIATOR_PENALTY = 0.7\n",
    "        \n",
    "        # === \"BOTH\" MODE THRESHOLDS ===\n",
    "        self.BOTH_MODE_STAGNATION_THRESHOLD = 35\n",
    "        self.BOTH_MODE_SWAP_THRESHOLD = 5\n",
    "        \n",
    "        # === TURN AS PROGRESS TRACKING ===\n",
    "        self.last_direction_for_progress = None\n",
    "        self.direction_change_counts_as_progress = True\n",
    "        \n",
    "        # === NOVELTY WEIGHTS ===\n",
    "        self.UNVISITED_TILE_BONUS = 1.5\n",
    "        self.OBSTRUCTION_PENALTY = 0.25\n",
    "        \n",
    "        # === TRANSITION SYSTEM ===\n",
    "        self.TRANSITION_ATTRACTION_WEIGHT = 0.6\n",
    "        self.TEMP_DEBT_ACCUMULATION = 0.5\n",
    "        self.TEMP_DEBT_DECAY = 0.02\n",
    "        self.TEMP_DEBT_MAX = 15.0\n",
    "        \n",
    "        # === DEBT CAPS AND DECAY ===\n",
    "        self.MAX_MAP_DEBT = 10.0\n",
    "        self.MAX_LOCATION_DEBT = 5.0\n",
    "        self.DEBT_DECAY_RATE = 0.005\n",
    "        \n",
    "        # === TRANSITION BAN SYSTEM ===\n",
    "        self.transition_bans = {}\n",
    "        self.BAN_VICINITY_RADIUS = 3\n",
    "        self.BAN_COVERAGE_LIFT_THRESHOLD = 0.6\n",
    "        self.BAN_TIMEOUT_STEPS = 300\n",
    "        \n",
    "        # Multi-scale memory\n",
    "        self.visited_maps = {}\n",
    "        self.map_novelty_debt = {}\n",
    "        self.location_memory = {}\n",
    "        self.location_novelty = {}\n",
    "        self.action_execution_count = {}\n",
    "        \n",
    "        self.swap_perceptron = ControlSwapPerceptron()\n",
    "        self.error_history = deque(maxlen=1000)\n",
    "        self.numeric_error_history = deque(maxlen=1000)\n",
    "        self.visual_error_history = deque(maxlen=1000)\n",
    "        self._entity_norms_cache = {}\n",
    "        self._cache_valid = False\n",
    "        self.innate_entities_spawned = False\n",
    "        \n",
    "        # === REPETITION CORRECTION ===\n",
    "        self.consecutive_action_count = 0\n",
    "        self.current_repeated_action = None\n",
    "        self.LEARNING_SLOWDOWN_START = 3\n",
    "        self.LEARNING_SLOWDOWN_MAX = 10\n",
    "        self.PENALTY_THRESHOLD = 12\n",
    "        self.HARD_RESET_THRESHOLD = 18\n",
    "        \n",
    "        # === PATTERN DETECTION ===\n",
    "        self.PATTERN_CHECK_WINDOW = 50\n",
    "        self.PATTERN_MIN_REPEATS = 3\n",
    "        self.PATTERN_MAX_LENGTH = 10\n",
    "        self.detected_pattern = None\n",
    "        self.pattern_repeat_count = 0\n",
    "\n",
    "        # === PROBE ACTION CACHE ===\n",
    "        self._cached_probe_action = None\n",
    "        self._cached_probe_dir = None\n",
    "        self._probe_cache_position = None\n",
    "\n",
    "        # === NAVIGATION MODE ===\n",
    "        self.nav_active = False\n",
    "        self.nav_path = []\n",
    "        self.nav_path_index = 0\n",
    "        self.nav_target = None\n",
    "        self.nav_target_list = []\n",
    "        self.nav_target_index = 0\n",
    "        self.nav_struck_targets = set()\n",
    "        self.nav_steps_taken = 0\n",
    "        self.nav_stagnation_count = 0\n",
    "        self.nav_last_position = None\n",
    "        \n",
    "        self.KNOWN_AREA_TRIGGER = 20\n",
    "        self.known_area_counter = 0\n",
    "        self.NAV_STAGNATION_LIMIT = 8\n",
    "        self.NAV_MAX_STEPS = 100\n",
    "        self.NAV_CURIOSITY_WINDOW = 5\n",
    "        self.nav_curiosity_countdown = 0\n",
    "        self.NAV_LEARNING_DAMPENING = 0.3\n",
    "\n",
    "        # === CROSS-MAP NAVIGATION ===\n",
    "        self.nav_map_chain = []           # ordered list of map_ids to traverse [current, ..., target_map]\n",
    "        self.nav_chain_index = 0          # which step in the chain we're on\n",
    "        self.nav_cross_map_target = None  # the final target (pos, map_id) across maps\n",
    "        self.nav_cross_map_target_data = None  # metadata about the final target (score, type, etc.)\n",
    "        self.nav_paused = False           # True when waiting for transition discovery\n",
    "        self.nav_paused_reason = \"\"       # why navigation is paused\n",
    "        self.nav_paused_target_map = None # which map we need a transition to\n",
    "        self.NAV_PAUSE_CHECK_INTERVAL = 50  # how often to recheck for new transitions while paused\n",
    "        self.nav_pause_check_countdown = 0  # countdown to next recheck\n",
    "        self.NAV_CROSS_MAP_REFRESH_INTERVAL = 40  # how often to recalculate cross-map path\n",
    "        self.nav_cross_map_refresh_countdown = 0   # countdown to next refresh\n",
    "        self._map_graph = {}              # map_id -> set of (dest_map_id, transition_dict) ‚Äî rebuilt on demand\n",
    "        self._map_graph_dirty = True      # flag to rebuild graph when transitions change\n",
    "\n",
    "        # === ENTITY SPAWNING & CLUSTERING ===\n",
    "        self.ENTITY_INITIAL_CAPACITY = 20\n",
    "        self.entity_capacity = self.ENTITY_INITIAL_CAPACITY\n",
    "        self.ENTITY_CAPACITY_GROWTH = 1.5\n",
    "        self.ENTITY_CLUSTER_SIMILARITY = 0.85\n",
    "        self.ENTITY_MIN_ACTIVATIONS = 10\n",
    "        self.entity_spawn_count = 0\n",
    "        self.entity_merge_count = 0\n",
    "\n",
    "        # === TAUGHT NAVIGATION TARGETS ===\n",
    "        self.taught_nav_targets = {}\n",
    "        self.taught_nav_global_order = []\n",
    "        self.nav_visited_targets = set()\n",
    "        self.taught_nav_loaded = False\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3 PART 2: Taught Reference, Blend System, Markov (Overworld + Battle)\n",
    "# ============================================================================\n",
    "# CHANGES:\n",
    "# 1. Added load_taught_battle_transitions() method\n",
    "# 2. Added compute_battle_markov_similarity() method\n",
    "# 3. Added get_battle_markov_action() method\n",
    "# ============================================================================\n",
    "\n",
    "    # =========================================================================\n",
    "    # TAUGHT MODEL REFERENCE\n",
    "    # =========================================================================\n",
    "    \n",
    "    def load_taught_reference(self, filepath):\n",
    "        \"\"\"\n",
    "        Load taught model as a READ-ONLY reference for stagnation blending.\n",
    "        Does NOT overwrite AI's own utilities or weights.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not Path(filepath).exists():\n",
    "                print(f\"  No taught reference model found at {filepath}\")\n",
    "                return\n",
    "            \n",
    "            with open(filepath, 'r') as f:\n",
    "                model = json.load(f)\n",
    "            \n",
    "            if \"perceptrons\" not in model:\n",
    "                print(f\"  ‚ö†Ô∏è Taught reference model empty or invalid\")\n",
    "                return\n",
    "            \n",
    "            for saved_action in model[\"perceptrons\"].get(\"actions\", []):\n",
    "                action_name = saved_action.get(\"action\")\n",
    "                if action_name:\n",
    "                    self.taught_reference['utilities'][action_name] = saved_action.get(\"utility\", 1.0)\n",
    "                    \n",
    "                    if saved_action.get(\"weights_nonzero\"):\n",
    "                        dim = saved_action.get(\"weights_shape\", 1376)\n",
    "                        w = np.zeros(dim)\n",
    "                        for idx, val in saved_action[\"weights_nonzero\"]:\n",
    "                            if idx < dim:\n",
    "                                w[idx] = val\n",
    "                        self.taught_reference['weights'][action_name] = w\n",
    "            \n",
    "            self.taught_reference['loaded'] = True\n",
    "            \n",
    "            print(f\"  üìñ Taught reference loaded:\")\n",
    "            print(f\"     Actions: {list(self.taught_reference['utilities'].keys())}\")\n",
    "            print(f\"     Utilities: {', '.join(f'{k}:{v:.3f}' for k, v in self.taught_reference['utilities'].items())}\")\n",
    "            print(f\"     Weights available: {list(self.taught_reference['weights'].keys())}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Error loading taught reference: {e}\")\n",
    "    \n",
    "    def blend_from_taught(self, tier):\n",
    "        \"\"\"\n",
    "        Blend AI's current utilities (and optionally weights) toward taught values.\n",
    "        \n",
    "        tier 1 (light):  80% AI / 20% taught ‚Äî utilities only\n",
    "        tier 2 (medium): 60% AI / 40% taught ‚Äî utilities only\n",
    "        tier 3 (hard):   40% AI / 60% taught ‚Äî utilities + weights\n",
    "        \"\"\"\n",
    "        if not self.taught_reference['loaded']:\n",
    "            return\n",
    "        \n",
    "        if tier not in self.BLEND_RATIOS:\n",
    "            return\n",
    "        \n",
    "        if self.timestep - self.last_blend_timestep < self.BLEND_COOLDOWN:\n",
    "            return\n",
    "        \n",
    "        ai_weight, taught_weight = self.BLEND_RATIOS[tier]\n",
    "        blend_weights = (tier == 3)\n",
    "        \n",
    "        blended_actions = []\n",
    "        \n",
    "        for a in self.actions():\n",
    "            if a.action not in self.taught_reference['utilities']:\n",
    "                continue\n",
    "            \n",
    "            taught_util = self.taught_reference['utilities'][a.action]\n",
    "            old_util = a.utility\n",
    "            \n",
    "            a.utility = ai_weight * a.utility + taught_weight * taught_util\n",
    "            \n",
    "            if taught_util > 1.0:\n",
    "                a.utility = max(a.utility, taught_util * 0.5)\n",
    "            \n",
    "            floor = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "            a.utility = max(a.utility, floor)\n",
    "            a.utility = min(a.utility, 2.0)\n",
    "            \n",
    "            blended_actions.append(f\"{a.action}:{old_util:.3f}‚Üí{a.utility:.3f}\")\n",
    "            \n",
    "            if blend_weights and a.action in self.taught_reference['weights']:\n",
    "                taught_w = self.taught_reference['weights'][a.action]\n",
    "                if a.weights is not None:\n",
    "                    min_dim = min(len(a.weights), len(taught_w))\n",
    "                    a.weights[:min_dim] = (\n",
    "                        ai_weight * a.weights[:min_dim] + \n",
    "                        taught_weight * taught_w[:min_dim]\n",
    "                    )\n",
    "        \n",
    "        self.last_blend_timestep = self.timestep\n",
    "        self.blend_tier = tier\n",
    "        self.blend_count += 1\n",
    "        \n",
    "        tier_names = {1: \"LIGHT\", 2: \"MEDIUM\", 3: \"HARD\"}\n",
    "        print(f\"  üîÄ BLEND [{tier_names.get(tier, '?')}] ({ai_weight:.0%} AI / {taught_weight:.0%} taught)\"\n",
    "              f\" | Blend #{self.blend_count}\")\n",
    "        for ba in blended_actions:\n",
    "            print(f\"     {ba}\")\n",
    "        if blend_weights:\n",
    "            print(f\"     + Weights blended for: {list(self.taught_reference['weights'].keys())}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # OVERWORLD MARKOV TRANSITION SYSTEM\n",
    "    # =========================================================================\n",
    "    \n",
    "    def load_taught_transitions(self, filepath=None):\n",
    "        filepath = filepath or TAUGHT_TRANSITIONS_FILE\n",
    "        try:\n",
    "            if Path(filepath).exists():\n",
    "                with open(filepath, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                self.taught_transitions = []\n",
    "                self.taught_batches = data.get('batches', [])\n",
    "                \n",
    "                for batch in self.taught_batches:\n",
    "                    batch_type = batch.get('batch_type', 'steady')\n",
    "                    trigger_action = batch.get('trigger_action')\n",
    "                    \n",
    "                    for frame in batch.get('frames', []):\n",
    "                        transition = {\n",
    "                            'state': frame.get('state', {}),\n",
    "                            'action': frame.get('action'),\n",
    "                            'recent_actions': frame.get('recent_actions', []),\n",
    "                            'frame_offset': frame.get('frame_offset', 0),\n",
    "                            'batch_type': batch_type,\n",
    "                            'trigger_action': trigger_action\n",
    "                        }\n",
    "                        self.taught_transitions.append(transition)\n",
    "                \n",
    "                self.taught_metadata = data.get('metadata', {})\n",
    "                \n",
    "                print(f\"  üìö Loaded taught transitions:\")\n",
    "                print(f\"     Batches: {len(self.taught_batches)}\")\n",
    "                print(f\"     Frames: {len(self.taught_transitions)}\")\n",
    "                print(f\"     Action changes: {self.taught_metadata.get('action_changes', 0)}\")\n",
    "                print(f\"     Maps visited: {self.taught_metadata.get('maps_visited', [])}\")\n",
    "            else:\n",
    "                self.taught_transitions = []\n",
    "                self.taught_batches = []\n",
    "                self.taught_metadata = {}\n",
    "                print(f\"  No taught transitions file found at {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading taught transitions: {e}\")\n",
    "            self.taught_transitions = []\n",
    "            self.taught_batches = []\n",
    "            self.taught_metadata = {}\n",
    "    \n",
    "    def extract_partial_context(self, context_state, raw_position=None):\n",
    "        raw_x = raw_position[0] if raw_position else int(context_state[0] * 255)\n",
    "        raw_y = raw_position[1] if raw_position else int(context_state[1] * 255)\n",
    "        current_map = int(context_state[2])\n",
    "        \n",
    "        movement_blocked = self.get_position_stagnation() > 3\n",
    "        \n",
    "        near_transition = False\n",
    "        memory = self.get_current_map_memory(current_map)\n",
    "        for t in memory.get('transitions', []):\n",
    "            t_pos = tuple(t['position']) if isinstance(t['position'], list) else t['position']\n",
    "            if abs(raw_x - t_pos[0]) + abs(raw_y - t_pos[1]) <= 2:\n",
    "                near_transition = True\n",
    "                break\n",
    "        \n",
    "        tile_probed = not self.should_interact_at_tile(raw_x, raw_y, current_map)\n",
    "        \n",
    "        return {\n",
    "            'in_battle': context_state[3] > 0.5,\n",
    "            'in_menu': context_state[4] > 0.5,\n",
    "            'movement_blocked': movement_blocked,\n",
    "            'near_transition': near_transition,\n",
    "            'tile_probed': tile_probed\n",
    "        }\n",
    "    \n",
    "    def compute_markov_similarity(self, context_state, raw_position=None, taught_frames=None):\n",
    "        frames = taught_frames if taught_frames is not None else self.taught_transitions\n",
    "        skip_map_check = taught_frames is not None\n",
    "        \n",
    "        if not frames:\n",
    "            return 0.0, None, -1\n",
    "        \n",
    "        raw_x = raw_position[0] if raw_position else int(context_state[0] * 255)\n",
    "        raw_y = raw_position[1] if raw_position else int(context_state[1] * 255)\n",
    "        current_map = int(context_state[2])\n",
    "        current_dir = int(context_state[5])\n",
    "        in_battle = context_state[3] > 0.5\n",
    "        in_menu = context_state[4] > 0.5\n",
    "        \n",
    "        current_actions = list(self.action_history)\n",
    "        current_partial = self.extract_partial_context(context_state, raw_position)\n",
    "        \n",
    "        best_score = 0.0\n",
    "        best_action = None\n",
    "        best_idx = -1\n",
    "        \n",
    "        for idx, transition in enumerate(frames):\n",
    "            t_state = transition.get('state', {})\n",
    "            t_action = transition.get('action')\n",
    "            t_recent = transition.get('recent_actions', [])\n",
    "            batch_type = transition.get('batch_type', 'steady')\n",
    "            \n",
    "            if not t_action or t_action == \"NONE\":\n",
    "                continue\n",
    "            \n",
    "            immediate_score = 0.0\n",
    "            \n",
    "            if not skip_map_check:\n",
    "                if t_state.get('map_id') != current_map:\n",
    "                    continue\n",
    "            immediate_score += 0.25\n",
    "            \n",
    "            t_x = t_state.get('x', 0)\n",
    "            t_y = t_state.get('y', 0)\n",
    "            pos_dist = abs(raw_x - t_x) + abs(raw_y - t_y)\n",
    "            \n",
    "            if pos_dist == 0:\n",
    "                immediate_score += MARKOV_POS_EXACT_BONUS\n",
    "            elif pos_dist <= 2:\n",
    "                immediate_score += MARKOV_POS_NEAR_BONUS\n",
    "            elif pos_dist <= MARKOV_POS_MAX_DIST:\n",
    "                immediate_score += MARKOV_POS_FAR_BONUS\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if t_state.get('direction') == current_dir:\n",
    "                immediate_score += 0.2\n",
    "            \n",
    "            t_in_battle = t_state.get('in_battle', 0) == 1\n",
    "            t_in_menu = t_state.get('in_menu', 0) == 1\n",
    "            \n",
    "            if t_in_battle == in_battle:\n",
    "                immediate_score += 0.1\n",
    "            if t_in_menu == in_menu:\n",
    "                immediate_score += 0.1\n",
    "            \n",
    "            sequential_score = 0.0\n",
    "            \n",
    "            if t_recent and current_actions:\n",
    "                if len(current_actions) >= 8 and len(t_recent) >= 8:\n",
    "                    if list(current_actions)[-8:] == t_recent[-8:]:\n",
    "                        sequential_score = MARKOV_SEQ_FULL_WEIGHT\n",
    "                \n",
    "                if sequential_score < MARKOV_SEQ_MEDIUM_WEIGHT:\n",
    "                    if len(current_actions) >= 5 and len(t_recent) >= 5:\n",
    "                        if list(current_actions)[-5:] == t_recent[-5:]:\n",
    "                            sequential_score = MARKOV_SEQ_MEDIUM_WEIGHT\n",
    "                \n",
    "                if sequential_score < MARKOV_SEQ_SHORT_WEIGHT:\n",
    "                    if len(current_actions) >= 3 and len(t_recent) >= 3:\n",
    "                        if list(current_actions)[-3:] == t_recent[-3:]:\n",
    "                            sequential_score = MARKOV_SEQ_SHORT_WEIGHT\n",
    "            \n",
    "            partial_score = 0.0\n",
    "            partial_matches = 0\n",
    "            partial_total = 2\n",
    "            \n",
    "            if t_in_battle == current_partial['in_battle']:\n",
    "                partial_matches += 1\n",
    "            if t_in_menu == current_partial['in_menu']:\n",
    "                partial_matches += 1\n",
    "            \n",
    "            partial_score = partial_matches / partial_total\n",
    "            \n",
    "            total_score = (\n",
    "                MARKOV_IMMEDIATE_WEIGHT * immediate_score +\n",
    "                MARKOV_SEQUENTIAL_WEIGHT * sequential_score +\n",
    "                MARKOV_PARTIAL_WEIGHT * partial_score\n",
    "            )\n",
    "            \n",
    "            if batch_type == \"action_change\":\n",
    "                total_score *= 1.2\n",
    "            \n",
    "            if transition.get('frame_offset', 0) == 0:\n",
    "                total_score *= 1.1\n",
    "            \n",
    "            if total_score > best_score:\n",
    "                best_score = total_score\n",
    "                best_action = t_action\n",
    "                best_idx = idx\n",
    "        \n",
    "        return best_score, best_action, best_idx\n",
    "    \n",
    "    def get_markov_action(self, context_state, raw_position=None, taught_frames=None):\n",
    "        if not self.markov_enabled:\n",
    "            return False, None, 0.0\n",
    "        \n",
    "        frames = taught_frames if taught_frames is not None else self.taught_transitions\n",
    "        if not frames:\n",
    "            return False, None, 0.0\n",
    "        \n",
    "        score, action, idx = self.compute_markov_similarity(\n",
    "            context_state, raw_position, taught_frames=frames\n",
    "        )\n",
    "        \n",
    "        self.last_markov_score = score\n",
    "        \n",
    "        if score >= MARKOV_FAMILIARITY_THRESHOLD:\n",
    "            self.last_markov_action = action\n",
    "            return True, action, score\n",
    "        \n",
    "        return False, None, score\n",
    "\n",
    "    # =========================================================================\n",
    "    # BATTLE MARKOV SYSTEM\n",
    "    # =========================================================================\n",
    "    \n",
    "    def load_taught_battle_transitions(self, filepath=None):\n",
    "        \"\"\"\n",
    "        Load battle demonstration frames from taught_battle_transitions.json.\n",
    "        This is read-only ‚Äî the AI never writes to this file.\n",
    "        Falls back gracefully if file is missing.\n",
    "        \"\"\"\n",
    "        filepath = filepath or TAUGHT_BATTLE_TRANSITIONS_FILE\n",
    "        try:\n",
    "            if not Path(filepath).exists():\n",
    "                self.battle_transitions = []\n",
    "                self.battle_sequences = []\n",
    "                self.battle_metadata = {}\n",
    "                self.battle_loaded = False\n",
    "                print(f\"  ‚öîÔ∏è No battle transitions file found at {filepath}\")\n",
    "                print(f\"     Battle fallback: A-button only\")\n",
    "                return\n",
    "            \n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            self.battle_transitions = data.get('flat_frames', [])\n",
    "            self.battle_sequences = data.get('battle_sequences', [])\n",
    "            self.battle_metadata = data.get('metadata', {})\n",
    "            self.battle_loaded = True\n",
    "            \n",
    "            print(f\"  ‚öîÔ∏è Loaded battle transitions:\")\n",
    "            print(f\"     Flat frames: {len(self.battle_transitions)}\")\n",
    "            print(f\"     Battle sequences: {len(self.battle_sequences)}\")\n",
    "            print(f\"     Total battle frames: {self.battle_metadata.get('total_battle_frames', 0)}\")\n",
    "            print(f\"     Battles recorded: {self.battle_metadata.get('battles_recorded', 0)}\")\n",
    "            print(f\"     Avg battle length: {self.battle_metadata.get('avg_battle_length', 0)}\")\n",
    "            outcomes = self.battle_metadata.get('outcomes', {})\n",
    "            if outcomes:\n",
    "                print(f\"     Outcomes: {outcomes}\")\n",
    "            common_seqs = self.battle_metadata.get('most_common_sequences', [])\n",
    "            if common_seqs:\n",
    "                for seq in common_seqs[:3]:\n",
    "                    print(f\"     Common seq: {seq.get('sequence', [])} x{seq.get('count', 0)} ({seq.get('context', '')})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Error loading battle transitions: {e}\")\n",
    "            self.battle_transitions = []\n",
    "            self.battle_sequences = []\n",
    "            self.battle_metadata = {}\n",
    "            self.battle_loaded = False\n",
    "    \n",
    "    def compute_battle_markov_similarity(self, context_state, palette_state=None):\n",
    "        \"\"\"\n",
    "        Battle-specific Markov matching against taught battle frames.\n",
    "        \n",
    "        Simpler than overworld Markov:\n",
    "        - No map filtering (battle behavior is map-independent)\n",
    "        - No position matching (position is irrelevant in battle)\n",
    "        - Primary signal: recent_actions sequential matching (70%)\n",
    "        - Secondary signal: palette similarity (20%)\n",
    "        - Tertiary signal: menu state (10%)\n",
    "        \n",
    "        Returns: (score, action, index)\n",
    "        \"\"\"\n",
    "        if not self.battle_transitions:\n",
    "            return 0.0, None, -1\n",
    "        \n",
    "        current_actions = list(self.battle_action_history)\n",
    "        in_menu = context_state[4] > 0.5\n",
    "        \n",
    "        best_score = 0.0\n",
    "        best_action = None\n",
    "        best_idx = -1\n",
    "        \n",
    "        for idx, frame in enumerate(self.battle_transitions):\n",
    "            t_action = frame.get('action')\n",
    "            t_recent = frame.get('recent_actions', [])\n",
    "            t_state = frame.get('state', {})\n",
    "            batch_type = frame.get('batch_type', 'steady')\n",
    "            \n",
    "            if not t_action or t_action == \"NONE\":\n",
    "                continue\n",
    "            \n",
    "            # === PRIMARY: Sequential action matching (70% weight) ===\n",
    "            seq_score = 0.0\n",
    "            \n",
    "            if t_recent and current_actions:\n",
    "                # 8-action match = very high confidence\n",
    "                if len(current_actions) >= 8 and len(t_recent) >= 8:\n",
    "                    if list(current_actions)[-8:] == t_recent[-8:]:\n",
    "                        seq_score = 1.0\n",
    "                \n",
    "                # 5-action match = high confidence\n",
    "                if seq_score < 0.6:\n",
    "                    if len(current_actions) >= 5 and len(t_recent) >= 5:\n",
    "                        if list(current_actions)[-5:] == t_recent[-5:]:\n",
    "                            seq_score = 0.6\n",
    "                \n",
    "                # 3-action match = moderate confidence\n",
    "                if seq_score < 0.3:\n",
    "                    if len(current_actions) >= 3 and len(t_recent) >= 3:\n",
    "                        if list(current_actions)[-3:] == t_recent[-3:]:\n",
    "                            seq_score = 0.3\n",
    "            \n",
    "            # === SECONDARY: Palette similarity (20% weight) ===\n",
    "            palette_score = 0.0\n",
    "            \n",
    "            if palette_state is not None and 'palette_snapshot' in frame:\n",
    "                # If the frame has a palette snapshot, compare\n",
    "                t_palette = np.array(frame['palette_snapshot'], dtype=float)\n",
    "                if len(t_palette) > 0 and len(palette_state) > 0:\n",
    "                    min_dim = min(len(t_palette), len(palette_state))\n",
    "                    diff = np.linalg.norm(t_palette[:min_dim] - palette_state[:min_dim])\n",
    "                    # Normalize: lower diff = higher similarity\n",
    "                    palette_score = 1.0 / (1.0 + diff * 0.01)\n",
    "            else:\n",
    "                # No palette data available ‚Äî neutral score\n",
    "                palette_score = 0.5\n",
    "            \n",
    "            # === TERTIARY: Menu state match (10% weight) ===\n",
    "            menu_score = 0.0\n",
    "            t_in_menu = t_state.get('in_menu', 0) == 1\n",
    "            if t_in_menu == in_menu:\n",
    "                menu_score = 1.0\n",
    "            \n",
    "            # === COMBINE ===\n",
    "            total_score = (\n",
    "                BATTLE_MARKOV_ACTION_SEQ_WEIGHT * seq_score +\n",
    "                BATTLE_MARKOV_PALETTE_WEIGHT * palette_score +\n",
    "                BATTLE_MARKOV_MENU_STATE_WEIGHT * menu_score\n",
    "            )\n",
    "            \n",
    "            # Boost action_change frames (human actively chose this)\n",
    "            if batch_type == \"action_change\":\n",
    "                total_score *= 1.15\n",
    "            \n",
    "            # Boost frame_offset 0 (start of a new action)\n",
    "            if frame.get('frame_offset', 0) == 0:\n",
    "                total_score *= 1.1\n",
    "            \n",
    "            if total_score > best_score:\n",
    "                best_score = total_score\n",
    "                best_action = t_action\n",
    "                best_idx = idx\n",
    "        \n",
    "        return best_score, best_action, best_idx\n",
    "    \n",
    "    def get_battle_markov_action(self, context_state, palette_state=None):\n",
    "        \"\"\"\n",
    "        Get battle action from Markov matching.\n",
    "        \n",
    "        Returns: (matched, action, score)\n",
    "          matched: True if score >= threshold\n",
    "          action: the suggested action string (or None)\n",
    "          score: the similarity score\n",
    "        \"\"\"\n",
    "        if not self.battle_loaded or not self.battle_transitions:\n",
    "            return False, None, 0.0\n",
    "        \n",
    "        score, action, idx = self.compute_battle_markov_similarity(\n",
    "            context_state, palette_state\n",
    "        )\n",
    "        \n",
    "        self.last_battle_markov_score = score\n",
    "        \n",
    "        # Use lower threshold than overworld ‚Äî follow human closely\n",
    "        threshold = BATTLE_MARKOV_THRESHOLD_LOW\n",
    "        if len(self.battle_transitions) > 200:\n",
    "            # More data = can be slightly pickier\n",
    "            threshold = BATTLE_MARKOV_THRESHOLD_HIGH\n",
    "        \n",
    "        if score >= threshold and action:\n",
    "            self.last_battle_markov_action = action\n",
    "            return True, action, score\n",
    "        \n",
    "        return False, None, score\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3 PART 3: Action Confirmation, Exploration Memory, Tile Probing\n",
    "# ============================================================================\n",
    "# NO CHANGES from original Cell 3 Part 1/2 ‚Äî just reorganized boundary\n",
    "# ============================================================================\n",
    "\n",
    "    # =========================================================================\n",
    "    # ACTION EXECUTION CONFIRMATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    def set_pending_action(self, action_name):\n",
    "        self.pending_action = action_name\n",
    "        self.pending_action_frames = 0\n",
    "    \n",
    "    def confirm_action_executed(self, context_state, prev_context_state):\n",
    "        if self.pending_action is None:\n",
    "            return True\n",
    "        self.pending_action_frames += 1\n",
    "        action_executed = False\n",
    "        if prev_context_state is not None:\n",
    "            if self.pending_action in [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]:\n",
    "                pos_changed = (context_state[0] != prev_context_state[0] or \n",
    "                              context_state[1] != prev_context_state[1])\n",
    "                dir_changed = context_state[5] != prev_context_state[5]\n",
    "                action_executed = pos_changed or dir_changed\n",
    "            elif self.pending_action in [\"A\", \"B\", \"Start\", \"Select\"]:\n",
    "                menu_changed = abs(context_state[4] - prev_context_state[4]) > 0.1\n",
    "                battle_changed = context_state[3] != prev_context_state[3]\n",
    "                map_changed = context_state[2] != prev_context_state[2]\n",
    "                action_executed = menu_changed or battle_changed or map_changed\n",
    "        if action_executed or self.pending_action_frames >= self.ACTION_CONFIRM_FRAMES:\n",
    "            self.last_confirmed_action = self.pending_action\n",
    "            self.pending_action = None\n",
    "            self.pending_action_frames = 0\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def should_send_new_action(self):\n",
    "        return self.pending_action is None or self.pending_action_frames >= self.ACTION_CONFIRM_FRAMES\n",
    "\n",
    "    # =========================================================================\n",
    "    # EXPLORATION MEMORY PERSISTENCE\n",
    "    # =========================================================================\n",
    "    \n",
    "    def load_exploration_memory(self):\n",
    "        try:\n",
    "            if self.EXPLORATION_MEMORY_FILE.exists():\n",
    "                with open(self.EXPLORATION_MEMORY_FILE, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    self.exploration_memory = {}\n",
    "                    for map_key, map_data in data.items():\n",
    "                        map_id = int(map_key.replace('map_', ''))\n",
    "                        self.exploration_memory[map_id] = self._deserialize_map_memory(map_data)\n",
    "                print(f\"  Loaded exploration memory: {len(self.exploration_memory)} maps\")\n",
    "            else:\n",
    "                self.exploration_memory = {}\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading exploration memory: {e}\")\n",
    "            self.exploration_memory = {}\n",
    "\n",
    "    def _deserialize_map_memory(self, map_data):\n",
    "        memory = {\n",
    "            'visited_tiles': set(tuple(t) for t in map_data.get('visited_tiles', [])),\n",
    "            'obstructions': set(tuple(t) for t in map_data.get('obstructions', [])),\n",
    "            'interactable_objects': map_data.get('interactable_objects', []),\n",
    "            'last_visited_timestep': map_data.get('last_visited_timestep', 0),\n",
    "            'transitions': map_data.get('transitions', []),\n",
    "            'temp_debt': map_data.get('temp_debt', 0.0),\n",
    "            'tile_interactions': {}\n",
    "        }\n",
    "        for tile_key, tile_data in map_data.get('tile_interactions', {}).items():\n",
    "            memory['tile_interactions'][tile_key] = {\n",
    "                'directions_tried': set(tile_data.get('directions_tried', [])),\n",
    "                'direction_attempts': {int(k): v for k, v in tile_data.get('direction_attempts', {}).items()},\n",
    "                'direction_successes': {int(k): v for k, v in tile_data.get('direction_successes', {}).items()},\n",
    "                'exhausted': tile_data.get('exhausted', False)\n",
    "            }\n",
    "        return memory\n",
    "\n",
    "    def save_exploration_memory(self):\n",
    "        try:\n",
    "            data = {f'map_{mid}': self._serialize_map_memory(md) for mid, md in self.exploration_memory.items()}\n",
    "            with open(self.EXPLORATION_MEMORY_FILE, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error saving exploration memory: {e}\")\n",
    "\n",
    "    def _serialize_map_memory(self, map_data):\n",
    "        serialized_ti = {}\n",
    "        for tile_key, td in map_data.get('tile_interactions', {}).items():\n",
    "            serialized_ti[tile_key] = {\n",
    "                'directions_tried': list(td.get('directions_tried', set())),\n",
    "                'direction_attempts': {str(k): v for k, v in td.get('direction_attempts', {}).items()},\n",
    "                'direction_successes': {str(k): v for k, v in td.get('direction_successes', {}).items()},\n",
    "                'exhausted': td.get('exhausted', False)\n",
    "            }\n",
    "        return {\n",
    "            'visited_tiles': list(map_data['visited_tiles']),\n",
    "            'obstructions': list(map_data['obstructions']),\n",
    "            'interactable_objects': map_data['interactable_objects'],\n",
    "            'last_visited_timestep': map_data['last_visited_timestep'],\n",
    "            'transitions': map_data.get('transitions', []),\n",
    "            'temp_debt': map_data.get('temp_debt', 0.0),\n",
    "            'tile_interactions': serialized_ti\n",
    "        }\n",
    "\n",
    "    def get_current_map_memory(self, map_id):\n",
    "        if map_id not in self.exploration_memory:\n",
    "            self.exploration_memory[map_id] = {\n",
    "                'visited_tiles': set(), 'obstructions': set(), 'interactable_objects': [],\n",
    "                'last_visited_timestep': self.timestep, 'transitions': [], 'temp_debt': 0.0,\n",
    "                'tile_interactions': {}\n",
    "            }\n",
    "        return self.exploration_memory[map_id]\n",
    "\n",
    "    def record_visited_tile(self, x, y, map_id):\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        memory['visited_tiles'].add((int(x), int(y)))\n",
    "        memory['last_visited_timestep'] = self.timestep\n",
    "\n",
    "    def record_obstruction(self, x, y, map_id, direction):\n",
    "        dx, dy = self.DIRECTION_DELTAS_INT.get(direction, (0, 0))\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        memory['obstructions'].add((int(x + dx), int(y + dy)))\n",
    "\n",
    "    # =========================================================================\n",
    "    # TILE-BASED INTERACTION PROBING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def get_tile_interaction_key(self, x, y):\n",
    "        return f\"{int(x)}_{int(y)}\"\n",
    "    \n",
    "    def get_tile_interaction_state(self, x, y, map_id):\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        tile_key = self.get_tile_interaction_key(x, y)\n",
    "        if tile_key not in memory['tile_interactions']:\n",
    "            memory['tile_interactions'][tile_key] = {\n",
    "                'directions_tried': set(),\n",
    "                'direction_attempts': {0: 0, 1: 0, 2: 0, 3: 0},\n",
    "                'direction_successes': {0: 0, 1: 0, 2: 0, 3: 0},\n",
    "                'exhausted': False\n",
    "            }\n",
    "        return memory['tile_interactions'][tile_key]\n",
    "    \n",
    "    def should_interact_at_tile(self, x, y, map_id):\n",
    "        tile_state = self.get_tile_interaction_state(x, y, map_id)\n",
    "        if tile_state['exhausted']:\n",
    "            return False\n",
    "        if len(tile_state['directions_tried']) < 4:\n",
    "            return True\n",
    "        for d in range(4):\n",
    "            attempts = tile_state['direction_attempts'].get(d, 0)\n",
    "            successes = tile_state['direction_successes'].get(d, 0)\n",
    "            if attempts > 0 and successes / attempts >= self.MIN_SUCCESS_RATE_THRESHOLD:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_untried_directions(self, x, y, map_id):\n",
    "        tile_state = self.get_tile_interaction_state(x, y, map_id)\n",
    "        return [d for d in range(4) if d not in tile_state['directions_tried']]\n",
    "    \n",
    "    def get_best_interaction_direction(self, x, y, map_id):\n",
    "        tile_state = self.get_tile_interaction_state(x, y, map_id)\n",
    "        untried = self.get_untried_directions(x, y, map_id)\n",
    "        if untried:\n",
    "            return untried[0]\n",
    "        best_dir, best_rate = None, 0.0\n",
    "        for d in range(4):\n",
    "            attempts = tile_state['direction_attempts'].get(d, 0)\n",
    "            if attempts > 0:\n",
    "                rate = tile_state['direction_successes'].get(d, 0) / attempts\n",
    "                if rate > best_rate:\n",
    "                    best_rate, best_dir = rate, d\n",
    "        return best_dir\n",
    "    \n",
    "    def get_best_probe_action(self, raw_x, raw_y, current_map, current_dir):\n",
    "        cache_key = (raw_x, raw_y, current_map, current_dir)\n",
    "        \n",
    "        if self._probe_cache_position == cache_key:\n",
    "            return self._cached_probe_action, self._cached_probe_dir\n",
    "        \n",
    "        if not self.should_interact_at_tile(raw_x, raw_y, current_map):\n",
    "            result = (None, None)\n",
    "        else:\n",
    "            untried = self.get_untried_directions(raw_x, raw_y, current_map)\n",
    "            if not untried:\n",
    "                best_dir = self.get_best_interaction_direction(raw_x, raw_y, current_map)\n",
    "                if best_dir is not None:\n",
    "                    result = ('A', current_dir) if current_dir == best_dir else (self.INT_TO_ACTION[best_dir], best_dir)\n",
    "                else:\n",
    "                    result = (None, None)\n",
    "            elif current_dir in untried:\n",
    "                result = ('A', current_dir)\n",
    "            else:\n",
    "                target_dir = untried[0]\n",
    "                result = (self.INT_TO_ACTION[target_dir], target_dir)\n",
    "        \n",
    "        self._probe_cache_position = cache_key\n",
    "        self._cached_probe_action, self._cached_probe_dir = result\n",
    "        return result\n",
    "    \n",
    "    def record_tile_interaction_attempt(self, x, y, map_id, direction, success):\n",
    "        tile_state = self.get_tile_interaction_state(x, y, map_id)\n",
    "        tile_state['directions_tried'].add(direction)\n",
    "        tile_state['direction_attempts'][direction] = tile_state['direction_attempts'].get(direction, 0) + 1\n",
    "        if success:\n",
    "            tile_state['direction_successes'][direction] = tile_state['direction_successes'].get(direction, 0) + 1\n",
    "            memory = self.get_current_map_memory(map_id)\n",
    "            dir_name = self.DIRECTION_NAMES.get(direction, str(direction))\n",
    "            interactable = [int(x), int(y), dir_name]\n",
    "            if interactable not in memory['interactable_objects']:\n",
    "                memory['interactable_objects'].append(interactable)\n",
    "                print(f\"  üéØ INTERACTABLE FOUND: ({x}, {y}) facing {dir_name}\")\n",
    "        self._check_tile_exhaustion(x, y, map_id)\n",
    "    \n",
    "    def _check_tile_exhaustion(self, x, y, map_id):\n",
    "        tile_state = self.get_tile_interaction_state(x, y, map_id)\n",
    "        if len(tile_state['directions_tried']) < 4:\n",
    "            return\n",
    "        if not any(tile_state['direction_successes'].get(d, 0) > 0 for d in range(4)):\n",
    "            tile_state['exhausted'] = True\n",
    "            print(f\"  ‚úì Tile ({x}, {y}) exhausted - no interactions found\")\n",
    "    \n",
    "    def get_direction_success_rate(self, x, y, map_id, direction):\n",
    "        tile_state = self.get_tile_interaction_state(x, y, map_id)\n",
    "        attempts = tile_state['direction_attempts'].get(direction, 0)\n",
    "        if attempts == 0:\n",
    "            return None\n",
    "        return tile_state['direction_successes'].get(direction, 0) / attempts\n",
    "    \n",
    "    def start_interaction_verification(self, x, y, map_id, direction):\n",
    "        self.pending_interaction_verify = {'x': x, 'y': y, 'map_id': map_id, 'direction': direction}\n",
    "        self.interaction_verify_countdown = self.INTERACTION_VERIFY_FRAMES\n",
    "    \n",
    "    def check_interaction_verification(self, context_state, prev_context_state):\n",
    "        if self.pending_interaction_verify is None:\n",
    "            return\n",
    "        self.interaction_verify_countdown -= 1\n",
    "        success = False\n",
    "        if prev_context_state is not None:\n",
    "            in_overworld = prev_context_state[3] <= 0.5 and prev_context_state[4] <= 0.5\n",
    "            if in_overworld:\n",
    "                menu_changed = abs(context_state[4] - prev_context_state[4]) > 0.1\n",
    "                battle_started = context_state[3] > 0.5 and prev_context_state[3] <= 0.5\n",
    "                map_changed = int(context_state[2]) != int(prev_context_state[2])\n",
    "                success = menu_changed or battle_started or map_changed\n",
    "        if success or self.interaction_verify_countdown <= 0:\n",
    "            info = self.pending_interaction_verify\n",
    "            self.record_tile_interaction_attempt(info['x'], info['y'], info['map_id'], info['direction'], success)\n",
    "            self.pending_interaction_verify = None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3 PART 4: Transitions, Debt, Menu Trap, Navigation (with Cross-Map)\n",
    "# ============================================================================\n",
    "# CHANGES:\n",
    "# 1. Added build_map_graph() ‚Äî builds connectivity from transition data\n",
    "# 2. Added find_map_path() ‚Äî BFS across map graph\n",
    "# 3. Added get_transition_to_map() ‚Äî find the tile to reach a neighbor map\n",
    "# 4. Modified start_navigation() ‚Äî detects cross-map targets, builds chain\n",
    "# 5. Added advance_map_chain() ‚Äî called on map change during cross-map nav\n",
    "# 6. Added pause/resume logic for missing transitions\n",
    "# 7. Modified abort_navigation() ‚Äî clears cross-map state\n",
    "# 8. Modified on_map_change() ‚Äî triggers chain advancement\n",
    "# 9. record_transition() marks graph dirty\n",
    "# ============================================================================\n",
    "\n",
    "    # =========================================================================\n",
    "    # TRANSITION SYSTEM\n",
    "    # =========================================================================\n",
    "    \n",
    "    def record_transition(self, from_pos, from_map, to_map, direction, action_type):\n",
    "        memory = self.get_current_map_memory(from_map)\n",
    "        for t in memory['transitions']:\n",
    "            if t['position'] == from_pos and t['direction'] == direction:\n",
    "                t['use_count'] += 1\n",
    "                t['last_used'] = self.timestep\n",
    "                return\n",
    "        memory['transitions'].append({\n",
    "            'position': from_pos, 'direction': direction, 'action': action_type,\n",
    "            'destination_map': to_map, 'use_count': 1, 'last_used': self.timestep\n",
    "        })\n",
    "        # Mark graph dirty so it rebuilds with the new transition\n",
    "        self._map_graph_dirty = True\n",
    "        print(f\"  üö™ TRANSITION FOUND: Map {from_map} ({from_pos}) ‚Üí Map {to_map}\")\n",
    "\n",
    "    def get_transition_attraction(self, current_map):\n",
    "        memory = self.get_current_map_memory(current_map)\n",
    "        transitions = memory.get('transitions', [])\n",
    "        if not transitions:\n",
    "            return 0.0, None\n",
    "        current_debt = self.map_novelty_debt.get(current_map, 0.0)\n",
    "        current_temp_debt = self.get_temp_debt(current_map)\n",
    "        current_coverage = self.get_exploration_coverage(current_map)\n",
    "        best_attraction, best_transition = 0.0, None\n",
    "        for t in transitions:\n",
    "            if self.is_transition_banned(current_map, t['position'], t['direction']):\n",
    "                continue\n",
    "            dest_map = t['destination_map']\n",
    "            dest_debt = self.map_novelty_debt.get(dest_map, 0.0)\n",
    "            dest_temp_debt = self.get_temp_debt(dest_map)\n",
    "            dest_coverage = self.get_exploration_coverage(dest_map)\n",
    "            debt_diff = (current_debt + current_temp_debt * 2.0) - (dest_debt + dest_temp_debt * 2.0)\n",
    "            coverage_diff = current_coverage - dest_coverage\n",
    "            attraction = debt_diff * 0.5 + coverage_diff * 0.5\n",
    "            if t['use_count'] < 3:\n",
    "                attraction *= 1.5\n",
    "            if attraction > best_attraction:\n",
    "                best_attraction, best_transition = attraction, t\n",
    "        return best_attraction * self.TRANSITION_ATTRACTION_WEIGHT, best_transition\n",
    "\n",
    "    # =========================================================================\n",
    "    # TRANSITION BAN SYSTEM\n",
    "    # =========================================================================\n",
    "    \n",
    "    def create_transition_ban(self, map_id, tile_pos, direction_back):\n",
    "        self.transition_bans[map_id] = {\n",
    "            'banned_tile': tile_pos, 'banned_direction': direction_back,\n",
    "            'vicinity_radius': self.BAN_VICINITY_RADIUS, 'vicinity_active': False,\n",
    "            'created_at': self.timestep\n",
    "        }\n",
    "        print(f\"  üö´ TRANSITION BAN: Map {map_id} at {tile_pos} facing {self.DIRECTION_NAMES.get(direction_back, '?')}\")\n",
    "    \n",
    "    def is_transition_banned(self, map_id, position, direction):\n",
    "        if map_id not in self.transition_bans:\n",
    "            return False\n",
    "        ban = self.transition_bans[map_id]\n",
    "        banned_tile = tuple(ban['banned_tile']) if isinstance(ban['banned_tile'], list) else ban['banned_tile']\n",
    "        position = tuple(position) if isinstance(position, list) else position\n",
    "        if position == banned_tile and direction == ban['banned_direction']:\n",
    "            return True\n",
    "        if ban['vicinity_active']:\n",
    "            dist = abs(position[0] - banned_tile[0]) + abs(position[1] - banned_tile[1])\n",
    "            if dist <= ban['vicinity_radius'] and direction == ban['banned_direction']:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_position_banned(self, map_id, x, y, direction):\n",
    "        return self.is_transition_banned(map_id, (x, y), direction)\n",
    "    \n",
    "    def update_transition_ban(self, map_id, current_pos):\n",
    "        if map_id not in self.transition_bans:\n",
    "            return\n",
    "        ban = self.transition_bans[map_id]\n",
    "        banned_tile = tuple(ban['banned_tile']) if isinstance(ban['banned_tile'], list) else ban['banned_tile']\n",
    "        if not ban['vicinity_active'] and abs(current_pos[0] - banned_tile[0]) + abs(current_pos[1] - banned_tile[1]) >= 3:\n",
    "            ban['vicinity_active'] = True\n",
    "            print(f\"  üö´ VICINITY BAN ACTIVE: Map {map_id}\")\n",
    "    \n",
    "    def check_ban_lift_conditions(self, map_id):\n",
    "        if map_id not in self.transition_bans:\n",
    "            return\n",
    "        ban = self.transition_bans[map_id]\n",
    "        should_lift, reason = False, \"\"\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        non_banned = [t for t in memory.get('transitions', []) if not self.is_transition_banned(map_id, t['position'], t['direction'])]\n",
    "        if non_banned:\n",
    "            should_lift, reason = True, \"alternative transition found\"\n",
    "        elif self.get_exploration_coverage(map_id) >= self.BAN_COVERAGE_LIFT_THRESHOLD:\n",
    "            should_lift, reason = True, f\"coverage reached\"\n",
    "        elif self.timestep - ban['created_at'] >= self.BAN_TIMEOUT_STEPS:\n",
    "            should_lift, reason = True, \"timeout\"\n",
    "        if should_lift:\n",
    "            del self.transition_bans[map_id]\n",
    "            print(f\"  ‚úÖ BAN LIFTED: Map {map_id} - {reason}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # DEBT SYSTEMS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def get_temp_debt(self, map_id):\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        raw_debt = memory.get('temp_debt', 0.0)\n",
    "        if map_id != self.current_map_id:\n",
    "            steps_away = self.timestep - memory.get('last_visited_timestep', 0)\n",
    "            return max(0.0, raw_debt - steps_away * self.TEMP_DEBT_DECAY)\n",
    "        return raw_debt\n",
    "\n",
    "    def accumulate_temp_debt(self, map_id):\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        memory['temp_debt'] = min(self.TEMP_DEBT_MAX, memory.get('temp_debt', 0.0) + self.TEMP_DEBT_ACCUMULATION)\n",
    "\n",
    "    def decay_all_debts(self):\n",
    "        for map_id in list(self.map_novelty_debt.keys()):\n",
    "            if map_id != self.current_map_id:\n",
    "                self.map_novelty_debt[map_id] *= (1.0 - self.DEBT_DECAY_RATE)\n",
    "                if self.map_novelty_debt[map_id] < 0.1:\n",
    "                    del self.map_novelty_debt[map_id]\n",
    "        \n",
    "        current_loc = None\n",
    "        if self.current_map_id is not None and len(self.last_positions) > 0:\n",
    "            pos = self.last_positions[-1]\n",
    "            current_loc = self.get_location_key(pos[0], pos[1], self.current_map_id)\n",
    "        \n",
    "        for loc in list(self.location_novelty.keys()):\n",
    "            if loc != current_loc:\n",
    "                self.location_novelty[loc] *= (1.0 - self.DEBT_DECAY_RATE)\n",
    "                if self.location_novelty[loc] < 0.1:\n",
    "                    del self.location_novelty[loc]\n",
    "\n",
    "    def get_exploration_coverage(self, map_id):\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        visited = len(memory['visited_tiles'])\n",
    "        obstructions = len(memory['obstructions'])\n",
    "        if visited == 0 or visited + obstructions < 10:\n",
    "            return 0.0\n",
    "        return visited / (visited + obstructions)\n",
    "\n",
    "    def detect_obstruction(self, prev_context, context_state, raw_position, prev_raw_position):\n",
    "        if prev_context is None or prev_raw_position is None:\n",
    "            return False\n",
    "        if self.last_action not in ['UP', 'DOWN', 'LEFT', 'RIGHT']:\n",
    "            return False\n",
    "        if raw_position == prev_raw_position:\n",
    "            self.record_obstruction(raw_position[0], raw_position[1], int(context_state[2]), int(context_state[5]))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # =========================================================================\n",
    "    # MENU TRAP B-BOOST\n",
    "    # =========================================================================\n",
    "    \n",
    "    def update_menu_trap_tracking(self, context_state, action_taken, raw_position=None):\n",
    "        current_pos = raw_position if raw_position else (round(context_state[0] * 255), round(context_state[1] * 255))\n",
    "        if self.menu_trap_position is not None and current_pos != self.menu_trap_position:\n",
    "            self.reset_menu_trap_boost()\n",
    "            return\n",
    "        if self.get_context_state_hash(context_state) == self.last_context_state_hash:\n",
    "            if action_taken in [\"A\", \"B\", \"Start\", \"Select\"]:\n",
    "                self.menu_trap_frames += 1\n",
    "                self.menu_trap_position = current_pos\n",
    "                if self.menu_trap_frames > self.MENU_TRAP_THRESHOLD:\n",
    "                    if self.original_b_utility is None:\n",
    "                        for a in self.actions():\n",
    "                            if a.action == 'B':\n",
    "                                self.original_b_utility = a.utility\n",
    "                                break\n",
    "                    self.menu_trap_b_boost = min(self.B_BOOST_MAX, self.menu_trap_b_boost + self.B_BOOST_INCREMENT)\n",
    "        elif current_pos != self.menu_trap_position:\n",
    "            self.reset_menu_trap_boost()\n",
    "\n",
    "    def reset_menu_trap_boost(self):\n",
    "        if self.menu_trap_b_boost > 1.0 and self.original_b_utility is not None:\n",
    "            for a in self.actions():\n",
    "                if a.action == 'B':\n",
    "                    a.utility = self.original_b_utility\n",
    "                    break\n",
    "        self.menu_trap_frames = 0\n",
    "        self.menu_trap_b_boost = 1.0\n",
    "        self.menu_trap_position = None\n",
    "        self.original_b_utility = None\n",
    "\n",
    "    # =========================================================================\n",
    "    # STANDARD METHODS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def add(self, p):\n",
    "        self.perceptrons.append(p)\n",
    "        self._cache_valid = False\n",
    "\n",
    "    def actions(self):\n",
    "        return [p for p in self.perceptrons if p.kind == \"action\"]\n",
    "\n",
    "    def entities(self):\n",
    "        return [p for p in self.perceptrons if p.kind == \"entity\"]\n",
    "\n",
    "    def get_location_key(self, x, y, map_id, bin_size=5):\n",
    "        return (int(map_id), int(x // bin_size) * bin_size, int(y // bin_size) * bin_size)\n",
    "\n",
    "    def is_near_map_edge(self, x, y):\n",
    "        return x < 10 or x > 245 or y < 10 or y > 245\n",
    "\n",
    "    def record_action_execution(self, action_name):\n",
    "        if action_name:\n",
    "            self.action_execution_count[action_name] = self.action_execution_count.get(action_name, 0) + 1\n",
    "\n",
    "    def get_position_stagnation(self):\n",
    "        if len(self.last_positions) < 2:\n",
    "            return 0\n",
    "        current_pos = self.last_positions[-1]\n",
    "        return sum(1 for pos in reversed(list(self.last_positions)[:-1]) if pos == current_pos)\n",
    "\n",
    "    def get_group_weight(self, group):\n",
    "        return sum(a.utility for a in self.actions() if a.group == group)\n",
    "\n",
    "    # =========================================================================\n",
    "    # MAP CONNECTIVITY GRAPH\n",
    "    # =========================================================================\n",
    "\n",
    "    def build_map_graph(self):\n",
    "        \"\"\"\n",
    "        Build a connectivity graph from all known transitions across all maps.\n",
    "        \n",
    "        Graph structure: {map_id: [(dest_map_id, transition_dict), ...]}\n",
    "        \n",
    "        Each edge represents a known transition: walking from map_id through\n",
    "        the transition tile reaches dest_map_id. The transition_dict contains\n",
    "        position, direction, and other metadata needed to pathfind to it.\n",
    "        \n",
    "        Only rebuilds when _map_graph_dirty is True (set when new transitions found).\n",
    "        \"\"\"\n",
    "        if not self._map_graph_dirty:\n",
    "            return self._map_graph\n",
    "        \n",
    "        graph = {}\n",
    "        \n",
    "        for map_id, memory in self.exploration_memory.items():\n",
    "            edges = []\n",
    "            for t in memory.get('transitions', []):\n",
    "                dest = t.get('destination_map')\n",
    "                if dest is not None:\n",
    "                    edges.append((dest, t))\n",
    "            if edges:\n",
    "                graph[map_id] = edges\n",
    "        \n",
    "        self._map_graph = graph\n",
    "        self._map_graph_dirty = False\n",
    "        \n",
    "        return graph\n",
    "\n",
    "    def find_map_path(self, from_map, to_map):\n",
    "        \"\"\"\n",
    "        BFS on the map connectivity graph to find shortest chain of maps\n",
    "        from from_map to to_map.\n",
    "        \n",
    "        Returns: list of map_ids [from_map, intermediate_1, ..., to_map]\n",
    "                 or [] if no path exists.\n",
    "        \"\"\"\n",
    "        if from_map == to_map:\n",
    "            return [from_map]\n",
    "        \n",
    "        graph = self.build_map_graph()\n",
    "        \n",
    "        if from_map not in graph:\n",
    "            return []\n",
    "        \n",
    "        # BFS\n",
    "        from collections import deque as bfs_deque\n",
    "        queue = bfs_deque([(from_map, [from_map])])\n",
    "        visited = {from_map}\n",
    "        \n",
    "        while queue:\n",
    "            current, path = queue.popleft()\n",
    "            \n",
    "            for dest_map, _ in graph.get(current, []):\n",
    "                if dest_map == to_map:\n",
    "                    return path + [dest_map]\n",
    "                \n",
    "                if dest_map not in visited:\n",
    "                    visited.add(dest_map)\n",
    "                    queue.append((dest_map, path + [dest_map]))\n",
    "        \n",
    "        return []\n",
    "\n",
    "    def get_transition_to_map(self, from_map, to_map):\n",
    "        \"\"\"\n",
    "        Find the best transition tile on from_map that leads to to_map.\n",
    "        \n",
    "        Returns: transition dict (with 'position', 'direction', etc.) or None.\n",
    "        \n",
    "        If multiple transitions lead to the same destination, picks the one\n",
    "        with highest use_count (most reliable).\n",
    "        \"\"\"\n",
    "        memory = self.get_current_map_memory(from_map)\n",
    "        \n",
    "        best_transition = None\n",
    "        best_use_count = -1\n",
    "        \n",
    "        for t in memory.get('transitions', []):\n",
    "            if t.get('destination_map') == to_map:\n",
    "                # Skip banned transitions\n",
    "                pos = tuple(t['position']) if isinstance(t['position'], list) else t['position']\n",
    "                if self.is_transition_banned(from_map, pos, t['direction']):\n",
    "                    continue\n",
    "                \n",
    "                use_count = t.get('use_count', 0)\n",
    "                if use_count > best_use_count:\n",
    "                    best_use_count = use_count\n",
    "                    best_transition = t\n",
    "        \n",
    "        return best_transition\n",
    "\n",
    "    def get_cross_map_status(self):\n",
    "        \"\"\"Return status dict for logging.\"\"\"\n",
    "        if not self.nav_map_chain:\n",
    "            return {'active': False}\n",
    "        \n",
    "        return {\n",
    "            'active': True,\n",
    "            'chain': self.nav_map_chain,\n",
    "            'chain_index': self.nav_chain_index,\n",
    "            'chain_length': len(self.nav_map_chain),\n",
    "            'current_map': self.nav_map_chain[self.nav_chain_index] if self.nav_chain_index < len(self.nav_map_chain) else None,\n",
    "            'target_map': self.nav_map_chain[-1] if self.nav_map_chain else None,\n",
    "            'final_target': self.nav_cross_map_target,\n",
    "            'paused': self.nav_paused,\n",
    "            'paused_reason': self.nav_paused_reason\n",
    "        }\n",
    "\n",
    "    # =========================================================================\n",
    "    # NAVIGATION SYSTEM - A* Pathfinding + Cross-Map + Taught Targets\n",
    "    # =========================================================================\n",
    "    \n",
    "    def load_taught_nav_targets(self, filepath=None):\n",
    "        \"\"\"Load human-curated navigation targets from taught_nav_targets.json.\"\"\"\n",
    "        filepath = filepath or TAUGHT_NAV_TARGETS_FILE\n",
    "        try:\n",
    "            if Path(filepath).exists():\n",
    "                with open(filepath, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                self.taught_nav_targets = {}\n",
    "                for map_key, targets in data.get('targets_by_map', {}).items():\n",
    "                    map_id = int(map_key)\n",
    "                    self.taught_nav_targets[map_id] = targets\n",
    "                \n",
    "                self.taught_nav_global_order = data.get('global_order', [])\n",
    "                self.taught_nav_loaded = True\n",
    "                \n",
    "                total = sum(len(t) for t in self.taught_nav_targets.values())\n",
    "                maps = list(self.taught_nav_targets.keys())\n",
    "                print(f\"  üéØ Loaded taught nav targets:\")\n",
    "                print(f\"     Total targets: {total}\")\n",
    "                print(f\"     Maps with targets: {maps}\")\n",
    "                print(f\"     Global order entries: {len(self.taught_nav_global_order)}\")\n",
    "            else:\n",
    "                self.taught_nav_targets = {}\n",
    "                self.taught_nav_global_order = []\n",
    "                self.taught_nav_loaded = False\n",
    "                print(f\"  No taught nav targets found at {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading taught nav targets: {e}\")\n",
    "            self.taught_nav_targets = {}\n",
    "            self.taught_nav_global_order = []\n",
    "            self.taught_nav_loaded = False\n",
    "\n",
    "    def _astar(self, start, goal, map_id):\n",
    "        \"\"\"A* pathfinding on visited_tiles grid, avoiding obstructions.\"\"\"\n",
    "        import heapq\n",
    "        \n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        visited_tiles = memory['visited_tiles']\n",
    "        obstructions = memory['obstructions']\n",
    "        \n",
    "        start = (int(start[0]), int(start[1]))\n",
    "        goal = (int(goal[0]), int(goal[1]))\n",
    "        \n",
    "        if start not in visited_tiles:\n",
    "            return []\n",
    "        \n",
    "        if goal not in visited_tiles:\n",
    "            best_adj = None\n",
    "            best_dist = float('inf')\n",
    "            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "                adj = (goal[0] + dx, goal[1] + dy)\n",
    "                if adj in visited_tiles and adj not in obstructions:\n",
    "                    d = abs(adj[0] - start[0]) + abs(adj[1] - start[1])\n",
    "                    if d < best_dist:\n",
    "                        best_dist = d\n",
    "                        best_adj = adj\n",
    "            if best_adj is None:\n",
    "                return []\n",
    "            goal = best_adj\n",
    "        \n",
    "        if start == goal:\n",
    "            return [start]\n",
    "        \n",
    "        open_set = [(abs(goal[0] - start[0]) + abs(goal[1] - start[1]), 0, start)]\n",
    "        came_from = {}\n",
    "        g_score = {start: 0}\n",
    "        closed = set()\n",
    "        \n",
    "        while open_set:\n",
    "            f, g, current = heapq.heappop(open_set)\n",
    "            \n",
    "            if current == goal:\n",
    "                path = [current]\n",
    "                while current in came_from:\n",
    "                    current = came_from[current]\n",
    "                    path.append(current)\n",
    "                path.reverse()\n",
    "                return path\n",
    "            \n",
    "            if current in closed:\n",
    "                continue\n",
    "            closed.add(current)\n",
    "            \n",
    "            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "                neighbor = (current[0] + dx, current[1] + dy)\n",
    "                if neighbor in closed or neighbor not in visited_tiles or neighbor in obstructions:\n",
    "                    continue\n",
    "                new_g = g + 1\n",
    "                if new_g < g_score.get(neighbor, float('inf')):\n",
    "                    g_score[neighbor] = new_g\n",
    "                    h = abs(goal[0] - neighbor[0]) + abs(goal[1] - neighbor[1])\n",
    "                    came_from[neighbor] = current\n",
    "                    heapq.heappush(open_set, (new_g + h, new_g, neighbor))\n",
    "        \n",
    "        return []\n",
    "\n",
    "    def _get_frontier_tiles(self, map_id):\n",
    "        \"\"\"Find unvisited tiles adjacent to visited tiles (fallback targets).\"\"\"\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        visited = memory['visited_tiles']\n",
    "        obstructions = memory['obstructions']\n",
    "        \n",
    "        frontier = set()\n",
    "        for vx, vy in visited:\n",
    "            for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "                neighbor = (vx + dx, vy + dy)\n",
    "                if neighbor not in visited and neighbor not in obstructions:\n",
    "                    if 0 <= neighbor[0] <= 255 and 0 <= neighbor[1] <= 255:\n",
    "                        frontier.add(neighbor)\n",
    "        return list(frontier)\n",
    "\n",
    "    def _score_nav_target(self, target, current_pos, map_id):\n",
    "        \"\"\"Score a fallback navigation target by novelty potential.\"\"\"\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        visited = memory['visited_tiles']\n",
    "        obstructions = memory['obstructions']\n",
    "        tx, ty = target\n",
    "        \n",
    "        unvisited_neighbors = 0\n",
    "        for dx, dy in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
    "            n = (tx + dx, ty + dy)\n",
    "            if n not in visited and n not in obstructions:\n",
    "                if 0 <= n[0] <= 255 and 0 <= n[1] <= 255:\n",
    "                    unvisited_neighbors += 1\n",
    "        \n",
    "        score = unvisited_neighbors * 2.0\n",
    "        dist = abs(current_pos[0] - tx) + abs(current_pos[1] - ty)\n",
    "        score -= dist * 0.05\n",
    "        if target in self.nav_struck_targets:\n",
    "            score -= 100.0\n",
    "        return score\n",
    "\n",
    "    def _get_taught_targets_for_map(self, map_id, current_pos):\n",
    "        \"\"\"Get unvisited taught nav targets for current map, sorted by nearest.\"\"\"\n",
    "        if not self.taught_nav_loaded:\n",
    "            return []\n",
    "        \n",
    "        map_targets = self.taught_nav_targets.get(map_id, [])\n",
    "        if not map_targets:\n",
    "            return []\n",
    "        \n",
    "        candidates = []\n",
    "        for t in map_targets:\n",
    "            order = t.get('order', 0)\n",
    "            if order in self.nav_visited_targets:\n",
    "                continue\n",
    "            pos = tuple(t['position'])\n",
    "            if pos in self.nav_struck_targets:\n",
    "                continue\n",
    "            dist = abs(current_pos[0] - pos[0]) + abs(current_pos[1] - pos[1])\n",
    "            candidates.append((pos, t, dist))\n",
    "        \n",
    "        candidates.sort(key=lambda x: x[2])\n",
    "        return [(pos, t) for pos, t, dist in candidates]\n",
    "\n",
    "    def _get_next_taught_target_any_map(self, current_pos, current_map):\n",
    "        \"\"\"\n",
    "        Find the next unvisited taught target across ALL maps.\n",
    "        Uses global_order to find the lowest-order unvisited target.\n",
    "        \n",
    "        Returns: (position, target_data, target_map_id) or (None, None, None)\n",
    "        \"\"\"\n",
    "        if not self.taught_nav_loaded or not self.taught_nav_global_order:\n",
    "            return None, None, None\n",
    "        \n",
    "        for entry in self.taught_nav_global_order:\n",
    "            order = entry.get('order', -1)\n",
    "            if order in self.nav_visited_targets:\n",
    "                continue\n",
    "            \n",
    "            target_map = entry.get('map_id')\n",
    "            pos = tuple(entry.get('position', [0, 0]))\n",
    "            \n",
    "            if pos in self.nav_struck_targets:\n",
    "                continue\n",
    "            \n",
    "            # Find full target data from the per-map list\n",
    "            target_data = entry\n",
    "            for t in self.taught_nav_targets.get(target_map, []):\n",
    "                if t.get('order') == order:\n",
    "                    target_data = t\n",
    "                    break\n",
    "            \n",
    "            return pos, target_data, target_map\n",
    "        \n",
    "        return None, None, None\n",
    "\n",
    "    def build_nav_target_list(self, current_pos, map_id):\n",
    "        \"\"\"\n",
    "        Build ranked target list.\n",
    "        Priority: \n",
    "          1. Taught targets on current map (nearest unvisited)\n",
    "          2. Taught targets on other maps (via cross-map nav)\n",
    "          3. Fallback: frontier tiles + transitions on current map\n",
    "        \"\"\"\n",
    "        targets = []\n",
    "        \n",
    "        # === PRIMARY: Taught nav targets on current map ===\n",
    "        taught_targets = self._get_taught_targets_for_map(map_id, current_pos)\n",
    "        \n",
    "        if taught_targets:\n",
    "            for pos, t_data in taught_targets:\n",
    "                dist = abs(current_pos[0] - pos[0]) + abs(current_pos[1] - pos[1])\n",
    "                score = t_data.get('forward_progress_score', 0.5) * 10.0\n",
    "                score -= dist * 0.02\n",
    "                progress_type = t_data.get('progress_type', 'unknown')\n",
    "                targets.append((pos, score, f\"taught_{progress_type}\", map_id))\n",
    "            \n",
    "            targets.sort(key=lambda x: x[1], reverse=True)\n",
    "            return targets\n",
    "        \n",
    "        # === SECONDARY: Taught targets on OTHER maps (cross-map) ===\n",
    "        cross_pos, cross_data, cross_map = self._get_next_taught_target_any_map(current_pos, map_id)\n",
    "        \n",
    "        if cross_pos is not None and cross_map is not None and cross_map != map_id:\n",
    "            # Check if we can reach that map\n",
    "            map_path = self.find_map_path(map_id, cross_map)\n",
    "            \n",
    "            if map_path and len(map_path) > 1:\n",
    "                # We have a path ‚Äî the immediate target is the transition to the next map\n",
    "                next_map = map_path[1]\n",
    "                transition = self.get_transition_to_map(map_id, next_map)\n",
    "                \n",
    "                if transition:\n",
    "                    t_pos = tuple(transition['position']) if isinstance(transition['position'], list) else transition['position']\n",
    "                    score = 15.0  # High priority ‚Äî cross-map progress\n",
    "                    score -= len(map_path) * 0.5  # Slight penalty for longer chains\n",
    "                    targets.append((t_pos, score, f\"cross_map_to_{cross_map}\", cross_map))\n",
    "                    \n",
    "                    # Store cross-map context for start_navigation to use\n",
    "                    self._pending_cross_map = {\n",
    "                        'final_target': cross_pos,\n",
    "                        'final_map': cross_map,\n",
    "                        'target_data': cross_data,\n",
    "                        'map_chain': map_path,\n",
    "                        'transition': transition\n",
    "                    }\n",
    "                    \n",
    "                    targets.sort(key=lambda x: x[1], reverse=True)\n",
    "                    return targets\n",
    "            \n",
    "            elif not map_path:\n",
    "                # No path exists yet ‚Äî will pause and explore when navigation starts\n",
    "                # Still add the target so start_navigation can detect the cross-map need\n",
    "                targets.append(((0, 0), 5.0, f\"cross_map_need_{cross_map}\", cross_map))\n",
    "                self._pending_cross_map = {\n",
    "                    'final_target': cross_pos,\n",
    "                    'final_map': cross_map,\n",
    "                    'target_data': cross_data,\n",
    "                    'map_chain': [],\n",
    "                    'transition': None\n",
    "                }\n",
    "                return targets\n",
    "        \n",
    "        # === FALLBACK: Frontier tiles + transitions on current map ===\n",
    "        frontier = self._get_frontier_tiles(map_id)\n",
    "        for ft in frontier:\n",
    "            score = self._score_nav_target(ft, current_pos, map_id)\n",
    "            targets.append((ft, score, 'frontier', map_id))\n",
    "        \n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        for t in memory.get('transitions', []):\n",
    "            t_pos = tuple(t['position']) if isinstance(t['position'], list) else t['position']\n",
    "            if self.is_transition_banned(map_id, t_pos, t['direction']):\n",
    "                continue\n",
    "            score = self._score_nav_target(t_pos, current_pos, map_id)\n",
    "            dest_coverage = self.get_exploration_coverage(t['destination_map'])\n",
    "            score += 3.0 * (1.0 - dest_coverage)\n",
    "            if t_pos not in self.nav_struck_targets:\n",
    "                targets.append((t_pos, score, 'transition', map_id))\n",
    "        \n",
    "        targets.sort(key=lambda x: x[1], reverse=True)\n",
    "        return targets\n",
    "\n",
    "    def start_navigation(self, current_pos, map_id):\n",
    "        \"\"\"\n",
    "        Initialize navigation mode. Build target list, path to first target.\n",
    "        Handles both same-map and cross-map targets.\n",
    "        \"\"\"\n",
    "        self._pending_cross_map = None  # Reset before building\n",
    "        self.nav_target_list = self.build_nav_target_list(current_pos, map_id)\n",
    "        \n",
    "        if not self.nav_target_list:\n",
    "            return False\n",
    "        \n",
    "        # Check if build_nav_target_list set up a cross-map context\n",
    "        if self._pending_cross_map:\n",
    "            cross = self._pending_cross_map\n",
    "            self._pending_cross_map = None\n",
    "            \n",
    "            if cross['map_chain'] and cross['transition']:\n",
    "                # We have a valid path across maps\n",
    "                self.nav_map_chain = cross['map_chain']\n",
    "                self.nav_chain_index = 0\n",
    "                self.nav_cross_map_target = cross['final_target']\n",
    "                self.nav_cross_map_target_data = cross['target_data']\n",
    "                self.nav_paused = False\n",
    "                \n",
    "                # A* to the transition tile on current map\n",
    "                t_pos = tuple(cross['transition']['position']) if isinstance(cross['transition']['position'], list) else cross['transition']['position']\n",
    "                path = self._astar(current_pos, t_pos, map_id)\n",
    "                \n",
    "                if path and len(path) > 1:\n",
    "                    self.nav_active = True\n",
    "                    self.nav_path = path\n",
    "                    self.nav_path_index = 1\n",
    "                    self.nav_target = t_pos\n",
    "                    self.nav_steps_taken = 0\n",
    "                    self.nav_stagnation_count = 0\n",
    "                    self.nav_last_position = current_pos\n",
    "                    self.nav_curiosity_countdown = 0\n",
    "                    \n",
    "                    chain_str = ' ‚Üí '.join(str(m) for m in self.nav_map_chain)\n",
    "                    print(f\"  üß≠üåç CROSS-MAP NAV START: {chain_str}\")\n",
    "                    print(f\"     Final target: ({cross['final_target'][0]}, {cross['final_target'][1]}) on map {cross['final_map']}\")\n",
    "                    print(f\"     Immediate: ‚Üí transition at ({t_pos[0]}, {t_pos[1]}) ‚Üí map {self.nav_map_chain[1]}\")\n",
    "                    self.nav_cross_map_refresh_countdown = self.NAV_CROSS_MAP_REFRESH_INTERVAL\n",
    "                    return True\n",
    "                else:\n",
    "                    # Can't reach the transition tile ‚Äî abort cross-map\n",
    "                    self._clear_cross_map_state()\n",
    "                    \n",
    "            elif not cross['map_chain']:\n",
    "                # No path exists ‚Äî pause navigation and explore\n",
    "                self.nav_map_chain = []\n",
    "                self.nav_chain_index = 0\n",
    "                self.nav_cross_map_target = cross['final_target']\n",
    "                self.nav_cross_map_target_data = cross['target_data']\n",
    "                self.nav_paused = True\n",
    "                self.nav_paused_reason = f\"no path to map {cross['final_map']}\"\n",
    "                self.nav_paused_target_map = cross['final_map']\n",
    "                self.nav_pause_check_countdown = self.NAV_PAUSE_CHECK_INTERVAL\n",
    "                self.nav_active = True  # Keep nav \"active\" but paused\n",
    "                \n",
    "                print(f\"  üß≠‚è∏Ô∏è CROSS-MAP NAV PAUSED: no path to map {cross['final_map']}\")\n",
    "                print(f\"     Exploring to find transitions...\")\n",
    "                return True  # Return True so exploration runs\n",
    "        \n",
    "        # Standard same-map navigation\n",
    "        self.nav_target_index = 0\n",
    "        return self._navigate_to_next_target(current_pos, map_id)\n",
    "\n",
    "    def advance_map_chain(self, new_map_id, current_pos):\n",
    "        \"\"\"\n",
    "        Called when map changes during cross-map navigation.\n",
    "        Advances to the next step in the chain and sets up A* on the new map.\n",
    "        \n",
    "        Returns True if navigation continues, False if chain is complete or broken.\n",
    "        \"\"\"\n",
    "        if not self.nav_map_chain:\n",
    "            return False\n",
    "        \n",
    "        # Find where we are in the chain\n",
    "        new_index = None\n",
    "        for i, chain_map in enumerate(self.nav_map_chain):\n",
    "            if chain_map == new_map_id:\n",
    "                new_index = i\n",
    "                break\n",
    "        \n",
    "        if new_index is None:\n",
    "            # We ended up on a map not in the chain ‚Äî chain is broken\n",
    "            print(f\"  üß≠üåç CROSS-MAP: landed on unexpected map {new_map_id}, aborting chain\")\n",
    "            self._clear_cross_map_state()\n",
    "            return False\n",
    "        \n",
    "        self.nav_chain_index = new_index\n",
    "        \n",
    "        # Are we on the final map?\n",
    "        if new_map_id == self.nav_map_chain[-1]:\n",
    "            # We've arrived at the target map ‚Äî now A* to the actual target\n",
    "            if self.nav_cross_map_target:\n",
    "                target_pos = self.nav_cross_map_target\n",
    "                path = self._astar(current_pos, target_pos, new_map_id)\n",
    "                \n",
    "                if path and len(path) > 1:\n",
    "                    self.nav_path = path\n",
    "                    self.nav_path_index = 1\n",
    "                    self.nav_target = target_pos\n",
    "                    self.nav_steps_taken = 0\n",
    "                    self.nav_stagnation_count = 0\n",
    "                    self.nav_last_position = current_pos\n",
    "                    \n",
    "                    print(f\"  üß≠üåç CROSS-MAP FINAL: arrived at map {new_map_id}, \"\n",
    "                          f\"pathfinding to ({target_pos[0]}, {target_pos[1]})\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"  üß≠üåç CROSS-MAP: can't reach target on final map {new_map_id}\")\n",
    "                    self._clear_cross_map_state()\n",
    "                    return False\n",
    "            else:\n",
    "                self._clear_cross_map_state()\n",
    "                return False\n",
    "        \n",
    "        # We're on an intermediate map ‚Äî find transition to next map in chain\n",
    "        next_map = self.nav_map_chain[new_index + 1]\n",
    "        transition = self.get_transition_to_map(new_map_id, next_map)\n",
    "        \n",
    "        if transition:\n",
    "            t_pos = tuple(transition['position']) if isinstance(transition['position'], list) else transition['position']\n",
    "            path = self._astar(current_pos, t_pos, new_map_id)\n",
    "            \n",
    "            if path and len(path) > 1:\n",
    "                self.nav_path = path\n",
    "                self.nav_path_index = 1\n",
    "                self.nav_target = t_pos\n",
    "                self.nav_steps_taken = 0\n",
    "                self.nav_stagnation_count = 0\n",
    "                self.nav_last_position = current_pos\n",
    "                \n",
    "                remaining = len(self.nav_map_chain) - new_index - 1\n",
    "                print(f\"  üß≠üåç CROSS-MAP STEP: map {new_map_id} ‚Üí transition to map {next_map} \"\n",
    "                      f\"({remaining} maps remaining)\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"  üß≠üåç CROSS-MAP: can't reach transition on map {new_map_id}\")\n",
    "                # Pause ‚Äî maybe we need to explore this map more\n",
    "                self.nav_paused = True\n",
    "                self.nav_paused_reason = f\"can't reach transition to map {next_map}\"\n",
    "                self.nav_paused_target_map = next_map\n",
    "                self.nav_pause_check_countdown = self.NAV_PAUSE_CHECK_INTERVAL\n",
    "                return True\n",
    "        else:\n",
    "            # No transition found to next map from here\n",
    "            print(f\"  üß≠üåç CROSS-MAP: no transition from map {new_map_id} to map {next_map}\")\n",
    "            self.nav_paused = True\n",
    "            self.nav_paused_reason = f\"no transition to map {next_map}\"\n",
    "            self.nav_paused_target_map = next_map\n",
    "            self.nav_pause_check_countdown = self.NAV_PAUSE_CHECK_INTERVAL\n",
    "            return True\n",
    "\n",
    "    def check_nav_pause_resume(self, current_pos, map_id):\n",
    "        \"\"\"\n",
    "        Called periodically when nav is paused. Checks if new transitions\n",
    "        have been discovered that allow resuming cross-map navigation.\n",
    "        \n",
    "        Returns True if navigation resumed, False if still paused.\n",
    "        \"\"\"\n",
    "        if not self.nav_paused:\n",
    "            return False\n",
    "        \n",
    "        self.nav_pause_check_countdown -= 1\n",
    "        if self.nav_pause_check_countdown > 0:\n",
    "            return False\n",
    "        \n",
    "        self.nav_pause_check_countdown = self.NAV_PAUSE_CHECK_INTERVAL\n",
    "        \n",
    "        target_map = self.nav_paused_target_map\n",
    "        if target_map is None:\n",
    "            return False\n",
    "        \n",
    "        # Rebuild graph with any new transitions\n",
    "        self._map_graph_dirty = True\n",
    "        \n",
    "        # Check if we now have a path to the final target map\n",
    "        final_map = self.nav_map_chain[-1] if self.nav_map_chain else target_map\n",
    "        if self.nav_cross_map_target_data:\n",
    "            final_map_from_data = None\n",
    "            # Try to get the map from global order\n",
    "            for entry in self.taught_nav_global_order:\n",
    "                if tuple(entry.get('position', [])) == self.nav_cross_map_target:\n",
    "                    final_map_from_data = entry.get('map_id')\n",
    "                    break\n",
    "            if final_map_from_data:\n",
    "                final_map = final_map_from_data\n",
    "        \n",
    "        new_path = self.find_map_path(map_id, final_map)\n",
    "        \n",
    "        if new_path and len(new_path) > 1:\n",
    "            # Path found ‚Äî resume navigation\n",
    "            self.nav_map_chain = new_path\n",
    "            self.nav_chain_index = 0\n",
    "            self.nav_paused = False\n",
    "            self.nav_paused_reason = \"\"\n",
    "            self.nav_paused_target_map = None\n",
    "            \n",
    "            # Set up A* to the transition tile for the next map\n",
    "            next_map = new_path[1]\n",
    "            transition = self.get_transition_to_map(map_id, next_map)\n",
    "            \n",
    "            if transition:\n",
    "                t_pos = tuple(transition['position']) if isinstance(transition['position'], list) else transition['position']\n",
    "                path = self._astar(current_pos, t_pos, map_id)\n",
    "                \n",
    "                if path and len(path) > 1:\n",
    "                    self.nav_path = path\n",
    "                    self.nav_path_index = 1\n",
    "                    self.nav_target = t_pos\n",
    "                    self.nav_steps_taken = 0\n",
    "                    self.nav_stagnation_count = 0\n",
    "                    self.nav_last_position = current_pos\n",
    "                    \n",
    "                    chain_str = ' ‚Üí '.join(str(m) for m in new_path)\n",
    "                    print(f\"  üß≠‚ñ∂Ô∏è CROSS-MAP NAV RESUMED: {chain_str}\")\n",
    "                    return True\n",
    "            \n",
    "            # Have the path but can't reach the transition yet\n",
    "            self.nav_paused = True\n",
    "            self.nav_paused_reason = f\"can't reach transition to map {next_map}\"\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def refresh_cross_map_navigation(self, current_pos, current_map):\n",
    "        \"\"\"\n",
    "        Periodic recalculation of cross-map path from current position.\n",
    "        Handles: wrong map, new transitions discovered, agent drifted off course.\n",
    "        \n",
    "        Called every NAV_CROSS_MAP_REFRESH_INTERVAL steps during active cross-map nav.\n",
    "        \n",
    "        Returns True if navigation was successfully refreshed, False if broken.\n",
    "        \"\"\"\n",
    "        if not self.nav_cross_map_target:\n",
    "            return False\n",
    "        \n",
    "        final_target = self.nav_cross_map_target\n",
    "        \n",
    "        # Find the final map from the chain or from target data\n",
    "        final_map = self.nav_map_chain[-1] if self.nav_map_chain else None\n",
    "        if final_map is None:\n",
    "            return False\n",
    "        \n",
    "        # Are we already on the final map?\n",
    "        if current_map == final_map:\n",
    "            # Just re-A* to the actual target\n",
    "            path = self._astar(current_pos, final_target, current_map)\n",
    "            if path and len(path) > 1:\n",
    "                self.nav_path = path\n",
    "                self.nav_path_index = 1\n",
    "                self.nav_target = final_target\n",
    "                self.nav_stagnation_count = 0\n",
    "                self.nav_last_position = current_pos\n",
    "                self.nav_paused = False\n",
    "                print(f\"  üß≠üîÑ CROSS-MAP REFRESH: on final map {current_map}, re-pathing to target\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"  üß≠üîÑ CROSS-MAP REFRESH: on final map but can't reach target\")\n",
    "                return False\n",
    "        \n",
    "        # Rebuild map graph (picks up any new transitions)\n",
    "        self._map_graph_dirty = True\n",
    "        new_chain = self.find_map_path(current_map, final_map)\n",
    "        \n",
    "        if not new_chain:\n",
    "            # No path from here ‚Äî pause and explore\n",
    "            self.nav_map_chain = [current_map]  # At least know where we are\n",
    "            self.nav_chain_index = 0\n",
    "            self.nav_paused = True\n",
    "            self.nav_paused_reason = f\"refresh: no path from map {current_map} to map {final_map}\"\n",
    "            self.nav_paused_target_map = final_map\n",
    "            self.nav_pause_check_countdown = self.NAV_PAUSE_CHECK_INTERVAL\n",
    "            print(f\"  üß≠üîÑ CROSS-MAP REFRESH: no path from {current_map} to {final_map}, pausing\")\n",
    "            return True  # Still \"active\" but paused\n",
    "        \n",
    "        # Update the chain\n",
    "        old_chain = self.nav_map_chain\n",
    "        self.nav_map_chain = new_chain\n",
    "        self.nav_chain_index = 0\n",
    "        \n",
    "        # A* to the transition for the next map in the new chain\n",
    "        next_map = new_chain[1]\n",
    "        transition = self.get_transition_to_map(current_map, next_map)\n",
    "        \n",
    "        if transition:\n",
    "            t_pos = tuple(transition['position']) if isinstance(transition['position'], list) else transition['position']\n",
    "            path = self._astar(current_pos, t_pos, current_map)\n",
    "            \n",
    "            if path and len(path) > 1:\n",
    "                self.nav_path = path\n",
    "                self.nav_path_index = 1\n",
    "                self.nav_target = t_pos\n",
    "                self.nav_stagnation_count = 0\n",
    "                self.nav_last_position = current_pos\n",
    "                self.nav_paused = False\n",
    "                \n",
    "                old_str = ' ‚Üí '.join(str(m) for m in old_chain)\n",
    "                new_str = ' ‚Üí '.join(str(m) for m in new_chain)\n",
    "                if old_chain != new_chain:\n",
    "                    print(f\"  üß≠üîÑ CROSS-MAP REFRESH: chain updated {old_str} ‚Üí {new_str}\")\n",
    "                else:\n",
    "                    print(f\"  üß≠üîÑ CROSS-MAP REFRESH: re-pathed on map {current_map}\")\n",
    "                return True\n",
    "            else:\n",
    "                # Can't reach transition ‚Äî pause\n",
    "                self.nav_paused = True\n",
    "                self.nav_paused_reason = f\"refresh: can't reach transition to map {next_map}\"\n",
    "                self.nav_paused_target_map = next_map\n",
    "                self.nav_pause_check_countdown = self.NAV_PAUSE_CHECK_INTERVAL\n",
    "                print(f\"  üß≠üîÑ CROSS-MAP REFRESH: can't reach transition to {next_map}, pausing\")\n",
    "                return True\n",
    "        else:\n",
    "            self.nav_paused = True\n",
    "            self.nav_paused_reason = f\"refresh: no transition to map {next_map}\"\n",
    "            self.nav_paused_target_map = next_map\n",
    "            self.nav_pause_check_countdown = self.NAV_PAUSE_CHECK_INTERVAL\n",
    "            print(f\"  üß≠üîÑ CROSS-MAP REFRESH: no transition to {next_map}, pausing\")\n",
    "            return True\n",
    "\n",
    "    def _clear_cross_map_state(self):\n",
    "        \"\"\"Reset all cross-map navigation state.\"\"\"\n",
    "        self.nav_map_chain = []\n",
    "        self.nav_chain_index = 0\n",
    "        self.nav_cross_map_target = None\n",
    "        self.nav_cross_map_target_data = None\n",
    "        self.nav_paused = False\n",
    "        self.nav_paused_reason = \"\"\n",
    "        self.nav_paused_target_map = None\n",
    "        self.nav_pause_check_countdown = 0\n",
    "        self.nav_cross_map_refresh_countdown = 0\n",
    "\n",
    "    def _navigate_to_next_target(self, current_pos, map_id):\n",
    "        \"\"\"Try to path to the next target in the list.\"\"\"\n",
    "        while self.nav_target_index < len(self.nav_target_list):\n",
    "            entry = self.nav_target_list[self.nav_target_index]\n",
    "            target = entry[0]\n",
    "            score = entry[1]\n",
    "            target_type = entry[2]\n",
    "            target_map = entry[3] if len(entry) > 3 else map_id\n",
    "            \n",
    "            if target in self.nav_struck_targets:\n",
    "                self.nav_target_index += 1\n",
    "                continue\n",
    "            \n",
    "            # Skip cross-map placeholder targets\n",
    "            if target_type.startswith('cross_map_need'):\n",
    "                self.nav_target_index += 1\n",
    "                continue\n",
    "            \n",
    "            path = self._astar(current_pos, target, map_id)\n",
    "            \n",
    "            if path and len(path) > 1:\n",
    "                self.nav_active = True\n",
    "                self.nav_path = path\n",
    "                self.nav_path_index = 1\n",
    "                self.nav_target = target\n",
    "                self.nav_steps_taken = 0\n",
    "                self.nav_stagnation_count = 0\n",
    "                self.nav_last_position = current_pos\n",
    "                self.nav_curiosity_countdown = 0\n",
    "                \n",
    "                print(f\"  üß≠ NAV START: ‚Üí ({target[0]}, {target[1]}) [{target_type}] \"\n",
    "                      f\"score={score:.1f} path={len(path)} steps\")\n",
    "                return True\n",
    "            \n",
    "            self.nav_target_index += 1\n",
    "        \n",
    "        self.abort_navigation(\"no valid targets\")\n",
    "        return False\n",
    "\n",
    "    def get_nav_action(self, current_pos):\n",
    "        \"\"\"Get next action from A* path.\"\"\"\n",
    "        if not self.nav_active or not self.nav_path:\n",
    "            return None\n",
    "        \n",
    "        # If paused, no path to follow ‚Äî let curiosity run\n",
    "        if self.nav_paused:\n",
    "            return None\n",
    "        \n",
    "        if self.nav_path_index < len(self.nav_path):\n",
    "            next_tile = self.nav_path[self.nav_path_index]\n",
    "            \n",
    "            if current_pos == next_tile:\n",
    "                self.nav_path_index += 1\n",
    "                if self.nav_path_index >= len(self.nav_path):\n",
    "                    return None\n",
    "                next_tile = self.nav_path[self.nav_path_index]\n",
    "            \n",
    "            dx = next_tile[0] - current_pos[0]\n",
    "            dy = next_tile[1] - current_pos[1]\n",
    "            \n",
    "            if dx > 0: return \"RIGHT\"\n",
    "            elif dx < 0: return \"LEFT\"\n",
    "            elif dy > 0: return \"DOWN\"\n",
    "            elif dy < 0: return \"UP\"\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def update_nav_state(self, current_pos, map_id):\n",
    "        \"\"\"Track navigation progress. Returns True to continue, False to end.\"\"\"\n",
    "        if not self.nav_active:\n",
    "            return False\n",
    "        \n",
    "        # If paused, check for resume periodically\n",
    "        if self.nav_paused:\n",
    "            self.check_nav_pause_resume(current_pos, map_id)\n",
    "            return True  # Stay \"active\" but paused ‚Äî curiosity runs\n",
    "        \n",
    "        self.nav_steps_taken += 1\n",
    "        \n",
    "        # Periodic cross-map refresh\n",
    "        if self.nav_map_chain:\n",
    "            self.nav_cross_map_refresh_countdown -= 1\n",
    "            if self.nav_cross_map_refresh_countdown <= 0:\n",
    "                self.nav_cross_map_refresh_countdown = self.NAV_CROSS_MAP_REFRESH_INTERVAL\n",
    "                self.refresh_cross_map_navigation(current_pos, map_id)\n",
    "        \n",
    "        if self.nav_steps_taken >= self.NAV_MAX_STEPS:\n",
    "            self.abort_navigation(\"max steps reached\")\n",
    "            return False\n",
    "        \n",
    "        if current_pos == self.nav_last_position:\n",
    "            self.nav_stagnation_count += 1\n",
    "            if self.nav_stagnation_count >= self.NAV_STAGNATION_LIMIT:\n",
    "                self.abort_navigation(\"stuck during pathfinding\")\n",
    "                return False\n",
    "        else:\n",
    "            self.nav_stagnation_count = 0\n",
    "        self.nav_last_position = current_pos\n",
    "        \n",
    "        if self.nav_target:\n",
    "            dist_to_target = abs(current_pos[0] - self.nav_target[0]) + abs(current_pos[1] - self.nav_target[1])\n",
    "            if dist_to_target <= 1:\n",
    "                # Check if this is a cross-map transition target\n",
    "                if self.nav_map_chain and self.nav_chain_index < len(self.nav_map_chain) - 1:\n",
    "                    # We're heading to a transition ‚Äî don't start curiosity window,\n",
    "                    # just let the map change happen naturally\n",
    "                    print(f\"  üß≠üåç Approaching transition at ({self.nav_target[0]}, {self.nav_target[1]})\")\n",
    "                    return True  # Keep navigating ‚Äî map change will trigger advance_map_chain\n",
    "                \n",
    "                if self.nav_curiosity_countdown == 0:\n",
    "                    self.nav_curiosity_countdown = self.NAV_CURIOSITY_WINDOW\n",
    "                    self._mark_taught_target_visited(self.nav_target)\n",
    "                    print(f\"  üß≠ NAV ARRIVED: ({self.nav_target[0]}, {self.nav_target[1]}) \"\n",
    "                          f\"‚Äî curiosity window {self.NAV_CURIOSITY_WINDOW} steps\")\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _mark_taught_target_visited(self, position):\n",
    "        \"\"\"Mark a taught nav target as visited by its order number.\"\"\"\n",
    "        if not self.taught_nav_loaded:\n",
    "            return\n",
    "        pos_tuple = tuple(position)\n",
    "        # Check current map first, then all maps (for cross-map targets)\n",
    "        maps_to_check = [self.current_map_id] if self.current_map_id is not None else []\n",
    "        maps_to_check += [m for m in self.taught_nav_targets.keys() if m != self.current_map_id]\n",
    "        \n",
    "        for check_map in maps_to_check:\n",
    "            for t in self.taught_nav_targets.get(check_map, []):\n",
    "                t_pos = tuple(t['position'])\n",
    "                if t_pos == pos_tuple:\n",
    "                    order = t.get('order', -1)\n",
    "                    if order >= 0:\n",
    "                        self.nav_visited_targets.add(order)\n",
    "                        print(f\"  üß≠ TARGET VISITED: order #{order} at ({pos_tuple[0]}, {pos_tuple[1]}) on map {check_map}\")\n",
    "                    return\n",
    "\n",
    "    def complete_nav_target(self, found_novelty):\n",
    "        \"\"\"After curiosity window: if novelty found, done. If not, strike and try next.\"\"\"\n",
    "        if found_novelty:\n",
    "            print(f\"  üß≠ NAV SUCCESS: Novelty found at ({self.nav_target[0]}, {self.nav_target[1]})\")\n",
    "            self.abort_navigation(\"novelty found\")\n",
    "            return\n",
    "        \n",
    "        if self.nav_target:\n",
    "            self.nav_struck_targets.add(self.nav_target)\n",
    "            print(f\"  üß≠ NAV STRIKE: ({self.nav_target[0]}, {self.nav_target[1]}) ‚Äî no novelty, trying next\")\n",
    "        \n",
    "        # If we were doing cross-map and arrived at final target, clear cross-map state\n",
    "        if self.nav_map_chain and self.nav_chain_index >= len(self.nav_map_chain) - 1:\n",
    "            self._clear_cross_map_state()\n",
    "        \n",
    "        self.nav_target_index += 1\n",
    "        current_pos = self.nav_last_position or (0, 0)\n",
    "        map_id = self.current_map_id\n",
    "        \n",
    "        if not self._navigate_to_next_target(current_pos, map_id):\n",
    "            self.abort_navigation(\"all targets exhausted\")\n",
    "\n",
    "    def abort_navigation(self, reason=\"\"):\n",
    "        \"\"\"End navigation mode. Clears both single-map and cross-map state.\"\"\"\n",
    "        if self.nav_active:\n",
    "            cross_info = \"\"\n",
    "            if self.nav_map_chain:\n",
    "                cross_info = f\" [cross-map chain: {' ‚Üí '.join(str(m) for m in self.nav_map_chain)}]\"\n",
    "            print(f\"  üß≠ NAV END: {reason} (took {self.nav_steps_taken} steps){cross_info}\")\n",
    "        \n",
    "        self.nav_active = False\n",
    "        self.nav_path = []\n",
    "        self.nav_path_index = 0\n",
    "        self.nav_target = None\n",
    "        self.nav_steps_taken = 0\n",
    "        self.nav_stagnation_count = 0\n",
    "        self.nav_curiosity_countdown = 0\n",
    "        self._clear_cross_map_state()\n",
    "\n",
    "    def update_known_area_counter(self, raw_x, raw_y, map_id):\n",
    "        \"\"\"Track consecutive steps in visited tiles. Triggers nav at threshold.\"\"\"\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        pos = (int(raw_x), int(raw_y))\n",
    "        if pos in memory['visited_tiles']:\n",
    "            self.known_area_counter += 1\n",
    "        else:\n",
    "            self.known_area_counter = 0\n",
    "\n",
    "    def should_start_navigation(self):\n",
    "        if self.nav_active:\n",
    "            return False\n",
    "        if self.known_area_counter < self.KNOWN_AREA_TRIGGER:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def is_nav_active(self):\n",
    "        return self.nav_active\n",
    "\n",
    "    def is_nav_paused(self):\n",
    "        return self.nav_paused\n",
    "\n",
    "    def is_in_nav_curiosity_window(self):\n",
    "        return self.nav_curiosity_countdown > 0\n",
    "\n",
    "    def tick_nav_curiosity_window(self):\n",
    "        if self.nav_curiosity_countdown > 0:\n",
    "            self.nav_curiosity_countdown -= 1\n",
    "            if self.nav_curiosity_countdown <= 0:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_nav_targets_status(self):\n",
    "        if not self.taught_nav_loaded:\n",
    "            return {'loaded': False, 'total': 0, 'visited': 0, 'remaining': 0}\n",
    "        total = sum(len(t) for t in self.taught_nav_targets.values())\n",
    "        visited = len(self.nav_visited_targets)\n",
    "        return {'loaded': True, 'total': total, 'visited': visited, 'remaining': total - visited}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3 PART 5: Stagnation, Blend Triggers, Mode Swap, Repetition/Pattern\n",
    "# ============================================================================\n",
    "# NO CHANGES ‚Äî reorganized from original Cell 3 Part 3\n",
    "# ============================================================================\n",
    "\n",
    "    # =========================================================================\n",
    "    # BLEND TIER DETECTION\n",
    "    # =========================================================================\n",
    "    \n",
    "    def get_blend_tier(self):\n",
    "        \"\"\"\n",
    "        Determine blend tier based on current stagnation metrics.\n",
    "        Returns 0 (no blend), 1 (light), 2 (medium), or 3 (hard).\n",
    "        Higher tier = more taught model influence.\n",
    "        \"\"\"\n",
    "        # Tier 3 (hard): extreme stagnation\n",
    "        t3 = self.BLEND_TIER_TRIGGERS[3]\n",
    "        if (self.detected_pattern and self.pattern_repeat_count >= t3['pattern_repeats']):\n",
    "            return 3\n",
    "        if self.state_stagnation_count >= self.STATE_STAGNATION_THRESHOLD * t3['state_stagnation_mult']:\n",
    "            return 3\n",
    "        \n",
    "        # Tier 2 (medium): significant stagnation\n",
    "        t2 = self.BLEND_TIER_TRIGGERS[2]\n",
    "        if (self.detected_pattern and self.pattern_repeat_count >= t2['pattern_repeats']):\n",
    "            return 2\n",
    "        if self.get_position_stagnation() >= t2['pos_stagnation']:\n",
    "            return 2\n",
    "        if self.consecutive_action_count >= t2['consecutive']:\n",
    "            return 2\n",
    "        \n",
    "        # Tier 1 (light): early stagnation\n",
    "        t1 = self.BLEND_TIER_TRIGGERS[1]\n",
    "        if (self.detected_pattern and self.pattern_repeat_count >= t1['pattern_repeats']):\n",
    "            return 1\n",
    "        if self.get_position_stagnation() >= t1['pos_stagnation']:\n",
    "            return 1\n",
    "        if self.consecutive_action_count >= t1['consecutive']:\n",
    "            return 1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def try_blend_if_needed(self):\n",
    "        \"\"\"\n",
    "        Check if blend should trigger. Called from action selection.\n",
    "        Returns True if a blend was performed.\n",
    "        \"\"\"\n",
    "        if not self.taught_reference['loaded']:\n",
    "            return False\n",
    "        \n",
    "        tier = self.get_blend_tier()\n",
    "        \n",
    "        if tier == 0:\n",
    "            return False\n",
    "        \n",
    "        # Only blend if tier escalated or cooldown passed\n",
    "        if tier <= self.blend_tier and (self.timestep - self.last_blend_timestep) < self.BLEND_COOLDOWN:\n",
    "            return False\n",
    "        \n",
    "        self.blend_from_taught(tier)\n",
    "        return True\n",
    "\n",
    "    # =========================================================================\n",
    "    # MODE SWAP & STAGNATION  \n",
    "    # =========================================================================\n",
    "    \n",
    "    def get_context_state_hash(self, context_state):\n",
    "        return (round(context_state[0], 2), round(context_state[1], 2), int(context_state[2]),\n",
    "                int(context_state[3]), round(context_state[4], 2), int(context_state[5]))\n",
    "\n",
    "    def check_state_stagnation(self, context_state):\n",
    "        current_hash = self.get_context_state_hash(context_state)\n",
    "        if current_hash == self.last_context_state_hash:\n",
    "            self.state_stagnation_count += 1\n",
    "            if self.state_stagnation_count == 1 and self.last_action:\n",
    "                self.stagnation_initiator_action = self.last_action\n",
    "        else:\n",
    "            self.state_stagnation_count = 0\n",
    "            self.stagnation_initiator_action = None\n",
    "        self.last_context_state_hash = current_hash\n",
    "        return self.state_stagnation_count >= self.STATE_STAGNATION_THRESHOLD\n",
    "\n",
    "    def check_position_stagnation(self):\n",
    "        return self.get_position_stagnation()\n",
    "\n",
    "    def should_force_random(self):\n",
    "        \"\"\"\n",
    "        Returns True if the agent is badly stuck and needs forced randomization.\n",
    "        Also triggers blend from taught model before randomizing.\n",
    "        \"\"\"\n",
    "        force = False\n",
    "        \n",
    "        if self.get_position_stagnation() >= 8:\n",
    "            force = True\n",
    "        if self.consecutive_action_count >= 15:\n",
    "            force = True\n",
    "        if self.detected_pattern and self.pattern_repeat_count >= 4:\n",
    "            force = True\n",
    "        if self.state_stagnation_count >= self.STATE_STAGNATION_THRESHOLD * 2:\n",
    "            force = True\n",
    "        \n",
    "        if force:\n",
    "            # Attempt blend before randomizing ‚Äî blend fixes priorities,\n",
    "            # random breaks the immediate loop\n",
    "            self.try_blend_if_needed()\n",
    "        \n",
    "        return force\n",
    "\n",
    "    def get_forced_random_action_name(self):\n",
    "        \"\"\"Pick a random action that ISN'T the currently repeated one or in the pattern.\"\"\"\n",
    "        candidates = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"A\", \"B\"]\n",
    "        \n",
    "        if self.current_repeated_action and self.current_repeated_action in candidates:\n",
    "            candidates.remove(self.current_repeated_action)\n",
    "        \n",
    "        if self.detected_pattern:\n",
    "            for a in self.detected_pattern:\n",
    "                if a in candidates:\n",
    "                    candidates.remove(a)\n",
    "        \n",
    "        if not candidates:\n",
    "            candidates = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "            if self.current_repeated_action in candidates:\n",
    "                candidates.remove(self.current_repeated_action)\n",
    "        \n",
    "        if not candidates:\n",
    "            candidates = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "        \n",
    "        return random.choice(candidates)\n",
    "\n",
    "    def check_direction_change_progress(self, context_state):\n",
    "        current_dir = int(context_state[5])\n",
    "        if self.last_direction_for_progress is None:\n",
    "            self.last_direction_for_progress = current_dir\n",
    "            return False\n",
    "        changed = current_dir != self.last_direction_for_progress\n",
    "        self.last_direction_for_progress = current_dir\n",
    "        return changed\n",
    "\n",
    "    def apply_stagnation_initiator_penalty(self):\n",
    "        if self.stagnation_initiator_action is None:\n",
    "            return\n",
    "        for a in self.actions():\n",
    "            if a.action == self.stagnation_initiator_action:\n",
    "                old_util = a.utility\n",
    "                floor = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "                a.utility = max(floor, a.utility * 0.5)\n",
    "                print(f\"  üìç STAGNATION PENALTY: {self.stagnation_initiator_action} {old_util:.3f} ‚Üí {a.utility:.3f}\")\n",
    "                break\n",
    "        self.stagnation_initiator_action = None\n",
    "\n",
    "    def check_productive_change(self, context_state):\n",
    "        current_map = int(context_state[2])\n",
    "        current_battle = context_state[3] > 0.5\n",
    "        current_pos = (context_state[0], context_state[1])\n",
    "        productive, reason = False, \"\"\n",
    "        \n",
    "        if self.last_map_id is not None and current_map != self.last_map_id:\n",
    "            productive, reason = True, \"map change\"\n",
    "        if self.last_battle_state is not None and current_battle != self.last_battle_state:\n",
    "            productive, reason = True, \"battle change\"\n",
    "        if self.position_at_mode_swap is not None:\n",
    "            dist = np.sqrt((current_pos[0] - self.position_at_mode_swap[0])**2 + \n",
    "                          (current_pos[1] - self.position_at_mode_swap[1])**2)\n",
    "            if dist > 0.03:\n",
    "                productive, reason = True, f\"moved {dist*255:.1f} tiles\"\n",
    "        \n",
    "        if self.direction_change_counts_as_progress and self.check_direction_change_progress(context_state):\n",
    "            self.state_stagnation_count = max(0, self.state_stagnation_count - 5)\n",
    "        \n",
    "        self.last_map_id = current_map\n",
    "        self.last_battle_state = current_battle\n",
    "        return productive, reason\n",
    "\n",
    "    def on_productive_change(self, reason):\n",
    "        self.move_to_interact_threshold = self.DEFAULT_MOVE_TO_INTERACT_THRESHOLD\n",
    "        self.interact_to_move_threshold = self.DEFAULT_INTERACT_TO_MOVE_THRESHOLD\n",
    "        self.swap_chain_count = 0\n",
    "        self.state_stagnation_count = 0\n",
    "        self.stagnation_initiator_action = None\n",
    "        self.unproductive_swap_count = 0\n",
    "        \n",
    "        # Reset blend tier on productive progress\n",
    "        if self.blend_tier > 0:\n",
    "            print(f\"  ‚úÖ Blend tier reset: {self.blend_tier} ‚Üí 0 ({reason})\")\n",
    "            self.blend_tier = 0\n",
    "        \n",
    "        # Reset known area counter ‚Äî productive change means fresh territory\n",
    "        self.known_area_counter = 0\n",
    "\n",
    "    def on_mode_swap(self, from_mode, to_mode):\n",
    "        self.swap_chain_count += 1\n",
    "        self.frames_in_current_mode = 0\n",
    "        self.unproductive_swap_count += 1\n",
    "        if self.unproductive_swap_count >= self.UNPRODUCTIVE_SWAP_THRESHOLD:\n",
    "            self._reset_highest_to_third(to_mode)\n",
    "            self.unproductive_swap_count = 0\n",
    "        if to_mode == \"interact\":\n",
    "            self.interact_to_move_threshold = min(self.MAX_THRESHOLD, self.interact_to_move_threshold + self.THRESHOLD_INCREMENT)\n",
    "        else:\n",
    "            self.move_to_interact_threshold = min(self.MAX_THRESHOLD, self.move_to_interact_threshold + self.THRESHOLD_INCREMENT)\n",
    "\n",
    "    def _reset_highest_to_third(self, mode):\n",
    "        if mode in [\"battle\", \"both\"]:\n",
    "            return\n",
    "        group = \"move\" if mode == \"move\" else \"interact\"\n",
    "        group_actions = [a for a in self.actions() if a.group == group]\n",
    "        if len(group_actions) < 3:\n",
    "            return\n",
    "        sorted_actions = sorted(group_actions, key=lambda a: a.utility, reverse=True)\n",
    "        floor = self.INTERACT_UTILITY_FLOOR if group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "        sorted_actions[0].utility = max(sorted_actions[2].utility * 0.9, floor)\n",
    "\n",
    "    def should_use_both_mode(self):\n",
    "        return (self.state_stagnation_count > self.BOTH_MODE_STAGNATION_THRESHOLD or \n",
    "                self.unproductive_swap_count > self.BOTH_MODE_SWAP_THRESHOLD)\n",
    "\n",
    "    def determine_control_mode(self, context_state, raw_position=None):\n",
    "        if context_state[3] > 0.5:\n",
    "            return \"battle\"\n",
    "        \n",
    "        self.frames_in_current_mode += 1\n",
    "        position_stagnation = self.get_position_stagnation()\n",
    "        \n",
    "        productive, reason = self.check_productive_change(context_state)\n",
    "        if productive:\n",
    "            self.on_productive_change(reason)\n",
    "        \n",
    "        if self.should_use_both_mode():\n",
    "            return \"both\"\n",
    "        \n",
    "        if self.check_state_stagnation(context_state):\n",
    "            self.apply_stagnation_initiator_penalty()\n",
    "            new_mode = \"interact\" if self.control_mode == \"move\" else \"move\"\n",
    "            self.control_mode = new_mode\n",
    "            self.position_at_mode_swap = (context_state[0], context_state[1])\n",
    "            self.on_mode_swap(self.control_mode, new_mode)\n",
    "            self.state_stagnation_count = 0\n",
    "            return self.control_mode\n",
    "        \n",
    "        raw_x = raw_position[0] if raw_position else int(context_state[0] * 255)\n",
    "        raw_y = raw_position[1] if raw_position else int(context_state[1] * 255)\n",
    "        current_map = int(context_state[2])\n",
    "        \n",
    "        tile_needs_probing = self.should_interact_at_tile(raw_x, raw_y, current_map)\n",
    "        untried_directions = self.get_untried_directions(raw_x, raw_y, current_map)\n",
    "        \n",
    "        if tile_needs_probing and untried_directions and self.control_mode == \"move\" and self.frames_in_current_mode >= 3:\n",
    "            self.control_mode = \"interact\"\n",
    "            self.position_at_mode_swap = (context_state[0], context_state[1])\n",
    "            self.frames_in_current_mode = 0\n",
    "            return self.control_mode\n",
    "        \n",
    "        if self.control_mode == \"move\" and position_stagnation >= self.move_to_interact_threshold:\n",
    "            self.control_mode = \"interact\"\n",
    "            self.position_at_mode_swap = (context_state[0], context_state[1])\n",
    "            self.on_mode_swap(\"move\", \"interact\")\n",
    "        elif self.control_mode == \"interact\":\n",
    "            if (not tile_needs_probing or not untried_directions) and self.frames_in_current_mode >= 5:\n",
    "                self.control_mode = \"move\"\n",
    "                self.position_at_mode_swap = (context_state[0], context_state[1])\n",
    "                self.frames_in_current_mode = 0\n",
    "            elif self.frames_in_current_mode >= self.interact_to_move_threshold:\n",
    "                self.control_mode = \"move\"\n",
    "                self.position_at_mode_swap = (context_state[0], context_state[1])\n",
    "                self.on_mode_swap(\"interact\", \"move\")\n",
    "        \n",
    "        return self.control_mode\n",
    "\n",
    "    # =========================================================================\n",
    "    # EXPLORATION TRACKING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def update_exploration_tracking(self, context_state, prev_context_state, raw_position=None, prev_raw_position=None):\n",
    "        current_map = int(context_state[2])\n",
    "        raw_x = raw_position[0] if raw_position else int(context_state[0] * 255)\n",
    "        raw_y = raw_position[1] if raw_position else int(context_state[1] * 255)\n",
    "        current_pos = (raw_x, raw_y)\n",
    "        \n",
    "        if self.current_map_id is not None and current_map != self.current_map_id:\n",
    "            prev_map = self.current_map_id\n",
    "            if prev_context_state is not None and prev_raw_position is not None:\n",
    "                self.record_transition(prev_raw_position, prev_map, current_map,\n",
    "                    int(prev_context_state[5]), 'interact' if self.last_action == 'A' else 'walk')\n",
    "            if prev_raw_position is not None:\n",
    "                entry_dir = int(context_state[5]) if prev_context_state is not None else 0\n",
    "                self.create_transition_ban(current_map, current_pos, (entry_dir + 2) % 4)\n",
    "            self.on_map_change(current_map)\n",
    "        \n",
    "        self.current_map_id = current_map\n",
    "        self.record_visited_tile(raw_x, raw_y, current_map)\n",
    "        self.accumulate_temp_debt(current_map)\n",
    "        self.update_transition_ban(current_map, current_pos)\n",
    "        self.check_ban_lift_conditions(current_map)\n",
    "        \n",
    "        if prev_context_state is not None and prev_raw_position is not None:\n",
    "            self.detect_obstruction(prev_context_state, context_state, raw_position, prev_raw_position)\n",
    "        \n",
    "        self.check_interaction_verification(context_state, prev_context_state)\n",
    "        self.last_direction = int(context_state[5])\n",
    "        \n",
    "        if self.timestep % 300 == 0:\n",
    "            self.decay_all_debts()\n",
    "\n",
    "    def on_map_change(self, new_map):\n",
    "        self.save_exploration_memory()\n",
    "        self.control_mode = \"move\"\n",
    "        self.frames_in_current_mode = 0\n",
    "        \n",
    "        # Abort navigation on map change\n",
    "        if self.nav_active:\n",
    "            self.abort_navigation(\"map changed\")\n",
    "        self.known_area_counter = 0\n",
    "        self.nav_struck_targets.clear()\n",
    "        \n",
    "        memory = self.get_current_map_memory(new_map)\n",
    "        tile_interactions = memory.get('tile_interactions', {})\n",
    "        print(f\"  üó∫Ô∏è MAP CHANGE ‚Üí {new_map}: {len(memory['visited_tiles'])} visited, {len(memory['obstructions'])} obs\")\n",
    "        print(f\"     Tiles probed: {len(tile_interactions)}, exhausted: {sum(1 for t in tile_interactions.values() if t.get('exhausted', False))}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # REPETITION & PATTERN HANDLING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def track_consecutive_action(self, action_name):\n",
    "        if action_name == self.current_repeated_action:\n",
    "            self.consecutive_action_count += 1\n",
    "        else:\n",
    "            self.current_repeated_action = action_name\n",
    "            self.consecutive_action_count = 1\n",
    "\n",
    "    def get_learning_multiplier(self, action_name):\n",
    "        if action_name != self.current_repeated_action or self.consecutive_action_count < self.LEARNING_SLOWDOWN_START:\n",
    "            return 1.0\n",
    "        progress = min(1.0, (self.consecutive_action_count - self.LEARNING_SLOWDOWN_START) / \n",
    "                       (self.LEARNING_SLOWDOWN_MAX - self.LEARNING_SLOWDOWN_START))\n",
    "        return max(0.05, 1.0 - 0.95 * progress)\n",
    "\n",
    "    def get_nth_highest_utility(self, group, n=3):\n",
    "        utilities = sorted([a.utility for a in self.actions() if a.group == group], reverse=True)\n",
    "        if len(utilities) < n:\n",
    "            return self.INTERACT_UTILITY_FLOOR if group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "        return utilities[n-1]\n",
    "\n",
    "    def detect_pattern(self):\n",
    "        if len(self.action_history) < 6:\n",
    "            return None, 0\n",
    "        recent = list(self.action_history)[-self.PATTERN_CHECK_WINDOW:]\n",
    "        for pattern_len in range(1, self.PATTERN_MAX_LENGTH + 1):\n",
    "            if len(recent) < pattern_len * self.PATTERN_MIN_REPEATS:\n",
    "                continue\n",
    "            candidate = tuple(recent[-pattern_len:])\n",
    "            repeat_count, idx = 0, len(recent) - pattern_len\n",
    "            while idx >= 0 and tuple(recent[idx:idx + pattern_len]) == candidate:\n",
    "                repeat_count += 1\n",
    "                idx -= pattern_len\n",
    "            if repeat_count >= self.PATTERN_MIN_REPEATS:\n",
    "                return candidate, repeat_count\n",
    "        return None, 0\n",
    "\n",
    "    def apply_pattern_penalty(self):\n",
    "        pattern, repeat_count = self.detect_pattern()\n",
    "        if pattern is None:\n",
    "            self.detected_pattern, self.pattern_repeat_count = None, 0\n",
    "            return\n",
    "        self.detected_pattern, self.pattern_repeat_count = pattern, repeat_count\n",
    "        \n",
    "        penalty_factor = max(0.3, 1.0 - repeat_count * 0.15)\n",
    "        \n",
    "        for action_name in set(pattern):\n",
    "            for a in self.actions():\n",
    "                if a.action == action_name:\n",
    "                    floor = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "                    a.utility = max(floor, a.utility * penalty_factor)\n",
    "                    break\n",
    "\n",
    "    def apply_repetition_penalty(self):\n",
    "        if self.current_repeated_action is None:\n",
    "            return\n",
    "        for a in self.actions():\n",
    "            if a.action == self.current_repeated_action:\n",
    "                floor = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "                if self.consecutive_action_count >= self.HARD_RESET_THRESHOLD:\n",
    "                    a.utility = floor\n",
    "                    self.consecutive_action_count = 0\n",
    "                    print(f\"  üî® HARD RESET: {a.action} ‚Üí {floor:.3f}\")\n",
    "                elif self.consecutive_action_count >= self.PENALTY_THRESHOLD:\n",
    "                    a.utility = max(a.utility * 0.5, floor)\n",
    "                break\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3 PART 6: Entity Spawning/Clustering, Learning, Save/Load\n",
    "# ============================================================================\n",
    "# NO CHANGES ‚Äî reorganized from original Cell 3 Part 3\n",
    "# ============================================================================\n",
    "\n",
    "    # =========================================================================\n",
    "    # ENTITY SPAWNING & CLUSTERING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def spawn_entity_from_novelty(self, learning_state, context_state, raw_position=None):\n",
    "        \"\"\"\n",
    "        Spawn a new entity perceptron from the current novel state.\n",
    "        The entity's weights are initialized from the state that surprised the AI,\n",
    "        so it learns to detect similar situations in the future.\n",
    "        No duplicate checking ‚Äî clustering handles redundancy later.\n",
    "        \"\"\"\n",
    "        entity = Perceptron(\"entity\", entity_type=f\"spawned_{self.entity_spawn_count}\")\n",
    "        entity.ensure_weights(len(learning_state))\n",
    "        \n",
    "        state_norm = np.linalg.norm(learning_state)\n",
    "        if state_norm > 0:\n",
    "            entity.weights = (learning_state / state_norm) * 0.1\n",
    "        else:\n",
    "            entity.weights = np.random.randn(len(learning_state)) * 0.001\n",
    "        \n",
    "        entity.utility = 1.0\n",
    "        self.add(entity)\n",
    "        self.entity_spawn_count += 1\n",
    "        \n",
    "        self.check_entity_capacity()\n",
    "    \n",
    "    def check_entity_capacity(self):\n",
    "        \"\"\"\n",
    "        If entity count exceeds capacity, run clustering.\n",
    "        If clustering didn't reduce count enough, expand capacity by 50%.\n",
    "        \"\"\"\n",
    "        n_entities = len(self.entities())\n",
    "        \n",
    "        if n_entities < self.entity_capacity:\n",
    "            return\n",
    "        \n",
    "        before_count = n_entities\n",
    "        self.cluster_entities()\n",
    "        after_count = len(self.entities())\n",
    "        \n",
    "        if after_count >= before_count * 0.9:\n",
    "            old_cap = self.entity_capacity\n",
    "            self.entity_capacity = int(self.entity_capacity * self.ENTITY_CAPACITY_GROWTH)\n",
    "            print(f\"  üß© Entity capacity expanded: {old_cap} ‚Üí {self.entity_capacity} \"\n",
    "                  f\"(clustering only reduced {before_count} ‚Üí {after_count})\")\n",
    "    \n",
    "    def cluster_entities(self):\n",
    "        \"\"\"\n",
    "        Cluster similar entity perceptrons using cosine similarity on activation patterns.\n",
    "        Merge similar entities by averaging their weights.\n",
    "        \"\"\"\n",
    "        entities = self.entities()\n",
    "        \n",
    "        innate_types = {\"sense_menu\", \"sense_battle\", \"sense_movement\", \"sense_map_transition\"}\n",
    "        spawned = [e for e in entities if e.entity_type not in innate_types]\n",
    "        innate = [e for e in entities if e.entity_type in innate_types]\n",
    "        \n",
    "        if len(spawned) < 2:\n",
    "            return\n",
    "        \n",
    "        clusterable = []\n",
    "        too_young = []\n",
    "        \n",
    "        for e in spawned:\n",
    "            if len(e.cluster_activations) >= self.ENTITY_MIN_ACTIVATIONS:\n",
    "                clusterable.append(e)\n",
    "            else:\n",
    "                too_young.append(e)\n",
    "        \n",
    "        if len(clusterable) < 2:\n",
    "            return\n",
    "        \n",
    "        max_len = max(len(e.cluster_activations) for e in clusterable)\n",
    "        activation_vecs = []\n",
    "        for e in clusterable:\n",
    "            vec = list(e.cluster_activations)\n",
    "            while len(vec) < max_len:\n",
    "                vec.append(0.0)\n",
    "            activation_vecs.append(np.array(vec))\n",
    "        \n",
    "        merged_indices = set()\n",
    "        merge_groups = []\n",
    "        \n",
    "        for i in range(len(clusterable)):\n",
    "            if i in merged_indices:\n",
    "                continue\n",
    "            group = [i]\n",
    "            vec_i = activation_vecs[i]\n",
    "            norm_i = np.linalg.norm(vec_i)\n",
    "            if norm_i < 1e-10:\n",
    "                continue\n",
    "            \n",
    "            for j in range(i + 1, len(clusterable)):\n",
    "                if j in merged_indices:\n",
    "                    continue\n",
    "                vec_j = activation_vecs[j]\n",
    "                norm_j = np.linalg.norm(vec_j)\n",
    "                if norm_j < 1e-10:\n",
    "                    continue\n",
    "                \n",
    "                cosine_sim = np.dot(vec_i, vec_j) / (norm_i * norm_j)\n",
    "                \n",
    "                if cosine_sim >= self.ENTITY_CLUSTER_SIMILARITY:\n",
    "                    group.append(j)\n",
    "                    merged_indices.add(j)\n",
    "            \n",
    "            if len(group) > 1:\n",
    "                merged_indices.add(i)\n",
    "                merge_groups.append(group)\n",
    "        \n",
    "        if not merge_groups:\n",
    "            return\n",
    "        \n",
    "        new_entities = []\n",
    "        merged_set = set()\n",
    "        \n",
    "        for group in merge_groups:\n",
    "            group_entities = [clusterable[idx] for idx in group]\n",
    "            \n",
    "            min_dim = min(len(e.weights) for e in group_entities if e.weights is not None)\n",
    "            if min_dim == 0:\n",
    "                continue\n",
    "            \n",
    "            avg_weights = np.zeros(min_dim)\n",
    "            for e in group_entities:\n",
    "                avg_weights += e.weights[:min_dim]\n",
    "            avg_weights /= len(group_entities)\n",
    "            \n",
    "            merged = Perceptron(\"entity\", entity_type=f\"merged_{self.entity_merge_count}\")\n",
    "            merged.weights = avg_weights\n",
    "            merged.utility = max(e.utility for e in group_entities)\n",
    "            merged.familiarity = np.mean([e.familiarity for e in group_entities])\n",
    "            merged.learning_rate = np.mean([e.learning_rate for e in group_entities])\n",
    "            \n",
    "            new_entities.append(merged)\n",
    "            self.entity_merge_count += 1\n",
    "            \n",
    "            for idx in group:\n",
    "                merged_set.add(id(clusterable[idx]))\n",
    "        \n",
    "        kept_spawned = [e for e in clusterable if id(e) not in merged_set]\n",
    "        \n",
    "        self.perceptrons = (\n",
    "            [p for p in self.perceptrons if p.kind == \"action\"] +\n",
    "            innate +\n",
    "            kept_spawned +\n",
    "            too_young +\n",
    "            new_entities\n",
    "        )\n",
    "        self._cache_valid = False\n",
    "        \n",
    "        total_merged = sum(len(g) for g in merge_groups)\n",
    "        print(f\"  üß© CLUSTERED: {total_merged} entities ‚Üí {len(new_entities)} merged \"\n",
    "              f\"| Total entities now: {len(self.entities())}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # ENTITY & LEARNING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def spawn_innate_entities(self, learning_state):\n",
    "        if self.innate_entities_spawned:\n",
    "            return\n",
    "        for etype, indices in [(\"sense_menu\", [5, 6]), (\"sense_battle\", [3, 4]), \n",
    "                                (\"sense_movement\", [0, 1]), (\"sense_map_transition\", [2])]:\n",
    "            entity = Perceptron(\"entity\", entity_type=etype)\n",
    "            entity.ensure_weights(len(learning_state))\n",
    "            entity.weights = np.zeros(len(learning_state))\n",
    "            for idx in indices:\n",
    "                entity.weights[idx] = 0.5 if len(indices) > 1 else 1.0\n",
    "            self.add(entity)\n",
    "        self.innate_entities_spawned = True\n",
    "\n",
    "    def enforce_utility_floors(self):\n",
    "        for a in self.actions():\n",
    "            floor = self.MOVE_UTILITY_FLOOR if a.group == \"move\" else self.INTERACT_UTILITY_FLOOR\n",
    "            a.utility = max(a.utility, floor)\n",
    "\n",
    "    def get_spawn_threshold_adaptive(self, error_type='combined', percentile=50):\n",
    "        history = {'numeric': self.numeric_error_history, 'visual': self.visual_error_history}.get(error_type, self.error_history)\n",
    "        return max(0.001, np.percentile(history, percentile)) if len(history) >= 100 else 0.0005\n",
    "\n",
    "    def stagnation_level(self, window=10):\n",
    "        if len(self.prev_learning_states) < window:\n",
    "            return 0.0\n",
    "        recent = list(self.prev_learning_states)[-window:]\n",
    "        diffs = []\n",
    "        for i in range(1, len(recent)):\n",
    "            a, b = recent[i], recent[i-1]\n",
    "            min_dim = min(len(a), len(b))\n",
    "            diffs.append(np.linalg.norm(a[:min_dim] - b[:min_dim]))\n",
    "        return 1.0 - np.tanh(np.mean(diffs) * 2.0)\n",
    "\n",
    "    def predict_future_error(self, state, action, context_state, raw_position=None):\n",
    "        entity_novelty = np.mean([e.predict(state) * e.utility for e in self.entities()]) if self.entities() else 0.5\n",
    "        combined = entity_novelty * 0.7 + action.utility * 0.3\n",
    "        \n",
    "        current_map = int(context_state[2])\n",
    "        loc = self.get_location_key(*(raw_position if raw_position else (context_state[0]*255, context_state[1]*255)), current_map)\n",
    "        \n",
    "        map_debt = min(self.map_novelty_debt.get(current_map, 0.0), self.MAX_MAP_DEBT)\n",
    "        loc_debt = min(self.location_novelty.get(loc, 0.0), self.MAX_LOCATION_DEBT)\n",
    "        total_debt = map_debt + self.get_temp_debt(current_map) + loc_debt * 0.5\n",
    "        combined *= 1.0 / (1.0 + total_debt * 5.0)\n",
    "        \n",
    "        if action.action == self.current_repeated_action and self.consecutive_action_count > self.LEARNING_SLOWDOWN_START:\n",
    "            combined *= 1.0 / (1.0 + (self.consecutive_action_count - self.LEARNING_SLOWDOWN_START) * 0.15)\n",
    "        if self.detected_pattern and action.action in self.detected_pattern:\n",
    "            combined *= 1.0 / (1.0 + self.pattern_repeat_count * 0.2)\n",
    "        \n",
    "        return combined + np.random.randn() * 0.05\n",
    "\n",
    "    def compute_multi_modal_error(self, state, next_state):\n",
    "        diffs = [abs(next_state[i] - state[i]) for i in range(min(8, len(state), len(next_state)))]\n",
    "        weights = [0.5, 0.5, 10.0, 5.0, 3.0, 2.0, 1.5, 0.3]\n",
    "        weighted = sum(d * w for d, w in zip(diffs, weights)) + np.linalg.norm(next_state[8:] - state[8:]) * 2.0\n",
    "        numeric = sum(diffs)\n",
    "        visual = np.linalg.norm(next_state[8:] - state[8:])\n",
    "        return weighted, numeric, visual\n",
    "\n",
    "    def learn(self, learning_state, next_learning_state, context_state, next_context_state, dead=False,\n",
    "              raw_position=None, next_raw_position=None):\n",
    "        if learning_state.shape != next_learning_state.shape:\n",
    "            max_dim = max(len(learning_state), len(next_learning_state))\n",
    "            learning_state = np.pad(learning_state, (0, max(0, max_dim - len(learning_state))))\n",
    "            next_learning_state = np.pad(next_learning_state, (0, max(0, max_dim - len(next_learning_state))))\n",
    "        \n",
    "        if not self.innate_entities_spawned:\n",
    "            self.spawn_innate_entities(learning_state)\n",
    "        \n",
    "        prev_context = self.prev_context_states[-1] if self.prev_context_states else None\n",
    "        prev_raw = getattr(self, '_last_raw_position', None)\n",
    "        self.update_exploration_tracking(context_state, prev_context, raw_position, prev_raw)\n",
    "        self._last_raw_position = raw_position\n",
    "        \n",
    "        weighted_error, numeric_error, visual_error = self.compute_multi_modal_error(learning_state, next_learning_state)\n",
    "        self.error_history.append(weighted_error)\n",
    "        self.numeric_error_history.append(numeric_error)\n",
    "        self.visual_error_history.append(visual_error)\n",
    "        \n",
    "        # === ENTITY SPAWNING: spawn freely when novelty exceeds threshold ===\n",
    "        # Only spawn from spatial novelty ‚Äî not menu/battle context changes\n",
    "        spawn_threshold = self.get_spawn_threshold_adaptive('combined', percentile=75)\n",
    "        if weighted_error > spawn_threshold and len(self.error_history) >= 100:\n",
    "            menu_active = context_state[4] > 0.5\n",
    "            battle_active = context_state[3] > 0.5\n",
    "            if not menu_active and not battle_active:\n",
    "                self.spawn_entity_from_novelty(learning_state, context_state, raw_position)\n",
    "        \n",
    "        current_map = int(context_state[2])\n",
    "        loc = self.get_location_key(*(raw_position if raw_position else (context_state[0]*255, context_state[1]*255)), current_map)\n",
    "        \n",
    "        self.visited_maps[current_map] = self.visited_maps.get(current_map, 0) + 1\n",
    "        self.location_memory[loc] = self.location_memory.get(loc, 0) + 1\n",
    "        \n",
    "        if self.visited_maps[current_map] > 10:\n",
    "            self.map_novelty_debt[current_map] = min(self.MAX_MAP_DEBT, \n",
    "                self.map_novelty_debt.get(current_map, 0.0) + 0.05 * (self.visited_maps[current_map] - 10))\n",
    "        if self.location_memory[loc] > 15:\n",
    "            self.location_novelty[loc] = min(self.MAX_LOCATION_DEBT,\n",
    "                self.location_novelty.get(loc, 0.0) + 0.1 * (self.location_memory[loc] - 15))\n",
    "        \n",
    "        if self.visited_maps[current_map] > 30:\n",
    "            weighted_error *= 0.5\n",
    "        if self.location_memory[loc] > 25:\n",
    "            weighted_error *= 0.7\n",
    "        \n",
    "        stagnation = self.stagnation_level()\n",
    "        learning_mult = self.get_learning_multiplier(self.last_action) if self.last_action else 1.0\n",
    "        if self.detected_pattern and self.last_action in self.detected_pattern:\n",
    "            learning_mult *= 0.5\n",
    "        \n",
    "        for p in self.perceptrons:\n",
    "            mult = learning_mult if (p.kind == \"action\" and p.action == self.last_action) else 1.0\n",
    "            if p.kind == \"action\" and self.detected_pattern and p.action in self.detected_pattern:\n",
    "                mult *= 0.5\n",
    "            p.update(learning_state, weighted_error * mult, stagnation=stagnation)\n",
    "        \n",
    "        for a in self.actions():\n",
    "            if a.action in ['Start', 'Select'] and a.weights is not None:\n",
    "                a.weights *= 0.999\n",
    "        \n",
    "        self.apply_repetition_penalty()\n",
    "        self.apply_pattern_penalty()\n",
    "        self.enforce_utility_floors()\n",
    "        \n",
    "        # Movement boost - ONLY if not stuck in repetition and not in navigation\n",
    "        # ONLY in overworld ‚Äî menu/battle state changes don't count as movement progress\n",
    "        if prev_context is not None and np.linalg.norm(context_state[:2] - prev_context[:2]) > 0.001:\n",
    "            if self.last_action and self.consecutive_action_count < self.PENALTY_THRESHOLD:\n",
    "                menu_active = context_state[4] > 0.5\n",
    "                battle_active = context_state[3] > 0.5\n",
    "                if not menu_active and not battle_active:\n",
    "                    if not self.nav_active:\n",
    "                        for a in self.actions():\n",
    "                            if a.action == self.last_action:\n",
    "                                boost = 1.15 if raw_position and self.is_near_map_edge(*raw_position) else 1.08\n",
    "                                a.utility = min(a.utility * boost, 2.0)\n",
    "                                break\n",
    "                    else:\n",
    "                        for a in self.actions():\n",
    "                            if a.action == self.last_action:\n",
    "                                boost = 1.0 + (0.08 * self.NAV_LEARNING_DAMPENING)\n",
    "                                a.utility = min(a.utility * boost, 2.0)\n",
    "                                break\n",
    "        \n",
    "        if self.timestep % self.SAVE_INTERVAL == 0:\n",
    "            self.save_exploration_memory()\n",
    "        \n",
    "        self.action_history.append(self.last_action)\n",
    "\n",
    "    def log_state(self, learning_state, context_state):\n",
    "        self.prev_learning_states.append(learning_state)\n",
    "        self.prev_context_states.append(context_state)\n",
    "\n",
    "    def update_position(self, x, y):\n",
    "        self.last_positions.append((int(x), int(y)))\n",
    "    \n",
    "    def get_tile_interaction_stats(self, map_id):\n",
    "        memory = self.get_current_map_memory(map_id)\n",
    "        tile_interactions = memory.get('tile_interactions', {})\n",
    "        return {\n",
    "            'probed': len(tile_interactions),\n",
    "            'exhausted': sum(1 for t in tile_interactions.values() if t.get('exhausted', False)),\n",
    "            'with_success': sum(1 for t in tile_interactions.values() if any(t.get('direction_successes', {}).get(d, 0) > 0 for d in range(4)))\n",
    "        }\n",
    "\n",
    "    def load_taught_model(self, filepath):\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                model = json.load(f)\n",
    "            \n",
    "            if \"perceptrons\" not in model:\n",
    "                print(f\"  ‚ö†Ô∏è Model file empty or invalid, starting fresh\")\n",
    "                return 0\n",
    "            \n",
    "            for saved_action in model[\"perceptrons\"][\"actions\"]:\n",
    "                for a in self.actions():\n",
    "                    if a.action == saved_action[\"action\"]:\n",
    "                        a.utility = saved_action[\"utility\"]\n",
    "                        a.learning_rate = saved_action.get(\"learning_rate\", 0.01)\n",
    "                        a.familiarity = saved_action.get(\"familiarity\", 0.0)\n",
    "                        if saved_action.get(\"weights_nonzero\"):\n",
    "                            dim = saved_action.get(\"weights_shape\", 1376)\n",
    "                            a.weights = np.zeros(dim)\n",
    "                            for idx, val in saved_action[\"weights_nonzero\"]:\n",
    "                                if idx < dim:\n",
    "                                    a.weights[idx] = val\n",
    "                        break\n",
    "                    if a.action in ['Start', 'Select'] and a.weights is not None:\n",
    "                        a.weights = np.zeros(len(a.weights))\n",
    "                        a.utility = 0.05\n",
    "            \n",
    "            for saved_entity in model[\"perceptrons\"].get(\"entities\", []):\n",
    "                for e in self.entities():\n",
    "                    if e.entity_type == saved_entity[\"entity_type\"]:\n",
    "                        e.utility = saved_entity.get(\"utility\", 1.0)\n",
    "                        e.familiarity = saved_entity.get(\"familiarity\", 0.0)\n",
    "                        if saved_entity.get(\"weights_nonzero\"):\n",
    "                            dim = saved_entity.get(\"weights_shape\", 1376)\n",
    "                            e.weights = np.zeros(dim)\n",
    "                            for idx, val in saved_entity[\"weights_nonzero\"]:\n",
    "                                if idx < dim:\n",
    "                                    e.weights[idx] = val\n",
    "                        break\n",
    "            \n",
    "            if \"debt_tracking\" in model:\n",
    "                debt = model[\"debt_tracking\"]\n",
    "                self.map_novelty_debt = {int(k): v for k, v in debt.get(\"map_novelty_debt\", {}).items()}\n",
    "                self.visited_maps = {int(k): v for k, v in debt.get(\"visited_maps\", {}).items()}\n",
    "                for k, v in debt.get(\"location_novelty\", {}).items():\n",
    "                    self.location_novelty[eval(k)] = v\n",
    "            \n",
    "            loaded_timestep = model.get(\"timestep\", 0)\n",
    "            self.timestep = loaded_timestep\n",
    "            return loaded_timestep\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Error loading model: {e}, starting fresh\")\n",
    "            return 0\n",
    "\n",
    "    def merge_taught_exploration(self, taught_filepath):\n",
    "        if not Path(taught_filepath).exists():\n",
    "            print(f\"  No taught exploration memory found at {taught_filepath}\")\n",
    "            return\n",
    "        \n",
    "        with open(taught_filepath, 'r') as f:\n",
    "            taught_data = json.load(f)\n",
    "        \n",
    "        transitions_added = 0\n",
    "        interactables_added = 0\n",
    "        \n",
    "        for map_key, taught_map in taught_data.items():\n",
    "            map_id = int(map_key.replace('map_', ''))\n",
    "            ai_map = self.get_current_map_memory(map_id)\n",
    "            \n",
    "            for t_trans in taught_map.get('transitions', []):\n",
    "                t_pos = tuple(t_trans['position'])\n",
    "                t_dir = t_trans['direction']\n",
    "                exists = any(\n",
    "                    tuple(existing['position']) == t_pos and existing['direction'] == t_dir\n",
    "                    for existing in ai_map['transitions']\n",
    "                )\n",
    "                if not exists:\n",
    "                    ai_map['transitions'].append(t_trans)\n",
    "                    transitions_added += 1\n",
    "            \n",
    "            for t_inter in taught_map.get('interactable_objects', []):\n",
    "                if t_inter not in ai_map['interactable_objects']:\n",
    "                    ai_map['interactable_objects'].append(t_inter)\n",
    "                    interactables_added += 1\n",
    "        \n",
    "        print(f\"  Merged: {transitions_added} transitions, {interactables_added} interactables\")\n",
    "    \n",
    "    def save_model_checkpoint(self, filepath):\n",
    "        model = {\n",
    "            \"timestep\": self.timestep,\n",
    "            \"perceptrons\": {\"actions\": [], \"entities\": []},\n",
    "            \"debt_tracking\": {\n",
    "                \"map_novelty_debt\": {str(k): v for k, v in self.map_novelty_debt.items()},\n",
    "                \"location_novelty\": {str(k): v for k, v in self.location_novelty.items()},\n",
    "                \"visited_maps\": {str(k): v for k, v in self.visited_maps.items()}\n",
    "            },\n",
    "            \"control_mode\": self.control_mode,\n",
    "            \"markov_stats\": {\n",
    "                \"markov_action_count\": self.markov_action_count,\n",
    "                \"curiosity_action_count\": self.curiosity_action_count\n",
    "            },\n",
    "            \"blend_stats\": {\n",
    "                \"blend_count\": self.blend_count,\n",
    "                \"last_blend_tier\": self.blend_tier\n",
    "            },\n",
    "            \"battle_stats\": {\n",
    "                \"battle_action_count\": self.battle_action_count,\n",
    "                \"battle_markov_action_count\": self.battle_markov_action_count,\n",
    "                \"current_battle_id\": self.current_battle_id\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for a in self.actions():\n",
    "            action_data = {\n",
    "                \"action\": a.action,\n",
    "                \"group\": a.group,\n",
    "                \"utility\": float(a.utility),\n",
    "                \"weights_shape\": len(a.weights) if a.weights is not None else 0,\n",
    "                \"weights_nonzero\": [[i, float(v)] for i, v in enumerate(a.weights) if abs(v) > 1e-10] if a.weights is not None else [],\n",
    "                \"learning_rate\": float(a.learning_rate),\n",
    "                \"familiarity\": float(a.familiarity)\n",
    "            }\n",
    "            model[\"perceptrons\"][\"actions\"].append(action_data)\n",
    "        \n",
    "        for e in self.entities():\n",
    "            entity_data = {\n",
    "                \"entity_type\": e.entity_type,\n",
    "                \"utility\": float(e.utility),\n",
    "                \"weights_shape\": len(e.weights) if e.weights is not None else 0,\n",
    "                \"weights_nonzero\": [[i, float(v)] for i, v in enumerate(e.weights) if abs(v) > 1e-10] if e.weights is not None else [],\n",
    "                \"familiarity\": float(e.familiarity)\n",
    "            }\n",
    "            model[\"perceptrons\"][\"entities\"].append(entity_data)\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(model, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71630ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Action Selection - Battle + Cross-Map Nav + Markov + Curiosity\n",
    "# ============================================================================\n",
    "# CHANGES:\n",
    "# 1. battle_action() ‚Äî separate battle handler (Markov + A fallback)\n",
    "# 2. Battle intercept at top of anticipatory_action()\n",
    "# 3. Navigation section handles paused state ‚Äî lets curiosity run when\n",
    "#    nav is paused waiting for transition discovery\n",
    "# ============================================================================\n",
    "\n",
    "import random\n",
    "\n",
    "GBA_ACTIONS = [\"Up\", \"Down\", \"Left\", \"Right\", \"A\", \"B\", \"Start\", \"Select\"]\n",
    "ACTION_DELTAS = {\"UP\": (0, -1), \"DOWN\": (0, 1), \"LEFT\": (-1, 0), \"RIGHT\": (1, 0)}\n",
    "DIRECTION_TO_ACTION = {0: \"DOWN\", 1: \"UP\", 2: \"LEFT\", 3: \"RIGHT\"}\n",
    "ACTION_TO_DIRECTION = {\"DOWN\": 0, \"UP\": 1, \"LEFT\": 2, \"RIGHT\": 3}\n",
    "\n",
    "def manhattan_distance(pos1, pos2):\n",
    "    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# BATTLE ACTION ‚Äî Completely isolated from overworld logic\n",
    "# ============================================================================\n",
    "\n",
    "def battle_action(brain, context_state, palette_state=None):\n",
    "    \"\"\"\n",
    "    Battle-only action selection. Called when in_battle > 0.5.\n",
    "    \n",
    "    COMPLETELY ISOLATED from overworld:\n",
    "    - No navigation, curiosity, stagnation, forced random, mode switching\n",
    "    \n",
    "    Strategy:\n",
    "    1. Markov match against taught battle frames\n",
    "    2. If match ‚Üí return that action\n",
    "    3. If no match ‚Üí press A (advances text, selects default menu options)\n",
    "    4. No randomness ‚Äî deterministic fallback\n",
    "    \"\"\"\n",
    "    actions_list = brain.actions()\n",
    "    \n",
    "    brain.battle_frame_count += 1\n",
    "    brain.battle_action_count += 1\n",
    "    \n",
    "    matched, action_name, score = brain.get_battle_markov_action(\n",
    "        context_state, palette_state\n",
    "    )\n",
    "    \n",
    "    if matched and action_name:\n",
    "        if action_name in [\"START\", \"SELECT\"]:\n",
    "            action_name = \"A\"\n",
    "        \n",
    "        brain.battle_markov_action_count += 1\n",
    "        brain.last_battle_markov_action = action_name\n",
    "        \n",
    "        for a in actions_list:\n",
    "            if a.action == action_name:\n",
    "                brain.record_action_execution(a.action)\n",
    "                brain.track_consecutive_action(a.action)\n",
    "                brain.battle_action_history.append(a.action)\n",
    "                return a\n",
    "    \n",
    "    for a in actions_list:\n",
    "        if a.action == \"A\":\n",
    "            brain.record_action_execution(a.action)\n",
    "            brain.track_consecutive_action(a.action)\n",
    "            brain.battle_action_history.append(a.action)\n",
    "            return a\n",
    "    \n",
    "    return actions_list[0]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CURIOSITY OVERRIDE CHECK (overworld only)\n",
    "# ============================================================================\n",
    "\n",
    "def _check_curiosity_override(brain, learning_state, context_state, raw_position, map_density):\n",
    "    \"\"\"\n",
    "    Check if curiosity detects something novel enough to override navigation.\n",
    "    Returns True if curiosity should take over.\n",
    "    \"\"\"\n",
    "    raw_x = raw_position[0] if raw_position else int(context_state[0] * 255)\n",
    "    raw_y = raw_position[1] if raw_position else int(context_state[1] * 255)\n",
    "    current_map = int(context_state[2])\n",
    "    \n",
    "    memory = brain.get_current_map_memory(current_map)\n",
    "    \n",
    "    if (raw_x, raw_y) not in memory['visited_tiles']:\n",
    "        return True\n",
    "    \n",
    "    if brain.should_interact_at_tile(raw_x, raw_y, current_map):\n",
    "        untried = brain.get_untried_directions(raw_x, raw_y, current_map)\n",
    "        if untried:\n",
    "            return True\n",
    "    \n",
    "    if context_state[3] <= 0.5 and context_state[4] <= 0.5 and brain.entities():\n",
    "        entity_signal = np.mean([abs(e.predict(learning_state)) * e.utility for e in brain.entities()])\n",
    "        density = map_density or {'tier': 'medium'}\n",
    "        novelty_threshold = {\n",
    "            'sparse': 0.15, 'thin': 0.25, 'medium': 0.35, 'dense': 0.45\n",
    "        }.get(density['tier'], 0.35)\n",
    "        \n",
    "        if entity_signal > novelty_threshold:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN ACTION SELECTION ‚Äî Battle intercept at top\n",
    "# ============================================================================\n",
    "\n",
    "def anticipatory_action(brain, learning_state, context_state, \n",
    "                       exploration_weight=1.3, min_interact_prob=0.15,\n",
    "                       raw_position=None,\n",
    "                       forced_explore_prob=0.18,\n",
    "                       override_threshold=1.5,\n",
    "                       taught_frames=None,\n",
    "                       map_density=None,\n",
    "                       palette_state=None):\n",
    "    \"\"\"\n",
    "    ACTION SELECTION HIERARCHY:\n",
    "    0. BATTLE THREAD (if in_battle ‚Äî Markov only, no overworld logic)\n",
    "    1. Forced random + blend (when badly stuck)\n",
    "    2. Navigation mode (single-map A* or cross-map chain)\n",
    "       - Paused nav: curiosity/exploration runs while waiting for transitions\n",
    "       - Curiosity can override if something novel detected\n",
    "    3. Markov imitation (familiar taught situation)\n",
    "    4. Curiosity exploration (default)\n",
    "    \"\"\"\n",
    "    actions_list = brain.actions()\n",
    "    if not actions_list:\n",
    "        return Perceptron(\"action\", action=\"UP\", group=\"move\")\n",
    "\n",
    "    # =================================================================\n",
    "    # === 0. BATTLE INTERCEPT ‚Äî before ALL overworld logic ===\n",
    "    # =================================================================\n",
    "    in_battle = context_state[3] > 0.5\n",
    "    \n",
    "    if in_battle:\n",
    "        return battle_action(brain, context_state, palette_state)\n",
    "\n",
    "    # =================================================================\n",
    "    # === OVERWORLD LOGIC BELOW ‚Äî only runs when NOT in battle ===\n",
    "    # =================================================================\n",
    "\n",
    "    # === ADAPT THRESHOLDS TO DATA DENSITY ===\n",
    "    density = map_density or {'taught_frames': 0, 'tier': 'sparse', 'coverage': 0.0, 'visited': 0}\n",
    "    tier = density['tier']\n",
    "    \n",
    "    markov_threshold = {\n",
    "        'sparse': 0.72, 'thin': 0.65, 'medium': 0.58, 'dense': 0.50\n",
    "    }.get(tier, MARKOV_FAMILIARITY_THRESHOLD)\n",
    "    \n",
    "    adapted_explore_prob = {\n",
    "        'sparse': 0.30, 'thin': 0.24, 'medium': 0.18, 'dense': 0.12\n",
    "    }.get(tier, forced_explore_prob)\n",
    "    \n",
    "    adapted_exploration_weight = {\n",
    "        'sparse': 1.8, 'thin': 1.5, 'medium': 1.3, 'dense': 1.1\n",
    "    }.get(tier, exploration_weight)\n",
    "    \n",
    "    transition_weight_mult = {\n",
    "        'sparse': 0.3, 'thin': 0.6, 'medium': 1.0, 'dense': 1.4\n",
    "    }.get(tier, 1.0)\n",
    "\n",
    "    raw_x = raw_position[0] if raw_position else int(context_state[0] * 255)\n",
    "    raw_y = raw_position[1] if raw_position else int(context_state[1] * 255)\n",
    "    current_map = int(context_state[2])\n",
    "    current_dir = int(context_state[5])\n",
    "    current_pos = (raw_x, raw_y)\n",
    "\n",
    "    # === 1. FORCED RANDOMIZATION + BLEND (highest priority when stuck) ===\n",
    "    brain.check_state_stagnation(context_state)\n",
    "    \n",
    "    if brain.should_force_random():\n",
    "        if brain.is_nav_active():\n",
    "            brain.abort_navigation(\"forced random triggered\")\n",
    "        \n",
    "        forced_name = brain.get_forced_random_action_name()\n",
    "        for a in actions_list:\n",
    "            if a.action == forced_name:\n",
    "                brain.curiosity_action_count += 1\n",
    "                brain.record_action_execution(a.action)\n",
    "                brain.track_consecutive_action(a.action)\n",
    "                print(f\"  üé≤ FORCED RANDOM: {forced_name} (pos_stag={brain.get_position_stagnation()}, \"\n",
    "                      f\"repeat={brain.consecutive_action_count}, pattern={brain.pattern_repeat_count})\")\n",
    "                return a\n",
    "\n",
    "    # === 2. NAVIGATION MODE ===\n",
    "    \n",
    "    if context_state[3] <= 0.5 and context_state[4] <= 0.5:\n",
    "        brain.update_known_area_counter(raw_x, raw_y, current_map)\n",
    "    \n",
    "    if not brain.is_nav_active() and brain.should_start_navigation():\n",
    "        if context_state[3] <= 0.5 and context_state[4] <= 0.5:\n",
    "            started = brain.start_navigation(current_pos, current_map)\n",
    "            if started:\n",
    "                brain.known_area_counter = 0\n",
    "    \n",
    "    if brain.is_nav_active():\n",
    "        # === PAUSED NAV: waiting for transition discovery ===\n",
    "        # Let curiosity/exploration run ‚Äî don't follow a path, don't abort\n",
    "        # The pause check happens inside update_nav_state\n",
    "        if brain.is_nav_paused():\n",
    "            # Still call update_nav_state so it checks for resume\n",
    "            brain.update_nav_state(current_pos, current_map)\n",
    "            # Fall through to Markov/Curiosity below ‚Äî explore freely\n",
    "        else:\n",
    "            # === ACTIVE NAV: following a path ===\n",
    "            if _check_curiosity_override(brain, learning_state, context_state, raw_position, map_density):\n",
    "                # Don't abort cross-map nav for curiosity ‚Äî just pause momentarily\n",
    "                if brain.nav_map_chain:\n",
    "                    pass  # Let nav continue ‚Äî cross-map takes priority over curiosity\n",
    "                else:\n",
    "                    brain.abort_navigation(\"curiosity override\")\n",
    "                    print(f\"  üß≠‚Üíüîç NAV interrupted: curiosity detected novelty at ({raw_x}, {raw_y})\")\n",
    "            else:\n",
    "                nav_continue = brain.update_nav_state(current_pos, current_map)\n",
    "                \n",
    "                if nav_continue:\n",
    "                    nav_action_name = brain.get_nav_action(current_pos)\n",
    "                    \n",
    "                    if nav_action_name:\n",
    "                        for a in actions_list:\n",
    "                            if a.action == nav_action_name:\n",
    "                                brain.curiosity_action_count += 1\n",
    "                                brain.record_action_execution(a.action)\n",
    "                                brain.track_consecutive_action(a.action)\n",
    "                                return a\n",
    "                    else:\n",
    "                        if not brain.nav_paused:\n",
    "                            brain.abort_navigation(\"path invalid\")\n",
    "    \n",
    "    # Handle nav curiosity window (arrived at target, letting curiosity check)\n",
    "    if brain.is_in_nav_curiosity_window():\n",
    "        window_expired = brain.tick_nav_curiosity_window()\n",
    "        \n",
    "        if window_expired:\n",
    "            memory = brain.get_current_map_memory(current_map)\n",
    "            tile_needs_probing = brain.should_interact_at_tile(raw_x, raw_y, current_map)\n",
    "            found_novelty = tile_needs_probing or (current_pos not in memory['visited_tiles'])\n",
    "            \n",
    "            brain.complete_nav_target(found_novelty)\n",
    "\n",
    "    # === 3. MARKOV CHECK (with adapted threshold) ===\n",
    "    use_markov = False\n",
    "    markov_action = None\n",
    "    markov_confidence = 0.0\n",
    "    \n",
    "    if brain.markov_enabled and taught_frames:\n",
    "        score, action, idx = brain.compute_markov_similarity(\n",
    "            context_state, raw_position, taught_frames=taught_frames\n",
    "        )\n",
    "        brain.last_markov_score = score\n",
    "        \n",
    "        if score >= markov_threshold and action:\n",
    "            use_markov = True\n",
    "            markov_action = action\n",
    "            markov_confidence = score\n",
    "            brain.last_markov_action = action\n",
    "    \n",
    "    if use_markov and markov_action:\n",
    "        for a in actions_list:\n",
    "            if a.action == markov_action:\n",
    "                brain.markov_action_count += 1\n",
    "                brain.record_action_execution(a.action)\n",
    "                brain.track_consecutive_action(a.action)\n",
    "                \n",
    "                if a.action == 'A':\n",
    "                    if brain.should_interact_at_tile(raw_x, raw_y, current_map):\n",
    "                        brain.start_interaction_verification(\n",
    "                            raw_x, raw_y, current_map, int(context_state[5])\n",
    "                        )\n",
    "                \n",
    "                return a\n",
    "\n",
    "    # === 4. CURIOSITY-DRIVEN SELECTION (default) ===\n",
    "    brain.curiosity_action_count += 1\n",
    "    \n",
    "    mode = brain.determine_control_mode(context_state, raw_position=raw_position)\n",
    "    \n",
    "    memory = brain.get_current_map_memory(current_map)\n",
    "    visited_tiles = memory['visited_tiles']\n",
    "    obstructions = memory['obstructions']\n",
    "    \n",
    "    tile_needs_probing = brain.should_interact_at_tile(raw_x, raw_y, current_map)\n",
    "    probe_action, probe_dir = brain.get_best_probe_action(raw_x, raw_y, current_map, current_dir)\n",
    "    \n",
    "    transition_attraction, best_transition = brain.get_transition_attraction(current_map)\n",
    "    coverage = brain.get_exploration_coverage(current_map)\n",
    "\n",
    "    # Forced random exploration (adapted to density)\n",
    "    if random.random() < adapted_explore_prob:\n",
    "        valid = [a for a in actions_list if a.action not in ['Start', 'Select']]\n",
    "        chosen = random.choice(valid)\n",
    "        brain.record_action_execution(chosen.action)\n",
    "        brain.track_consecutive_action(chosen.action)\n",
    "        if chosen.action == 'A' and tile_needs_probing:\n",
    "            brain.start_interaction_verification(raw_x, raw_y, current_map, current_dir)\n",
    "        return chosen\n",
    "\n",
    "    # Score ALL actions\n",
    "    action_scores = {}\n",
    "    \n",
    "    for a in actions_list:\n",
    "        if a.action in ['Start', 'Select']:\n",
    "            action_scores[a.action] = (a, 0.0)\n",
    "            continue\n",
    "            \n",
    "        predicted = brain.predict_future_error(learning_state, a, context_state, raw_position=raw_position)\n",
    "        \n",
    "        if a.group == \"move\":\n",
    "            predicted *= adapted_exploration_weight\n",
    "            \n",
    "            dx, dy = ACTION_DELTAS.get(a.action, (0, 0))\n",
    "            target_tile = (raw_x + dx, raw_y + dy)\n",
    "            action_direction = ACTION_TO_DIRECTION.get(a.action, -1)\n",
    "            \n",
    "            if target_tile not in visited_tiles:\n",
    "                predicted *= brain.UNVISITED_TILE_BONUS\n",
    "            \n",
    "            if target_tile in obstructions:\n",
    "                predicted *= brain.OBSTRUCTION_PENALTY\n",
    "            \n",
    "            if brain.is_position_banned(current_map, raw_x, raw_y, action_direction):\n",
    "                predicted *= 0.05\n",
    "            \n",
    "            if transition_attraction > 0.3 and best_transition and coverage > 0.5:\n",
    "                trans_pos = tuple(best_transition['position']) if isinstance(best_transition['position'], list) else best_transition['position']\n",
    "                if manhattan_distance(target_tile, trans_pos) < manhattan_distance(current_pos, trans_pos):\n",
    "                    predicted *= (1.0 + transition_attraction * transition_weight_mult)\n",
    "            \n",
    "            if probe_action == a.action and probe_dir is not None:\n",
    "                predicted *= 2.0\n",
    "            \n",
    "            predicted *= (0.9 + random.random() * 0.2)\n",
    "        \n",
    "        elif a.group == \"interact\":\n",
    "            predicted = max(predicted, min_interact_prob)\n",
    "            \n",
    "            if a.action == 'B':\n",
    "                predicted *= brain.menu_trap_b_boost\n",
    "            \n",
    "            if a.action == 'A':\n",
    "                if tile_needs_probing and probe_action == 'A':\n",
    "                    predicted *= 3.0\n",
    "                elif tile_needs_probing:\n",
    "                    predicted *= 0.5\n",
    "                else:\n",
    "                    predicted *= 0.3\n",
    "        \n",
    "        action_scores[a.action] = (a, predicted)\n",
    "\n",
    "    # Find best in-mode and best out-of-mode\n",
    "    if mode == \"battle\":\n",
    "        preferred_group = \"interact\"\n",
    "    elif mode == \"interact\":\n",
    "        preferred_group = \"interact\"\n",
    "    else:\n",
    "        preferred_group = \"move\"\n",
    "    \n",
    "    in_mode = [(a, s) for name, (a, s) in action_scores.items() if a.group == preferred_group and s > 0]\n",
    "    out_mode = [(a, s) for name, (a, s) in action_scores.items() if a.group != preferred_group and s > 0 and a.action not in ['Start', 'Select']]\n",
    "    \n",
    "    best_in_mode = max(in_mode, key=lambda x: x[1]) if in_mode else None\n",
    "    best_out_mode = max(out_mode, key=lambda x: x[1]) if out_mode else None\n",
    "    \n",
    "    chosen = None\n",
    "    \n",
    "    if best_in_mode and best_out_mode:\n",
    "        if best_out_mode[1] > best_in_mode[1] * override_threshold:\n",
    "            chosen = best_out_mode[0]\n",
    "        else:\n",
    "            chosen = best_in_mode[0]\n",
    "    elif best_in_mode:\n",
    "        chosen = best_in_mode[0]\n",
    "    elif best_out_mode:\n",
    "        chosen = best_out_mode[0]\n",
    "    else:\n",
    "        chosen = max(actions_list, key=lambda a: a.utility)\n",
    "    \n",
    "    brain.record_action_execution(chosen.action)\n",
    "    brain.track_consecutive_action(chosen.action)\n",
    "    \n",
    "    if chosen.action == 'A' and tile_needs_probing:\n",
    "        brain.start_interaction_verification(raw_x, raw_y, current_map, current_dir)\n",
    "    \n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Cache System - MapCache, CacheManager, IOThread\n",
    "# ============================================================================\n",
    "# NEW CELL - Layer on top of existing code, no rewrites\n",
    "#\n",
    "# MapCache: Per-map data container (exploration + taught transitions + live state)\n",
    "# CacheManager: Indexes all maps at startup, handles switching\n",
    "# IOThread: Background file I/O decoupled from Brain\n",
    "# ============================================================================\n",
    "\n",
    "import threading\n",
    "import gc\n",
    "\n",
    "class MapCache:\n",
    "    \"\"\"Thread-safe container for one map's data.\"\"\"\n",
    "\n",
    "    def __init__(self, map_id):\n",
    "        self.map_id = map_id\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "        # From exploration_memory[map_id] - synced to/from Brain\n",
    "        self.exploration_data = None  # Set by CacheManager\n",
    "\n",
    "        # From taught_transitions filtered by map_id\n",
    "        self.taught_frames = []\n",
    "\n",
    "        # Live state (IOThread writes, Brain reads)\n",
    "        self.current_state = np.zeros(EXPECTED_STATE_DIM)\n",
    "        self.palette = np.zeros(PALETTE_DIM)\n",
    "        self.tiles = np.zeros(TILE_DIM)\n",
    "        self.raw_position = (0, 0)\n",
    "        self.dead = False\n",
    "        self.state_fresh = False  # True when IOThread wrote new state\n",
    "        self.state_version = 0    # Increments each IOThread write\n",
    "\n",
    "        # Pending action (Brain writes, IOThread reads)\n",
    "        self.pending_action_out = None  # Action to write to file\n",
    "\n",
    "    def get_state(self):\n",
    "        with self.lock:\n",
    "            return (\n",
    "                self.current_state.copy(),\n",
    "                self.palette.copy(),\n",
    "                self.tiles.copy(),\n",
    "                self.dead,\n",
    "                self.raw_position\n",
    "            )\n",
    "\n",
    "    def update_state(self, context_state, palette, tiles, dead, raw_position):\n",
    "        with self.lock:\n",
    "            self.current_state = context_state\n",
    "            self.palette = palette\n",
    "            self.tiles = tiles\n",
    "            self.dead = dead\n",
    "            self.raw_position = raw_position\n",
    "            self.state_fresh = True\n",
    "            self.state_version += 1\n",
    "\n",
    "    def is_fresh(self):\n",
    "        with self.lock:\n",
    "            return self.state_fresh\n",
    "\n",
    "    def mark_consumed(self):\n",
    "        with self.lock:\n",
    "            self.state_fresh = False\n",
    "\n",
    "    def get_version(self):\n",
    "        with self.lock:\n",
    "            return self.state_version\n",
    "\n",
    "    def set_pending_action(self, action_name):\n",
    "        with self.lock:\n",
    "            self.pending_action_out = action_name\n",
    "\n",
    "    def get_pending_action(self):\n",
    "        with self.lock:\n",
    "            a = self.pending_action_out\n",
    "            self.pending_action_out = None\n",
    "            return a\n",
    "\n",
    "    def get_taught_frames(self):\n",
    "        \"\"\"Return taught transitions for this map (no lock needed, read-only after init).\"\"\"\n",
    "        return self.taught_frames\n",
    "\n",
    "\n",
    "class CacheManager:\n",
    "    \"\"\"Manages all MapCaches. Pre-indexes at startup, handles map switching.\"\"\"\n",
    "\n",
    "    def __init__(self, brain):\n",
    "        self.brain = brain\n",
    "        self.caches = {}        # map_id -> MapCache\n",
    "        self.active_cache = None\n",
    "        self.active_map_id = None\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def load_all(self, exploration_path=None, taught_path=None):\n",
    "        \"\"\"\n",
    "        Startup: Load exploration memory + taught transitions,\n",
    "        create MapCache for each map, index taught frames by map.\n",
    "        \"\"\"\n",
    "        exploration_path = exploration_path or EXPLORATION_MEMORY_FILE\n",
    "        taught_path = taught_path or TAUGHT_TRANSITIONS_FILE\n",
    "\n",
    "        # 1. Exploration memory is already loaded in Brain\n",
    "        for map_id, mem_data in self.brain.exploration_memory.items():\n",
    "            cache = self._get_or_create(map_id)\n",
    "            cache.exploration_data = mem_data\n",
    "\n",
    "        # 2. Index taught transitions by map_id\n",
    "        taught_by_map = {}\n",
    "        for t in self.brain.taught_transitions:\n",
    "            t_map = t.get('state', {}).get('map_id')\n",
    "            if t_map is not None:\n",
    "                taught_by_map.setdefault(t_map, []).append(t)\n",
    "\n",
    "        for map_id, frames in taught_by_map.items():\n",
    "            cache = self._get_or_create(map_id)\n",
    "            cache.taught_frames = frames\n",
    "\n",
    "        total_maps = len(self.caches)\n",
    "        total_taught = sum(len(c.taught_frames) for c in self.caches.values())\n",
    "        print(f\"  üì¶ CacheManager: {total_maps} maps cached, {total_taught} taught frames indexed\")\n",
    "\n",
    "    def _get_or_create(self, map_id):\n",
    "        if map_id not in self.caches:\n",
    "            self.caches[map_id] = MapCache(map_id)\n",
    "        return self.caches[map_id]\n",
    "\n",
    "    def get_active(self):\n",
    "        return self.active_cache\n",
    "\n",
    "    def detect_and_set_initial_map(self):\n",
    "        \"\"\"Read game_state.json once to determine starting map.\"\"\"\n",
    "        ctx, pal, til, dead, raw_pos = read_game_state()\n",
    "        map_id = int(ctx[2])\n",
    "        self._switch_to(map_id)\n",
    "        # Seed the active cache with the initial state\n",
    "        self.active_cache.update_state(ctx, pal, til, dead, raw_pos)\n",
    "        print(f\"  üì¶ Initial map: {map_id}\")\n",
    "        return map_id\n",
    "\n",
    "    def switch_map(self, new_map_id):\n",
    "        \"\"\"Called by main thread when map changes.\"\"\"\n",
    "        if new_map_id == self.active_map_id:\n",
    "            return\n",
    "        self._sync_from_brain()  # Save Brain's exploration data back to current cache\n",
    "        self._switch_to(new_map_id)\n",
    "        self._sync_to_brain()    # Load new cache's data into Brain\n",
    "\n",
    "    def _switch_to(self, map_id):\n",
    "        with self.lock:\n",
    "            cache = self._get_or_create(map_id)\n",
    "            self.active_cache = cache\n",
    "            self.active_map_id = map_id\n",
    "\n",
    "    def _sync_to_brain(self):\n",
    "        \"\"\"Push active cache's exploration data into Brain.\"\"\"\n",
    "        cache = self.active_cache\n",
    "        if cache and cache.exploration_data is not None:\n",
    "            self.brain.exploration_memory[cache.map_id] = cache.exploration_data\n",
    "\n",
    "    def _sync_from_brain(self):\n",
    "        \"\"\"Pull Brain's exploration data into active cache.\"\"\"\n",
    "        cache = self.active_cache\n",
    "        if cache and cache.map_id in self.brain.exploration_memory:\n",
    "            cache.exploration_data = self.brain.exploration_memory[cache.map_id]\n",
    "\n",
    "    def sync_all_from_brain(self):\n",
    "        \"\"\"Sync ALL maps from Brain back to caches (for saving).\"\"\"\n",
    "        for map_id, mem_data in self.brain.exploration_memory.items():\n",
    "            cache = self._get_or_create(map_id)\n",
    "            cache.exploration_data = mem_data\n",
    "\n",
    "    def save_exploration_memory(self):\n",
    "        \"\"\"Save all maps' exploration data to disk.\"\"\"\n",
    "        self._sync_from_brain()  # Make sure current map is synced\n",
    "        self.brain.save_exploration_memory()\n",
    "\n",
    "    def get_active_taught_frames(self):\n",
    "        \"\"\"Return taught frames for current map only (for fast Markov scan).\"\"\"\n",
    "        if self.active_cache:\n",
    "            return self.active_cache.get_taught_frames()\n",
    "        return []\n",
    "\n",
    "    def get_map_density(self):\n",
    "        \"\"\"\n",
    "        Returns a density dict for the active map, used to adapt thresholds.\n",
    "        \n",
    "        Density tiers:\n",
    "          sparse:  < 50 taught frames\n",
    "          thin:    50-200\n",
    "          medium:  200-1000\n",
    "          dense:   1000+\n",
    "          \n",
    "        Also includes exploration coverage and visited tile count.\n",
    "        \"\"\"\n",
    "        if not self.active_cache:\n",
    "            return {'taught_frames': 0, 'tier': 'sparse', 'coverage': 0.0, 'visited': 0}\n",
    "        \n",
    "        n_frames = len(self.active_cache.get_taught_frames())\n",
    "        map_id = self.active_map_id\n",
    "        \n",
    "        # Exploration data from brain\n",
    "        coverage = self.brain.get_exploration_coverage(map_id) if map_id is not None else 0.0\n",
    "        memory = self.brain.get_current_map_memory(map_id) if map_id is not None else {}\n",
    "        visited = len(memory.get('visited_tiles', set()))\n",
    "        \n",
    "        if n_frames < 50:\n",
    "            tier = 'sparse'\n",
    "        elif n_frames < 200:\n",
    "            tier = 'thin'\n",
    "        elif n_frames < 1000:\n",
    "            tier = 'medium'\n",
    "        else:\n",
    "            tier = 'dense'\n",
    "        \n",
    "        return {\n",
    "            'taught_frames': n_frames,\n",
    "            'tier': tier,\n",
    "            'coverage': coverage,\n",
    "            'visited': visited\n",
    "        }\n",
    "\n",
    "\n",
    "class IOThread(threading.Thread):\n",
    "    \"\"\"Background thread: reads game_state.json, writes action.json.\"\"\"\n",
    "\n",
    "    def __init__(self, cache_manager, interval=0.02, gc_interval=300):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cm = cache_manager\n",
    "        self.interval = interval\n",
    "        self.gc_interval = gc_interval  # GC every N iterations\n",
    "        self.running = False\n",
    "        self._iteration = 0\n",
    "\n",
    "    def run(self):\n",
    "        self.running = True\n",
    "        print(f\"  üîÑ IOThread started (interval={self.interval*1000:.0f}ms)\")\n",
    "\n",
    "        while self.running:\n",
    "            try:\n",
    "                cache = self.cm.get_active()\n",
    "                if cache is None:\n",
    "                    time.sleep(self.interval)\n",
    "                    continue\n",
    "\n",
    "                # --- READ game_state.json ---\n",
    "                ctx, pal, til, dead, raw_pos = read_game_state()\n",
    "                cache.update_state(ctx, pal, til, dead, raw_pos)\n",
    "\n",
    "                # --- WRITE action.json ---\n",
    "                action = cache.get_pending_action()\n",
    "                if action is not None:\n",
    "                    write_action(action)\n",
    "\n",
    "                # --- PERIODIC GC ---\n",
    "                self._iteration += 1\n",
    "                if self._iteration % self.gc_interval == 0:\n",
    "                    gc.collect()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  [IOThread ERROR] {e}\")\n",
    "\n",
    "            time.sleep(self.interval)\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        print(\"  üîÑ IOThread stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1cb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Main Loop - Battle + Cross-Map Nav + Cache + Blend\n",
    "# ============================================================================\n",
    "# CHANGES:\n",
    "# 1. Load battle transitions at startup\n",
    "# 2. Battle start/end detection and logging\n",
    "# 3. Pass palette_state to anticipatory_action for battle Markov\n",
    "# 4. Cross-map nav: advance_map_chain() on map change\n",
    "# 5. Cross-map nav status in logging\n",
    "# 6. Map graph info in startup banner and milestones\n",
    "# ============================================================================\n",
    "\n",
    "brain = Brain()\n",
    "\n",
    "for b in [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]:\n",
    "    brain.add(Perceptron(\"action\", action=b, group=\"move\"))\n",
    "for b in [\"A\", \"B\", \"Start\", \"Select\"]:\n",
    "    brain.add(Perceptron(\"action\", action=b, group=\"interact\"))\n",
    "\n",
    "# === FILE PATHS ===\n",
    "TAUGHT_MODEL_PATH = BASE_PATH / \"taught_model_checkpoint.json\"\n",
    "TAUGHT_EXPLORATION_PATH = BASE_PATH / \"taught_exploration_memory.json\"\n",
    "\n",
    "# === LOAD AI'S OWN MODEL (primary) ===\n",
    "if MODEL_CHECKPOINT_FILE.exists():\n",
    "    loaded_ts = brain.load_taught_model(MODEL_CHECKPOINT_FILE)\n",
    "    print(f\"ü§ñ AI MODEL: Loaded from timestep {loaded_ts}\")\n",
    "    print(f\"   Utilities: {[f'{a.action}:{a.utility:.3f}' for a in brain.actions()]}\")\n",
    "else:\n",
    "    print(\"ü§ñ AI MODEL: No existing model ‚Äî starting fresh\")\n",
    "\n",
    "# === LOAD TAUGHT REFERENCE (read-only, for stagnation blending) ===\n",
    "brain.load_taught_reference(TAUGHT_MODEL_PATH)\n",
    "\n",
    "# === MERGE TAUGHT EXPLORATION (additive) ===\n",
    "brain.merge_taught_exploration(TAUGHT_EXPLORATION_PATH)\n",
    "\n",
    "# === LOAD TAUGHT TRANSITIONS FOR OVERWORLD MARKOV ===\n",
    "brain.load_taught_transitions(TAUGHT_TRANSITIONS_FILE)\n",
    "\n",
    "# === LOAD TAUGHT BATTLE TRANSITIONS FOR BATTLE MARKOV ===\n",
    "brain.load_taught_battle_transitions(TAUGHT_BATTLE_TRANSITIONS_FILE)\n",
    "\n",
    "# === LOAD TAUGHT NAVIGATION TARGETS ===\n",
    "brain.load_taught_nav_targets(TAUGHT_NAV_TARGETS_FILE)\n",
    "\n",
    "# === BUILD INITIAL MAP GRAPH ===\n",
    "map_graph = brain.build_map_graph()\n",
    "graph_edges = sum(len(v) for v in map_graph.values())\n",
    "graph_maps = list(map_graph.keys())\n",
    "\n",
    "# === INITIALIZE CACHE SYSTEM ===\n",
    "cache_manager = CacheManager(brain)\n",
    "cache_manager.load_all()\n",
    "cache_manager.detect_and_set_initial_map()\n",
    "\n",
    "# === START I/O THREAD ===\n",
    "io_thread = IOThread(cache_manager, interval=0.02, gc_interval=300)\n",
    "io_thread.start()\n",
    "\n",
    "exploration_weight = 1.3\n",
    "forced_explore_prob = 0.18\n",
    "prev_context_state = None\n",
    "prev_raw_position = None\n",
    "last_processed_version = -1\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AI CONTROL - v12.0 (Battle + Cross-Map Nav + Markov + Cache + Blend)\")\n",
    "print(\"=\"*70)\n",
    "print(\"MODELS:\")\n",
    "print(f\"  - AI model: {MODEL_CHECKPOINT_FILE}\")\n",
    "print(f\"  - Taught reference: {TAUGHT_MODEL_PATH} ({'loaded' if brain.taught_reference['loaded'] else 'NOT FOUND'})\")\n",
    "if brain.taught_reference['loaded']:\n",
    "    taught_utils = ', '.join(f\"{k}:{v:.3f}\" for k, v in brain.taught_reference['utilities'].items())\n",
    "    print(f\"  - Taught utilities: {taught_utils}\")\n",
    "print(\"=\"*70)\n",
    "print(\"BATTLE SYSTEM:\")\n",
    "print(f\"  - Battle transitions: {'LOADED' if brain.battle_loaded else 'NOT FOUND (A-button fallback)'}\")\n",
    "if brain.battle_loaded:\n",
    "    print(f\"  - Battle frames: {len(brain.battle_transitions)}\")\n",
    "    print(f\"  - Battles recorded: {brain.battle_metadata.get('battles_recorded', 0)}\")\n",
    "    print(f\"  - Avg battle length: {brain.battle_metadata.get('avg_battle_length', 0)}\")\n",
    "    outcomes = brain.battle_metadata.get('outcomes', {})\n",
    "    if outcomes:\n",
    "        print(f\"  - Outcomes: win={outcomes.get('win',0)} run={outcomes.get('run',0)} loss={outcomes.get('loss',0)}\")\n",
    "    print(f\"  - Markov threshold: {BATTLE_MARKOV_THRESHOLD_LOW:.2f}-{BATTLE_MARKOV_THRESHOLD_HIGH:.2f}\")\n",
    "print(f\"  - Fallback action: A (advances text, selects defaults)\")\n",
    "print(f\"  - Isolated from: navigation, curiosity, stagnation, forced random\")\n",
    "print(\"=\"*70)\n",
    "print(\"CACHE SYSTEM:\")\n",
    "print(f\"  - Maps cached: {len(cache_manager.caches)}\")\n",
    "print(f\"  - Active map: {cache_manager.active_map_id}\")\n",
    "active_taught = len(cache_manager.get_active_taught_frames())\n",
    "print(f\"  - Active map taught frames: {active_taught}\")\n",
    "print(f\"  - Total taught frames: {len(brain.taught_transitions)}\")\n",
    "print(f\"  - IOThread interval: {io_thread.interval*1000:.0f}ms\")\n",
    "print(\"=\"*70)\n",
    "print(\"BLEND SYSTEM:\")\n",
    "print(f\"  - Tier 1 (light 80/20):  pattern 3+ | pos stuck 8+ | repeat 12+\")\n",
    "print(f\"  - Tier 2 (medium 60/40): pattern 6+ | pos stuck 15+ | repeat 15+\")\n",
    "print(f\"  - Tier 3 (hard 40/60):   pattern 10+ | state stag 2x threshold\")\n",
    "print(f\"  - Cooldown: {brain.BLEND_COOLDOWN} steps between blends\")\n",
    "print(\"=\"*70)\n",
    "print(\"NAVIGATION SYSTEM:\")\n",
    "print(f\"  - Known area trigger: {brain.KNOWN_AREA_TRIGGER} steps in visited tiles\")\n",
    "print(f\"  - Nav stagnation limit: {brain.NAV_STAGNATION_LIMIT} steps\")\n",
    "print(f\"  - Nav max steps: {brain.NAV_MAX_STEPS}\")\n",
    "print(f\"  - Curiosity window at target: {brain.NAV_CURIOSITY_WINDOW} steps\")\n",
    "print(f\"  - Learning dampening during nav: {brain.NAV_LEARNING_DAMPENING}\")\n",
    "nav_status = brain.get_nav_targets_status()\n",
    "if nav_status['loaded']:\n",
    "    print(f\"  - Taught targets: {nav_status['total']} across {list(brain.taught_nav_targets.keys())}\")\n",
    "else:\n",
    "    print(f\"  - Taught targets: NOT LOADED (using frontier fallback)\")\n",
    "print(f\"  CROSS-MAP:\")\n",
    "print(f\"  - Map graph: {len(graph_maps)} maps, {graph_edges} edges\")\n",
    "if graph_maps:\n",
    "    print(f\"  - Connected maps: {graph_maps}\")\n",
    "print(f\"  - Pause check interval: {brain.NAV_PAUSE_CHECK_INTERVAL} steps\")\n",
    "print(\"=\"*70)\n",
    "print(\"MARKOV SYSTEM (OVERWORLD):\")\n",
    "print(f\"  - Taught batches: {len(brain.taught_batches)}\")\n",
    "print(f\"  - Taught frames: {len(brain.taught_transitions)}\")\n",
    "print(f\"  - Density-adaptive thresholds: sparse=0.72 thin=0.65 medium=0.58 dense=0.50\")\n",
    "print(\"=\"*70)\n",
    "print(\"CURIOSITY SYSTEM:\")\n",
    "print(f\"  - Forced random exploration: {forced_explore_prob:.0%}\")\n",
    "print(f\"  - Unvisited tile bonus: {brain.UNVISITED_TILE_BONUS}x\")\n",
    "print(f\"  - Obstruction penalty: {brain.OBSTRUCTION_PENALTY}x\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # === WAIT FOR NEW STATE FROM IOTHREAD ===\n",
    "        active_cache = cache_manager.get_active()\n",
    "        current_version = active_cache.get_version()\n",
    "        \n",
    "        if current_version == last_processed_version:\n",
    "            time.sleep(0.005)\n",
    "            continue\n",
    "        \n",
    "        context_state, palette_state, tile_state, dead, raw_position = active_cache.get_state()\n",
    "        last_processed_version = current_version\n",
    "        \n",
    "        # Skip if zero state (IOThread hasn't started yet)\n",
    "        if np.sum(np.abs(context_state)) < 0.001:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "        \n",
    "        raw_x, raw_y = raw_position\n",
    "        in_battle = context_state[3]\n",
    "        current_map = int(context_state[2])\n",
    "        current_dir = int(context_state[5])\n",
    "        \n",
    "        # === BATTLE START/END DETECTION ===\n",
    "        currently_in_battle = in_battle > 0.5\n",
    "        \n",
    "        if currently_in_battle and not brain.in_battle_last_frame:\n",
    "            brain.current_battle_id += 1\n",
    "            brain.battle_frame_count = 0\n",
    "            brain.battle_action_history.clear()\n",
    "            print(f\"\\n  ‚öîÔ∏è BATTLE START (#{brain.current_battle_id}) at Map {current_map} ({raw_x}, {raw_y})\")\n",
    "            \n",
    "            if brain.is_nav_active():\n",
    "                brain.abort_navigation(\"battle started\")\n",
    "        \n",
    "        elif not currently_in_battle and brain.in_battle_last_frame:\n",
    "            battle_markov_rate = (brain.battle_markov_action_count / max(1, brain.battle_action_count))\n",
    "            print(f\"\\n  ‚öîÔ∏è BATTLE END (#{brain.current_battle_id}) ‚Äî {brain.battle_frame_count} frames\")\n",
    "            print(f\"     Battle Markov rate: {brain.battle_markov_action_count}/{brain.battle_action_count} \"\n",
    "                  f\"({battle_markov_rate:.1%})\")\n",
    "            brain.battle_frame_count = 0\n",
    "        \n",
    "        brain.in_battle_last_frame = currently_in_battle\n",
    "        \n",
    "        # === MAP CHANGE DETECTION ===\n",
    "        if not currently_in_battle and current_map != cache_manager.active_map_id:\n",
    "            old_map = cache_manager.active_map_id\n",
    "            cache_manager.switch_map(current_map)\n",
    "            active_cache = cache_manager.get_active()\n",
    "            print(f\"  üì¶ Cache switched to map {current_map} \"\n",
    "                  f\"(taught frames: {len(active_cache.get_taught_frames())})\")\n",
    "            \n",
    "            # === CROSS-MAP NAV: advance chain on map change ===\n",
    "            if brain.nav_map_chain and brain.is_nav_active() and not brain.is_nav_paused():\n",
    "                current_pos = (raw_x, raw_y)\n",
    "                chain_continues = brain.advance_map_chain(current_map, current_pos)\n",
    "                if not chain_continues:\n",
    "                    brain.abort_navigation(\"cross-map chain broken\")\n",
    "        \n",
    "        brain.update_position(raw_x, raw_y)\n",
    "\n",
    "        derived = compute_derived_features(context_state, prev_context_state)\n",
    "        learning_state = build_learning_state(derived, palette_state, tile_state, in_battle)\n",
    "        \n",
    "        brain.log_state(learning_state, context_state)\n",
    "        \n",
    "        # Action execution confirmation\n",
    "        brain.confirm_action_executed(context_state, prev_context_state)\n",
    "\n",
    "        if brain.should_send_new_action():\n",
    "            taught_frames = cache_manager.get_active_taught_frames()\n",
    "            map_density = cache_manager.get_map_density()\n",
    "            \n",
    "            action = anticipatory_action(\n",
    "                brain, learning_state, context_state,\n",
    "                exploration_weight=exploration_weight,\n",
    "                raw_position=raw_position,\n",
    "                forced_explore_prob=forced_explore_prob,\n",
    "                taught_frames=taught_frames,\n",
    "                map_density=map_density,\n",
    "                palette_state=palette_state\n",
    "            )\n",
    "\n",
    "            if action is not None:\n",
    "                active_cache.set_pending_action(action.action)\n",
    "                brain.last_action = action.action\n",
    "                brain.set_pending_action(action.action)\n",
    "                if not currently_in_battle:\n",
    "                    brain.update_menu_trap_tracking(context_state, action.action, raw_position=raw_position)\n",
    "            else:\n",
    "                active_cache.set_pending_action(\"NONE\")\n",
    "        else:\n",
    "            if brain.pending_action:\n",
    "                active_cache.set_pending_action(brain.pending_action)\n",
    "\n",
    "        # === LOGGING ===\n",
    "        if brain.timestep % 100 == 0:\n",
    "            memory = brain.get_current_map_memory(current_map)\n",
    "            visited_count = len(memory['visited_tiles'])\n",
    "            obs_count = len(memory['obstructions'])\n",
    "            interactables = len(memory['interactable_objects'])\n",
    "            coverage = brain.get_exploration_coverage(current_map)\n",
    "            transitions = memory.get('transitions', [])\n",
    "            tile_stats = brain.get_tile_interaction_stats(current_map)\n",
    "            \n",
    "            tile_needs_probing = brain.should_interact_at_tile(raw_x, raw_y, current_map)\n",
    "            probe_action, probe_dir = brain.get_best_probe_action(raw_x, raw_y, current_map, current_dir)\n",
    "            \n",
    "            dir_name = brain.DIRECTION_NAMES.get(current_dir, '?')\n",
    "            mode = brain.control_mode\n",
    "            is_both_mode = brain.should_use_both_mode()\n",
    "            mode_display = \"BOTH ‚ö°\" if is_both_mode else mode\n",
    "            \n",
    "            total_actions = brain.markov_action_count + brain.curiosity_action_count\n",
    "            markov_ratio = brain.markov_action_count / max(1, total_actions)\n",
    "            \n",
    "            density = cache_manager.get_map_density()\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"Step {brain.timestep} | Map {current_map} | Pos ({raw_x}, {raw_y}) facing {dir_name}\")\n",
    "            print(f\"  Mode: {mode_display} | Battle: {int(in_battle)} | Stagnation: {brain.state_stagnation_count}\")\n",
    "            \n",
    "            # === BATTLE STATUS ===\n",
    "            if currently_in_battle:\n",
    "                battle_total = brain.battle_action_count\n",
    "                battle_markov = brain.battle_markov_action_count\n",
    "                battle_markov_rate = battle_markov / max(1, battle_total)\n",
    "                print(f\"\\n  ‚öîÔ∏è IN BATTLE (#{brain.current_battle_id}):\")\n",
    "                print(f\"     Frame: {brain.battle_frame_count} | Actions: {battle_total}\")\n",
    "                print(f\"     Battle Markov: {battle_markov}/{battle_total} ({battle_markov_rate:.1%})\")\n",
    "                print(f\"     Last Markov score: {brain.last_battle_markov_score:.3f} \"\n",
    "                      f\"(threshold: {BATTLE_MARKOV_THRESHOLD_LOW:.2f}-{BATTLE_MARKOV_THRESHOLD_HIGH:.2f})\")\n",
    "                if brain.last_battle_markov_action:\n",
    "                    print(f\"     Last Markov suggestion: {brain.last_battle_markov_action}\")\n",
    "                print(f\"     Battle data: {'LOADED' if brain.battle_loaded else 'NONE (A fallback)'} \"\n",
    "                      f\"({len(brain.battle_transitions)} frames)\")\n",
    "            else:\n",
    "                # === NAVIGATION STATUS (overworld only) ===\n",
    "                cross_status = brain.get_cross_map_status()\n",
    "                \n",
    "                if brain.is_nav_active():\n",
    "                    if cross_status['active']:\n",
    "                        # Cross-map navigation\n",
    "                        chain_str = ' ‚Üí '.join(str(m) for m in cross_status['chain'])\n",
    "                        current_step = cross_status['chain_index']\n",
    "                        total_steps = cross_status['chain_length']\n",
    "                        \n",
    "                        if brain.is_nav_paused():\n",
    "                            print(f\"\\n  üß≠üåç CROSS-MAP NAV PAUSED:\")\n",
    "                            print(f\"     Chain: {chain_str} (step {current_step + 1}/{total_steps})\")\n",
    "                            print(f\"     Reason: {cross_status['paused_reason']}\")\n",
    "                            print(f\"     Resume check in: {brain.nav_pause_check_countdown} steps\")\n",
    "                            if cross_status['final_target']:\n",
    "                                ft = cross_status['final_target']\n",
    "                                print(f\"     Final target: ({ft[0]}, {ft[1]}) on map {cross_status['target_map']}\")\n",
    "                        else:\n",
    "                            nav_progress = f\"{brain.nav_path_index}/{len(brain.nav_path)}\"\n",
    "                            print(f\"\\n  üß≠üåç CROSS-MAP NAV ACTIVE:\")\n",
    "                            print(f\"     Chain: {chain_str} (step {current_step + 1}/{total_steps})\")\n",
    "                            print(f\"     Current path: {nav_progress} | Steps: {brain.nav_steps_taken}\")\n",
    "                            if brain.nav_target:\n",
    "                                print(f\"     Immediate target: ({brain.nav_target[0]}, {brain.nav_target[1]})\")\n",
    "                            if cross_status['final_target']:\n",
    "                                ft = cross_status['final_target']\n",
    "                                print(f\"     Final target: ({ft[0]}, {ft[1]}) on map {cross_status['target_map']}\")\n",
    "                    else:\n",
    "                        # Single-map navigation\n",
    "                        nav_target = brain.nav_target\n",
    "                        nav_progress = f\"{brain.nav_path_index}/{len(brain.nav_path)}\"\n",
    "                        targets_remaining = len(brain.nav_target_list) - brain.nav_target_index\n",
    "                        print(f\"\\n  üß≠ NAVIGATION ACTIVE:\")\n",
    "                        print(f\"     Target: ({nav_target[0]}, {nav_target[1]}) | Path: {nav_progress} | Steps: {brain.nav_steps_taken}\")\n",
    "                        print(f\"     Targets remaining: {targets_remaining} | Struck: {len(brain.nav_struck_targets)}\")\n",
    "                        if brain.nav_stagnation_count > 0:\n",
    "                            print(f\"     Nav stagnation: {brain.nav_stagnation_count}/{brain.NAV_STAGNATION_LIMIT}\")\n",
    "                \n",
    "                elif brain.is_in_nav_curiosity_window():\n",
    "                    print(f\"\\n  üß≠ NAV CURIOSITY WINDOW: {brain.nav_curiosity_countdown} steps remaining\")\n",
    "                else:\n",
    "                    nav_status = brain.get_nav_targets_status()\n",
    "                    if nav_status['loaded']:\n",
    "                        print(f\"\\n  üß≠ Navigation: inactive (known area: {brain.known_area_counter}/{brain.KNOWN_AREA_TRIGGER})\")\n",
    "                        print(f\"     Taught targets: {nav_status['remaining']} remaining / {nav_status['total']} total ({nav_status['visited']} visited)\")\n",
    "                    else:\n",
    "                        print(f\"\\n  üß≠ Navigation: inactive (known area: {brain.known_area_counter}/{brain.KNOWN_AREA_TRIGGER}) [frontier fallback]\")\n",
    "            \n",
    "            print(f\"\\n  üß† DECISION MODE:\")\n",
    "            print(f\"     Overworld Markov: {brain.markov_action_count} ({markov_ratio:.1%}) | Curiosity: {brain.curiosity_action_count} ({1-markov_ratio:.1%})\")\n",
    "            print(f\"     Battle actions: {brain.battle_action_count} | Battle Markov: {brain.battle_markov_action_count}\")\n",
    "            print(f\"     Last OW Markov score: {brain.last_markov_score:.3f} (threshold adapts to density)\")\n",
    "            print(f\"     Map density: {density['tier']} ({density['taught_frames']} frames, {density['visited']} tiles, {density['coverage']:.0%} coverage)\")\n",
    "            if brain.last_markov_action:\n",
    "                print(f\"     Last OW Markov suggestion: {brain.last_markov_action}\")\n",
    "            \n",
    "            # Blend status\n",
    "            if brain.taught_reference['loaded']:\n",
    "                blend_status = f\"Tier {brain.blend_tier}\" if brain.blend_tier > 0 else \"Inactive\"\n",
    "                print(f\"\\n  üîÄ BLEND: {blend_status} | Total blends: {brain.blend_count}\")\n",
    "                if brain.blend_tier > 0:\n",
    "                    ai_w, taught_w = brain.BLEND_RATIOS[brain.blend_tier]\n",
    "                    print(f\"     Current ratio: {ai_w:.0%} AI / {taught_w:.0%} taught\")\n",
    "            \n",
    "            print(f\"\\n  üìä EXPLORATION:\")\n",
    "            print(f\"     Visited: {visited_count} | Obstructions: {obs_count} | Coverage: {coverage:.0%}\")\n",
    "            print(f\"     Interactables found: {interactables}\")\n",
    "            \n",
    "            # Map graph status\n",
    "            mg = brain.build_map_graph()\n",
    "            mg_edges = sum(len(v) for v in mg.values())\n",
    "            print(f\"     Map graph: {len(mg)} maps, {mg_edges} edges\")\n",
    "            \n",
    "            print(f\"\\n  üéØ TILE PROBING:\")\n",
    "            print(f\"     Tiles probed: {tile_stats['probed']} | Exhausted: {tile_stats['exhausted']} | With success: {tile_stats['with_success']}\")\n",
    "            \n",
    "            if not currently_in_battle:\n",
    "                if tile_needs_probing:\n",
    "                    if probe_action == 'A':\n",
    "                        print(f\"     Current tile: READY TO PROBE (facing untried direction)\")\n",
    "                    elif probe_action:\n",
    "                        print(f\"     Current tile: NEED TO TURN {probe_action} first\")\n",
    "                    else:\n",
    "                        print(f\"     Current tile: NEEDS PROBING (checking directions)\")\n",
    "                else:\n",
    "                    print(f\"     Current tile: EXHAUSTED or fully probed\")\n",
    "                \n",
    "                tile_state_data = brain.get_tile_interaction_state(raw_x, raw_y, current_map)\n",
    "                success_info = []\n",
    "                for d in range(4):\n",
    "                    attempts = tile_state_data['direction_attempts'].get(d, 0)\n",
    "                    successes = tile_state_data['direction_successes'].get(d, 0)\n",
    "                    if attempts > 0:\n",
    "                        success_info.append(f\"{brain.DIRECTION_NAMES.get(d, '?')}:{successes}/{attempts}\")\n",
    "                if success_info:\n",
    "                    print(f\"     Direction results: {', '.join(success_info)}\")\n",
    "            \n",
    "            if transitions:\n",
    "                print(f\"\\n  üö™ TRANSITIONS: {len(transitions)} known\")\n",
    "                for t in transitions[:3]:\n",
    "                    pos = tuple(t['position']) if isinstance(t['position'], list) else t['position']\n",
    "                    banned = \"üö´\" if brain.is_transition_banned(current_map, pos, t['direction']) else \"\"\n",
    "                    print(f\"     ({pos[0]},{pos[1]}) ‚Üí Map {t['destination_map']} (used {t['use_count']}x) {banned}\")\n",
    "            \n",
    "            map_debt = brain.map_novelty_debt.get(current_map, 0.0)\n",
    "            temp_debt = brain.get_temp_debt(current_map)\n",
    "            if map_debt > 0.1 or temp_debt > 0.1:\n",
    "                print(f\"\\n  üí≥ DEBT: map={map_debt:.2f}/{brain.MAX_MAP_DEBT}, temp={temp_debt:.2f}\")\n",
    "            \n",
    "            if brain.menu_trap_b_boost > 1.0:\n",
    "                print(f\"\\n  üîí MENU TRAP: B boost {brain.menu_trap_b_boost:.2f}x ({brain.menu_trap_frames} frames)\")\n",
    "            \n",
    "            if is_both_mode:\n",
    "                print(f\"\\n  ‚ö° BOTH MODE ACTIVE: stagnation={brain.state_stagnation_count}, swaps={brain.unproductive_swap_count}\")\n",
    "            \n",
    "            if brain.pending_action:\n",
    "                print(f\"\\n  ‚è≥ Pending: {brain.pending_action} ({brain.pending_action_frames}/{brain.ACTION_CONFIRM_FRAMES})\")\n",
    "            \n",
    "            action_utils = sorted([(a.action, a.utility) for a in brain.actions()], key=lambda x: x[1], reverse=True)\n",
    "            print(f\"\\n  ‚ö° Utilities: {' '.join([f'{k}:{v:.2f}' for k,v in action_utils])}\")\n",
    "            \n",
    "            n_actions = len(brain.actions())\n",
    "            n_entities = len(brain.entities())\n",
    "            n_total = len(brain.perceptrons)\n",
    "            print(f\"  üß© Perceptrons: {n_total} total ({n_actions} actions, {n_entities} entities)\")\n",
    "            \n",
    "            if brain.state_stagnation_count > 10:\n",
    "                print(f\"\\n  ‚ö†Ô∏è STAGNATION WARNING: {brain.state_stagnation_count}/{brain.STATE_STAGNATION_THRESHOLD}\")\n",
    "            if brain.detected_pattern:\n",
    "                pattern_str = '-'.join(str(a) for a in brain.detected_pattern)\n",
    "                print(f\"  üîÑ PATTERN DETECTED ({len(brain.detected_pattern)}): {pattern_str} x{brain.pattern_repeat_count}\")\n",
    "\n",
    "        # === MILESTONES ===\n",
    "        if brain.timestep % 500 == 0 and brain.timestep > 0:\n",
    "            total_visited = sum(len(m['visited_tiles']) for m in brain.exploration_memory.values())\n",
    "            total_obs = sum(len(m['obstructions']) for m in brain.exploration_memory.values())\n",
    "            total_interactables = sum(len(m['interactable_objects']) for m in brain.exploration_memory.values())\n",
    "            total_transitions = sum(len(m.get('transitions', [])) for m in brain.exploration_memory.values())\n",
    "            total_probed = sum(len(m.get('tile_interactions', {})) for m in brain.exploration_memory.values())\n",
    "            total_exhausted = sum(\n",
    "                sum(1 for t in m.get('tile_interactions', {}).values() if t.get('exhausted', False))\n",
    "                for m in brain.exploration_memory.values()\n",
    "            )\n",
    "            \n",
    "            total_actions = brain.markov_action_count + brain.curiosity_action_count\n",
    "            markov_ratio = brain.markov_action_count / max(1, total_actions)\n",
    "            \n",
    "            battle_total = brain.battle_action_count\n",
    "            battle_markov = brain.battle_markov_action_count\n",
    "            battle_markov_rate = battle_markov / max(1, battle_total)\n",
    "            \n",
    "            mg = brain.build_map_graph()\n",
    "            mg_edges = sum(len(v) for v in mg.values())\n",
    "            \n",
    "            print(f\"\\n{'#'*70}\")\n",
    "            print(f\"# MILESTONE {brain.timestep}\")\n",
    "            print(f\"# Maps explored: {len(brain.exploration_memory)}\")\n",
    "            print(f\"# Tiles visited: {total_visited} | Obstructions: {total_obs}\")\n",
    "            print(f\"# Interactables: {total_interactables} | Transitions: {total_transitions}\")\n",
    "            print(f\"# Tiles probed: {total_probed} | Exhausted: {total_exhausted}\")\n",
    "            print(f\"#\")\n",
    "            print(f\"# CACHE SYSTEM:\")\n",
    "            print(f\"#   Maps cached: {len(cache_manager.caches)}\")\n",
    "            print(f\"#   Active map: {cache_manager.active_map_id} ({len(cache_manager.get_active_taught_frames())} taught frames)\")\n",
    "            print(f\"#\")\n",
    "            print(f\"# MAP GRAPH:\")\n",
    "            print(f\"#   Maps: {len(mg)} | Edges: {mg_edges}\")\n",
    "            print(f\"#   Connected: {list(mg.keys())}\")\n",
    "            print(f\"#\")\n",
    "            print(f\"# HYBRID DECISION STATS:\")\n",
    "            print(f\"#   Overworld Markov (imitation): {brain.markov_action_count} ({markov_ratio:.1%})\")\n",
    "            print(f\"#   Curiosity (explore): {brain.curiosity_action_count} ({1-markov_ratio:.1%})\")\n",
    "            print(f\"#   Taught transitions: {len(brain.taught_transitions)}\")\n",
    "            print(f\"#\")\n",
    "            print(f\"# BATTLE STATS:\")\n",
    "            print(f\"#   Battles fought: {brain.current_battle_id}\")\n",
    "            print(f\"#   Battle actions: {battle_total}\")\n",
    "            print(f\"#   Battle Markov: {battle_markov}/{battle_total} ({battle_markov_rate:.1%})\")\n",
    "            print(f\"#   Battle data: {'LOADED' if brain.battle_loaded else 'NOT LOADED'} ({len(brain.battle_transitions)} frames)\")\n",
    "            print(f\"#\")\n",
    "            print(f\"# BLEND STATS:\")\n",
    "            print(f\"#   Total blends: {brain.blend_count}\")\n",
    "            print(f\"#   Current tier: {brain.blend_tier}\")\n",
    "            print(f\"#   Taught reference: {'loaded' if brain.taught_reference['loaded'] else 'not loaded'}\")\n",
    "            print(f\"#\")\n",
    "            print(f\"# NAVIGATION STATS:\")\n",
    "            print(f\"#   Active: {brain.is_nav_active()}\")\n",
    "            cross_status = brain.get_cross_map_status()\n",
    "            if cross_status['active']:\n",
    "                chain_str = ' ‚Üí '.join(str(m) for m in cross_status['chain'])\n",
    "                print(f\"#   Cross-map: {chain_str} (step {cross_status['chain_index'] + 1}/{cross_status['chain_length']})\")\n",
    "                if cross_status['paused']:\n",
    "                    print(f\"#   PAUSED: {cross_status['paused_reason']}\")\n",
    "            else:\n",
    "                print(f\"#   Cross-map: inactive\")\n",
    "            print(f\"#   Struck targets (this session): {len(brain.nav_struck_targets)}\")\n",
    "            nav_status = brain.get_nav_targets_status()\n",
    "            if nav_status['loaded']:\n",
    "                print(f\"#   Taught targets: {nav_status['remaining']} remaining / {nav_status['total']} total\")\n",
    "            else:\n",
    "                print(f\"#   Taught targets: not loaded (frontier fallback)\")\n",
    "            print(f\"{'#'*70}\")\n",
    "\n",
    "            brain.save_model_checkpoint(BASE_PATH / \"model_checkpoint.json\")\n",
    "            cache_manager.save_exploration_memory()\n",
    "            print(f\"# Model + exploration saved\")\n",
    "\n",
    "        # === WAIT FOR NEXT STATE (new IOThread read) ===\n",
    "        for _ in range(10):\n",
    "            time.sleep(0.005)\n",
    "            if active_cache.get_version() > last_processed_version:\n",
    "                break\n",
    "\n",
    "        # === LEARN ===\n",
    "        next_ctx, next_pal, next_til, dead, next_raw_pos = active_cache.get_state()\n",
    "        last_processed_version = active_cache.get_version()\n",
    "        \n",
    "        next_in_battle = next_ctx[3]\n",
    "        next_derived = compute_derived_features(next_ctx, context_state)\n",
    "        next_learning_state = build_learning_state(next_derived, next_pal, next_til, next_in_battle)\n",
    "\n",
    "        brain.learn(learning_state, next_learning_state, context_state, next_ctx, dead=dead, \n",
    "                    raw_position=raw_position, next_raw_position=next_raw_pos)\n",
    "\n",
    "        prev_context_state = context_state.copy()\n",
    "        prev_raw_position = raw_position\n",
    "        brain.timestep += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nüõë Stopping AI...\")\n",
    "    io_thread.stop()\n",
    "    io_thread.join(timeout=2)\n",
    "    cache_manager.save_exploration_memory()\n",
    "    brain.save_model_checkpoint(BASE_PATH / \"model_checkpoint.json\")\n",
    "    print(\"‚úÖ Saved and stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
