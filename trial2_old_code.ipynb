{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677ae718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "# --- File paths (same folder as notebook & Lua script) ---\n",
    "BASE_PATH = Path(\"C:/Users/natmaw/Documents/Boston Stuff/CS 5100 Foundations of AI/cogai/\")\n",
    "ACTION_FILE = BASE_PATH / \"action.json\"\n",
    "STATE_FILE  = BASE_PATH / \"game_state.json\"\n",
    "\n",
    "# --- FireRed state vector size ---\n",
    "# Lua always writes: [x, y, map, hp_cur, hp_max]\n",
    "EXPECTED_STATE_DIM = 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb86b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_game_state():\n",
    "    if not STATE_FILE.exists():\n",
    "        return np.zeros(EXPECTED_STATE_DIM, dtype=float), False\n",
    "\n",
    "    try:\n",
    "        with open(STATE_FILE, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        raw = data.get(\"state\", [])\n",
    "        dead = bool(data.get(\"dead\", False))\n",
    "\n",
    "        raw_state = np.array(raw, dtype=float)\n",
    "\n",
    "    except Exception:\n",
    "        # Any parse error → safe fallback\n",
    "        return np.zeros(EXPECTED_STATE_DIM, dtype=float), False\n",
    "\n",
    "    # --- HARD PAD / TRIM (authoritative fix) ---\n",
    "    if raw_state.shape[0] < EXPECTED_STATE_DIM:\n",
    "        pad = np.zeros(EXPECTED_STATE_DIM - raw_state.shape[0], dtype=float)\n",
    "        raw_state = np.concatenate([raw_state, pad])\n",
    "    elif raw_state.shape[0] > EXPECTED_STATE_DIM:\n",
    "        raw_state = raw_state[:EXPECTED_STATE_DIM]\n",
    "\n",
    "    return raw_state, dead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75a0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_action(action_name):\n",
    "    with open(ACTION_FILE, \"w\") as f:\n",
    "        json.dump({\"action\": action_name}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9dd8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, kind, action=None, group=None):\n",
    "        self.kind = kind\n",
    "        self.action = action\n",
    "        self.group = group  # \"move\" or \"interact\" or None\n",
    "        self.utility = 1.0\n",
    "        self.weights = None\n",
    "        self.eligibility = 0.0\n",
    "\n",
    "    def ensure_weights(self, dim):\n",
    "        if self.weights is None:\n",
    "            self.weights = np.random.randn(dim) * 0.01\n",
    "\n",
    "    def predict(self, state):\n",
    "        self.ensure_weights(len(state))\n",
    "        return np.dot(self.weights, state)\n",
    "\n",
    "    def update(self, state, error, gamma=0.9, stagnation=0.0):\n",
    "        self.ensure_weights(len(state))\n",
    "        self.eligibility = gamma * self.eligibility + 1.0\n",
    "        lr = 0.03\n",
    "        self.weights += lr * error * state * self.eligibility\n",
    "\n",
    "        if self.kind == \"action\":\n",
    "            if stagnation > 0.5:\n",
    "                self.utility *= 0.97\n",
    "            else:\n",
    "                self.utility *= 0.995\n",
    "        self.utility = np.clip(self.utility, 0.01, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980759f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self):\n",
    "        self.perceptrons = []\n",
    "        self.prev_states = []\n",
    "        self.last_positions = []\n",
    "        self.movement_stagnation = 0\n",
    "        self.control_mode = \"move\"\n",
    "        self.timestep = 0\n",
    "\n",
    "    def add(self, p):\n",
    "        self.perceptrons.append(p)\n",
    "\n",
    "    def actions(self):\n",
    "        return [p for p in self.perceptrons if p.kind == \"action\"]\n",
    "\n",
    "    def entities(self):\n",
    "        return [p for p in self.perceptrons if p.kind == \"entity\"]\n",
    "\n",
    "    def stagnation_level(self, window=10):\n",
    "        if len(self.prev_states) < window:\n",
    "            return 0.0\n",
    "        diffs = [\n",
    "            np.linalg.norm(self.prev_states[i] - self.prev_states[i - 1])\n",
    "            for i in range(1, window)\n",
    "        ]\n",
    "        return 1.0 - np.tanh(sum(diffs))\n",
    "\n",
    "    def predict_future_error(self, state, action):\n",
    "        novelty = sum(e.predict(state) for e in self.entities())\n",
    "        noise = np.random.randn() * 0.05\n",
    "        return novelty + noise\n",
    "\n",
    "    def learn(self, state, next_state, dead=False):\n",
    "        if state.shape != next_state.shape:\n",
    "            return\n",
    "        error = np.linalg.norm(next_state - state)\n",
    "        if dead:\n",
    "            error *= 0.5\n",
    "        stagnation = self.stagnation_level()\n",
    "        for p in self.perceptrons:\n",
    "            p.update(state, -error, stagnation=stagnation)\n",
    "        if abs(error) > 0.3:\n",
    "            self.add(Perceptron(\"entity\"))\n",
    "        self.perceptrons = [p for p in self.perceptrons if p.utility > 0.05]\n",
    "\n",
    "    def log_state(self, state):\n",
    "        self.prev_states.append(state)\n",
    "        if len(self.prev_states) > 50:\n",
    "            self.prev_states.pop(0)\n",
    "\n",
    "    def update_position(self, x, y, interaction_threshold=5, menu_threshold=15):\n",
    "        self.last_positions.append((x, y))\n",
    "        if len(self.last_positions) > menu_threshold:\n",
    "            self.last_positions.pop(0)\n",
    "\n",
    "        unique_positions = len(set(self.last_positions))\n",
    "        if unique_positions <= 1:\n",
    "            self.movement_stagnation += 1\n",
    "        else:\n",
    "            self.movement_stagnation = 0\n",
    "\n",
    "        if self.movement_stagnation >= menu_threshold:\n",
    "            self.control_mode = \"both\"\n",
    "        elif self.movement_stagnation >= interaction_threshold:\n",
    "            self.control_mode = \"interact\"\n",
    "        else:\n",
    "            self.control_mode = \"move\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cb347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBA_ACTIONS = [\n",
    "    \"Up\", \"Down\", \"Left\", \"Right\",\n",
    "    \"A\", \"B\", \"Start\", \"Select\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1df11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anticipatory_action(\n",
    "    brain,\n",
    "    state,\n",
    "    exploration_weight=1.5,\n",
    "    forced_explore_prob=0.4,\n",
    "    explore_bonus=0.3,\n",
    "    min_interact_prob=0.2  # ensures interactions never vanish\n",
    "):\n",
    "    actions_list = brain.actions()\n",
    "    if not actions_list:\n",
    "        return random.choice([Perceptron(\"action\", action=a, group=\"move\") for a in [\"UP\",\"DOWN\",\"LEFT\",\"RIGHT\",\"A\",\"B\",\"Start\",\"Select\"]])\n",
    "\n",
    "    # Control filtering\n",
    "    allowed = []\n",
    "    for a in actions_list:\n",
    "        if brain.control_mode == \"move\" and a.group != \"move\":\n",
    "            continue\n",
    "        if brain.control_mode == \"interact\" and a.group != \"interact\":\n",
    "            continue\n",
    "        allowed.append(a)\n",
    "    if not allowed:\n",
    "        # fallback: allow all\n",
    "        allowed = actions_list\n",
    "\n",
    "    # Forced exploration\n",
    "    if random.random() < forced_explore_prob:\n",
    "        return random.choice(allowed)\n",
    "\n",
    "    best_action, best_score = None, -np.inf\n",
    "    for a in allowed:\n",
    "        predicted = brain.predict_future_error(state, a)\n",
    "\n",
    "        # separate bias for movement vs interaction\n",
    "        if a.group == \"move\":\n",
    "            predicted *= exploration_weight\n",
    "            predicted += explore_bonus\n",
    "        elif a.group == \"interact\":\n",
    "            predicted = max(predicted, min_interact_prob)  # never too low\n",
    "\n",
    "        if predicted > best_score:\n",
    "            best_score = predicted\n",
    "            best_action = a\n",
    "\n",
    "    # final fallback: if something went wrong\n",
    "    if best_action is None:\n",
    "        best_action = random.choice(allowed)\n",
    "\n",
    "    return best_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e97d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_state(prev_states, current_state, window, alpha):\n",
    "    history = prev_states[-(window-1):] if prev_states else []\n",
    "\n",
    "    while len(history) < (window-1):\n",
    "        history.insert(0, np.zeros(EXPECTED_STATE_DIM, dtype=float))\n",
    "\n",
    "    history.append(current_state)\n",
    "\n",
    "    weighted = [\n",
    "        s * (alpha ** (window - 1 - i))\n",
    "        for i, s in enumerate(history)\n",
    "    ]\n",
    "\n",
    "    return np.concatenate(weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd7a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI CONTROL STARTED — switch to BizHawk window\n"
     ]
    }
   ],
   "source": [
    "# --- Brain & Perceptrons setup ---\n",
    "brain = Brain()\n",
    "\n",
    "# interaction & move groups\n",
    "interact_buttons = [\"A\", \"B\", \"Start\", \"Select\"]\n",
    "move_buttons = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "\n",
    "for b in move_buttons:\n",
    "    brain.add(Perceptron(\"action\", action=b, group=\"move\"))\n",
    "for b in interact_buttons:\n",
    "    brain.add(Perceptron(\"action\", action=b, group=\"interact\"))\n",
    "\n",
    "# exploration objectives\n",
    "brain.add(Perceptron(\"objective\"))\n",
    "brain.add(Perceptron(\"objective\"))\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "temporal_window = 3\n",
    "alpha_decay = 0.7\n",
    "exploration_weight = 1.5\n",
    "forced_explore_prob = 0.4\n",
    "\n",
    "prev_states = []\n",
    "\n",
    "print(\"AI CONTROL STARTED — switch to BizHawk window\")\n",
    "\n",
    "while True:\n",
    "    raw_state, dead = read_game_state()\n",
    "\n",
    "    # --- Update position & control mode ---\n",
    "    x, y = raw_state[0], raw_state[1]\n",
    "    brain.update_position(x, y)\n",
    "\n",
    "    prev_states.append(raw_state)\n",
    "    if len(prev_states) > temporal_window:\n",
    "        prev_states.pop(0)\n",
    "\n",
    "    state = temporal_state(prev_states, raw_state, temporal_window, alpha_decay)\n",
    "    brain.log_state(state)\n",
    "\n",
    "    action = anticipatory_action(\n",
    "        brain,\n",
    "        state,\n",
    "        exploration_weight=exploration_weight,\n",
    "        forced_explore_prob=forced_explore_prob\n",
    "    )\n",
    "\n",
    "    if action is not None:\n",
    "        write_action(action.action)\n",
    "    else:\n",
    "        write_action(\"NONE\")\n",
    "\n",
    "    time.sleep(0.03)  # ~30 FPS\n",
    "\n",
    "    next_raw, dead = read_game_state()\n",
    "    next_state = temporal_state(prev_states, next_raw, temporal_window, alpha_decay)\n",
    "\n",
    "    brain.learn(state, next_state, dead=dead)\n",
    "\n",
    "    brain.timestep += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
