{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304255b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: State Management & Utilities\n",
    "# ============================================================================\n",
    "# CHANGES FROM PREVIOUS:\n",
    "# 1. Added TAUGHT_BATTLE_TRANSITIONS_FILE path constant\n",
    "# 2. Added DEFAULT_BATTLE_DATA constant (matches AI agent exactly)\n",
    "# 3. Added parse_battle_data() â€” extracts \"b\" field from game_state.json\n",
    "# 4. Updated parse_game_state_data() â€” returns battle_data as 5th value\n",
    "# 5. Updated read_game_state() â€” returns battle_data as 6th value\n",
    "# 6. Fully backward compatible â€” missing \"b\" field returns all -1 defaults\n",
    "# ============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "BASE_PATH = Path(r\"C:\\Users\\HP\\Documents\\cogai\")\n",
    "ACTION_FILE = BASE_PATH / \"action.json\"\n",
    "STATE_FILE = BASE_PATH / \"game_state.json\"\n",
    "INPUT_FILE = BASE_PATH / \"input_cache.txt\"\n",
    "MODEL_FILE = BASE_PATH / \"taught_model_checkpoint.json\"\n",
    "TAUGHT_TRANSITIONS_FILE = BASE_PATH / \"taught_transitions.json\"\n",
    "TAUGHT_BATTLE_TRANSITIONS_FILE = BASE_PATH / \"taught_battle_transitions.json\"\n",
    "EXPLORATION_MEMORY_FILE = BASE_PATH / \"taught_exploration_memory.json\"\n",
    "MODEL_CHECKPOINT_FILE = BASE_PATH / \"taught_model_checkpoint.json\"\n",
    "TAUGHT_EXPLORATION_FILE = BASE_PATH / \"taught_exploration_memory.json\"\n",
    "\n",
    "# === MARKOV SIMILARITY WEIGHTS (consistent with AI agent) ===\n",
    "MARKOV_IMMEDIATE_WEIGHT = 0.5\n",
    "MARKOV_SEQUENTIAL_WEIGHT = 0.3\n",
    "MARKOV_PARTIAL_WEIGHT = 0.2\n",
    "MARKOV_FAMILIARITY_THRESHOLD = 0.6\n",
    "\n",
    "MARKOV_SEQ_FULL_WEIGHT = 1.0\n",
    "MARKOV_SEQ_MEDIUM_WEIGHT = 0.6\n",
    "MARKOV_SEQ_SHORT_WEIGHT = 0.3\n",
    "\n",
    "MARKOV_POS_EXACT_BONUS = 0.35\n",
    "MARKOV_POS_NEAR_BONUS = 0.25\n",
    "MARKOV_POS_FAR_BONUS = 0.1\n",
    "MARKOV_POS_MAX_DIST = 5\n",
    "\n",
    "EXPECTED_STATE_DIM = 6\n",
    "PALETTE_DIM = 768\n",
    "TILE_DIM = 600\n",
    "LEARNING_STATE_DIM = 8 + TILE_DIM + PALETTE_DIM  # 1376\n",
    "\n",
    "# Action code mapping (from Lua short codes)\n",
    "ACTION_MAP = {\n",
    "    'U': 'UP', 'D': 'DOWN', 'L': 'LEFT', 'R': 'RIGHT',\n",
    "    'A': 'A', 'B': 'B', 'S': 'Start', 'E': 'Select'\n",
    "}\n",
    "\n",
    "# === DEFAULT BATTLE DATA (all -1 = unavailable) ===\n",
    "# Matches AI agent's DEFAULT_BATTLE_DATA exactly\n",
    "DEFAULT_BATTLE_DATA = {\n",
    "    'battle_cursor': -1,   # bc: 0=Fight,1=Bag,2=Pokemon,3=Run (-1=not in battle menu)\n",
    "    'move_cursor': -1,     # mc: 0-3 move slot (-1=not in move menu)\n",
    "    'player_species': -1,  # ps: Gen III species ID (-1=not in battle)\n",
    "    'enemy_species': -1,   # es: Gen III species ID (-1=not in battle)\n",
    "    'player_hp': -1,       # ph: current HP (-1=unavailable)\n",
    "    'player_max_hp': -1,   # pm: max HP (-1=unavailable)\n",
    "    'enemy_hp': -1,        # eh: current HP (-1=unavailable)\n",
    "    'party_cursor': -1,    # pc: 0-5 slot, 6=cancel (-1=not in party menu)\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_game_state(raw_state):\n",
    "    if len(raw_state) < 6:\n",
    "        raw_state = list(raw_state) + [0] * (6 - len(raw_state))\n",
    "    normalized = np.array(raw_state, dtype=float)\n",
    "    normalized[0] = raw_state[0] / 255.0\n",
    "    normalized[1] = raw_state[1] / 255.0\n",
    "    normalized[2] = np.clip(raw_state[2], 0, 255)\n",
    "    normalized[3] = 1.0 if raw_state[3] > 0 else 0.0\n",
    "    normalized[4] = 1.0 if raw_state[4] > 0 else 0.0\n",
    "    normalized[5] = int(raw_state[5]) % 4\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def compute_derived_features(current, prev):\n",
    "    if prev is None:\n",
    "        return np.zeros(8)\n",
    "    vel_x = current[0] - prev[0]\n",
    "    vel_y = current[1] - prev[1]\n",
    "    map_changed = 1.0 if abs(current[2] - prev[2]) > 0.5 else 0.0\n",
    "    battle_started = 1.0 if current[3] > prev[3] else 0.0\n",
    "    battle_ended = 1.0 if current[3] < prev[3] else 0.0\n",
    "    menu_opened = 1.0 if current[4] > prev[4] else 0.0\n",
    "    menu_closed = 1.0 if current[4] < prev[4] else 0.0\n",
    "    direction_changed = 1.0 if current[5] != prev[5] else 0.0\n",
    "    return np.array([vel_x, vel_y, map_changed, battle_started, battle_ended,\n",
    "                     menu_opened, menu_closed, direction_changed])\n",
    "\n",
    "\n",
    "def build_learning_state(derived, palette, tiles, in_battle):\n",
    "    \"\"\"Build learning state â€” matches AI agent's version exactly.\"\"\"\n",
    "    if len(derived) != 8:\n",
    "        derived = np.zeros(8)\n",
    "    if len(tiles) != TILE_DIM:\n",
    "        tiles = np.zeros(TILE_DIM)\n",
    "    if len(palette) != PALETTE_DIM:\n",
    "        palette = np.zeros(PALETTE_DIM)\n",
    "\n",
    "    if in_battle > 0.5:\n",
    "        state = np.concatenate([derived, palette])\n",
    "    else:\n",
    "        state = np.concatenate([derived, tiles, palette])\n",
    "    noise = np.random.randn(len(state)) * 0.0001\n",
    "    return state + noise\n",
    "\n",
    "\n",
    "def _pad_or_trim(arr, target_dim):\n",
    "    \"\"\"Dimension safety helper.\"\"\"\n",
    "    if arr.shape[0] < target_dim:\n",
    "        return np.pad(arr, (0, target_dim - arr.shape[0]))\n",
    "    elif arr.shape[0] > target_dim:\n",
    "        return arr[:target_dim]\n",
    "    return arr\n",
    "\n",
    "\n",
    "def parse_battle_data(data):\n",
    "    \"\"\"\n",
    "    Parse battle data from the 'b' field in game_state.json.\n",
    "\n",
    "    Lua writes short keys: bc, mc, ps, es, ph, pm, eh, pc\n",
    "    Uses -1 for unavailable fields (e.g., enemy species when not in battle).\n",
    "\n",
    "    Returns dict with full key names matching DEFAULT_BATTLE_DATA.\n",
    "    If 'b' field is missing (old Lua script), returns all -1 defaults.\n",
    "    \"\"\"\n",
    "    b = data.get('b')\n",
    "    if b is None:\n",
    "        return DEFAULT_BATTLE_DATA.copy()\n",
    "\n",
    "    return {\n",
    "        'battle_cursor': b.get('bc', -1),\n",
    "        'move_cursor': b.get('mc', -1),\n",
    "        'player_species': b.get('ps', -1),\n",
    "        'enemy_species': b.get('es', -1),\n",
    "        'player_hp': b.get('ph', -1),\n",
    "        'player_max_hp': b.get('pm', -1),\n",
    "        'enemy_hp': b.get('eh', -1),\n",
    "        'party_cursor': b.get('pc', -1),\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_game_state_data(data):\n",
    "    \"\"\"Parse game state dict handling both long and short key formats.\n",
    "    Now returns battle_data as 5th value.\"\"\"\n",
    "    raw = data.get(\"state\") or data.get(\"s\") or []\n",
    "    palette_raw = data.get(\"palette\") or data.get(\"p\") or []\n",
    "    tiles_raw = data.get(\"tiles\") or data.get(\"t\") or []\n",
    "    dead = bool(data.get(\"dead\", False))\n",
    "    battle_data = parse_battle_data(data)\n",
    "    return raw, palette_raw, tiles_raw, dead, battle_data\n",
    "\n",
    "\n",
    "def read_game_state(max_retries=3):\n",
    "    \"\"\"\n",
    "    Read game state from JSON file.\n",
    "\n",
    "    Returns: (context_state, palette_state, tile_state, dead, raw_position, battle_data)\n",
    "\n",
    "    battle_data is a dict with keys:\n",
    "      battle_cursor, move_cursor, player_species, enemy_species,\n",
    "      player_hp, player_max_hp, enemy_hp, party_cursor\n",
    "    All values are -1 when unavailable (backward compatible with old Lua).\n",
    "    \"\"\"\n",
    "    if not STATE_FILE.exists():\n",
    "        return (np.zeros(EXPECTED_STATE_DIM), np.zeros(PALETTE_DIM), np.zeros(TILE_DIM),\n",
    "                False, (0, 0), DEFAULT_BATTLE_DATA.copy())\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            with open(STATE_FILE, \"r\") as f:\n",
    "                data = json.loads(f.read())\n",
    "\n",
    "            raw, palette_raw, tiles_raw, dead, battle_data = parse_game_state_data(data)\n",
    "\n",
    "            raw_x = int(raw[0]) if len(raw) > 0 else 0\n",
    "            raw_y = int(raw[1]) if len(raw) > 1 else 0\n",
    "            raw_position = (raw_x, raw_y)\n",
    "\n",
    "            context_state = normalize_game_state(np.array(raw, dtype=float))\n",
    "            palette_state = np.array(palette_raw, dtype=float) if palette_raw else np.zeros(PALETTE_DIM)\n",
    "            tile_state = np.array(tiles_raw, dtype=float) if tiles_raw else np.zeros(TILE_DIM)\n",
    "\n",
    "            context_state = _pad_or_trim(context_state, EXPECTED_STATE_DIM)\n",
    "            palette_state = _pad_or_trim(palette_state, PALETTE_DIM)\n",
    "            tile_state = _pad_or_trim(tile_state, TILE_DIM)\n",
    "\n",
    "            return context_state, palette_state, tile_state, dead, raw_position, battle_data\n",
    "\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(0.001)\n",
    "                continue\n",
    "            return (np.zeros(EXPECTED_STATE_DIM), np.zeros(PALETTE_DIM), np.zeros(TILE_DIM),\n",
    "                    False, (0, 0), DEFAULT_BATTLE_DATA.copy())\n",
    "        except Exception:\n",
    "            return (np.zeros(EXPECTED_STATE_DIM), np.zeros(PALETTE_DIM), np.zeros(TILE_DIM),\n",
    "                    False, (0, 0), DEFAULT_BATTLE_DATA.copy())\n",
    "\n",
    "\n",
    "def write_action(action_name):\n",
    "    if action_name:\n",
    "        action_name = action_name.upper()\n",
    "    try:\n",
    "        with open(ACTION_FILE, \"w\") as f:\n",
    "            json.dump({\"action\": action_name}, f)\n",
    "            f.flush()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to write action: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16535a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Perceptron Classes\n",
    "# ============================================================================\n",
    "# CHANGES FROM YOUR ORIGINAL:\n",
    "# 1. ensure_weights() now resizes with old-weight preservation (same as yours)\n",
    "# 2. update() has dimension mismatch fallback matching colleague's approach\n",
    "#    (uses min_dim slicing instead of full resize â€” keeps both paths for safety)\n",
    "# 3. No functional changes â€” your version was already close\n",
    "# ============================================================================\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, kind, action=None, group=None, entity_type=None):\n",
    "        self.kind = kind\n",
    "        self.action = action\n",
    "        self.group = group\n",
    "        self.entity_type = entity_type\n",
    "        \n",
    "        self.utility = 1.0\n",
    "        self.weights = None\n",
    "        \n",
    "        self.eligibility_fast = 0.0\n",
    "        self.eligibility_slow = 0.0\n",
    "        \n",
    "        self.familiarity = 0.0\n",
    "        self.activation_history = deque(maxlen=10)\n",
    "        \n",
    "        self.learning_rate = 0.01\n",
    "        self.prediction_errors = deque(maxlen=50)\n",
    "\n",
    "    def ensure_weights(self, dim):\n",
    "        \"\"\"Initialize or resize weights to match dimension.\"\"\"\n",
    "        if self.weights is None:\n",
    "            self.weights = np.random.randn(dim) * 0.001\n",
    "        elif len(self.weights) != dim:\n",
    "            old_weights = self.weights\n",
    "            self.weights = np.random.randn(dim) * 0.001\n",
    "            min_len = min(len(old_weights), dim)\n",
    "            self.weights[:min_len] = old_weights[:min_len]\n",
    "\n",
    "    def predict(self, state):\n",
    "        self.ensure_weights(len(state))\n",
    "        \n",
    "        # Handle dimension mismatch (matches colleague)\n",
    "        if len(self.weights) != len(state):\n",
    "            min_dim = min(len(self.weights), len(state))\n",
    "            raw_activation = np.dot(self.weights[:min_dim], state[:min_dim])\n",
    "        else:\n",
    "            raw_activation = np.dot(self.weights, state)\n",
    "        \n",
    "        if self.kind == \"entity\":\n",
    "            novelty_factor = 1.0 / (1.0 + np.sqrt(self.familiarity * 0.5))\n",
    "            decayed_activation = raw_activation * novelty_factor\n",
    "            self.activation_history.append(abs(raw_activation))\n",
    "            return decayed_activation\n",
    "        else:\n",
    "            return raw_activation\n",
    "\n",
    "    def adapt_learning_rate(self):\n",
    "        if len(self.prediction_errors) >= 50:\n",
    "            avg_error = np.mean(self.prediction_errors)\n",
    "            if avg_error < 0.1:\n",
    "                self.learning_rate = max(0.001, self.learning_rate * 0.99)\n",
    "            elif avg_error > 0.5:\n",
    "                self.learning_rate = min(0.05, self.learning_rate * 1.01)\n",
    "\n",
    "    def update(self, state, error, gamma_fast=0.5, gamma_slow=0.95, stagnation=0.0):\n",
    "        self.ensure_weights(len(state))\n",
    "        \n",
    "        # Handle dimension mismatch (matches colleague's approach)\n",
    "        if len(self.weights) != len(state):\n",
    "            min_dim = min(len(self.weights), len(state))\n",
    "            state = state[:min_dim]\n",
    "            self.weights = self.weights[:min_dim]\n",
    "        \n",
    "        self.eligibility_fast = gamma_fast * self.eligibility_fast + 1.0\n",
    "        self.eligibility_slow = gamma_slow * self.eligibility_slow + 1.0\n",
    "        \n",
    "        self.adapt_learning_rate()\n",
    "        \n",
    "        fast_update = 0.7 * self.learning_rate * error * state * self.eligibility_fast\n",
    "        slow_update = 0.3 * self.learning_rate * error * state * self.eligibility_slow\n",
    "        self.weights += fast_update + slow_update\n",
    "\n",
    "        if self.kind == \"action\":\n",
    "            if error > 0.01:\n",
    "                if stagnation > 0.5:\n",
    "                    self.utility *= 0.97\n",
    "                elif error > 0.2:\n",
    "                    self.utility = min(self.utility * 1.02, 2.0)\n",
    "                else:\n",
    "                    self.utility *= 0.995\n",
    "            \n",
    "            if self.group == \"move\":\n",
    "                self.utility = np.clip(self.utility, 0.1, 2.0)\n",
    "            else:\n",
    "                self.utility = np.clip(self.utility, 0.01, 2.0)\n",
    "        \n",
    "        if self.kind == \"entity\" and len(self.activation_history) > 0:\n",
    "            recent_avg = np.mean(self.activation_history)\n",
    "            if recent_avg > 0.1:\n",
    "                self.familiarity += 0.03\n",
    "        \n",
    "        if self.kind == \"entity\":\n",
    "            prediction = self.predict(state)\n",
    "            self.prediction_errors.append(abs(prediction - error))\n",
    "\n",
    "\n",
    "class ControlSwapPerceptron(Perceptron):\n",
    "    def __init__(self):\n",
    "        super().__init__(kind=\"control_swap\")\n",
    "        self.swap_history = deque(maxlen=100)\n",
    "        self.confidence = 0.0\n",
    "        \n",
    "    def should_swap(self, state, movement_stagnation):\n",
    "        if self.weights is None:\n",
    "            return False, 0.0\n",
    "        self.ensure_weights(len(state))\n",
    "        swap_score = np.dot(self.weights, state)\n",
    "        stagnation_factor = np.tanh(movement_stagnation / 5.0)\n",
    "        combined_score = swap_score * 0.7 + stagnation_factor * 0.3\n",
    "        return combined_score > 0.5, abs(combined_score)\n",
    "    \n",
    "    def record_swap_outcome(self, state, swapped, novelty_gained):\n",
    "        self.swap_history.append((swapped, novelty_gained))\n",
    "        if len(self.swap_history) >= 20:\n",
    "            recent = list(self.swap_history)[-20:]\n",
    "            successful = sum(1 for swap, nov in recent if swap and nov > 0.2)\n",
    "            self.confidence = successful / 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Brain Class â€” Complete, Aligned with AI Agent\n",
    "# ============================================================================\n",
    "# CHANGES FROM PREVIOUS:\n",
    "# 1. Added self.battle_data â€” current frame battle state from Lua \"b\" field\n",
    "# 2. Added self.battle_data_buffer â€” list of (timestep, battle_data) for\n",
    "#    post-processing into taught_battle_transitions.json\n",
    "# 3. Added self.in_battle_last_frame â€” tracks battle start/end for buffer\n",
    "# 4. Added self.current_battle_id â€” battle counter for buffer indexing\n",
    "# 5. Added update_battle_data() â€” called every frame from main loop\n",
    "# 6. Added get_battle_data_for_range() â€” used by battle extraction\n",
    "# ============================================================================\n",
    "\n",
    "import gc\n",
    "import random\n",
    "\n",
    "class Brain:\n",
    "    def __init__(self):\n",
    "        self.perceptrons = []\n",
    "        self.prev_learning_states = deque(maxlen=50)\n",
    "        self.prev_context_states = deque(maxlen=10)\n",
    "        self.last_positions = deque(maxlen=30)\n",
    "        self.action_history = deque(maxlen=100)\n",
    "        \n",
    "        self.control_mode = \"move\"\n",
    "        self.timestep = 0\n",
    "        self.last_action = None\n",
    "        self.last_direction = 0\n",
    "        \n",
    "        self.MOVE_UTILITY_FLOOR = 0.05\n",
    "        self.INTERACT_UTILITY_FLOOR = 0.15\n",
    "        \n",
    "        # === EXPLORATION MEMORY ===\n",
    "        self.EXPLORATION_MEMORY_FILE = BASE_PATH / \"taught_exploration_memory.json\"\n",
    "        self.exploration_memory = {}\n",
    "        self.current_map_id = None\n",
    "        self.SAVE_INTERVAL = 100\n",
    "        self.MAX_MAPS_IN_MEMORY = 20\n",
    "        \n",
    "        self.DIRECTION_NAMES = {0: \"DOWN\", 1: \"UP\", 2: \"LEFT\", 3: \"RIGHT\"}\n",
    "        self.DIRECTION_TO_INT = {\"DOWN\": 0, \"UP\": 1, \"LEFT\": 2, \"RIGHT\": 3}\n",
    "        self.INT_TO_ACTION = {0: \"DOWN\", 1: \"UP\", 2: \"LEFT\", 3: \"RIGHT\"}\n",
    "        self.DIRECTION_DELTAS_INT = {0: (0, 1), 1: (0, -1), 2: (-1, 0), 3: (1, 0)}\n",
    "        self.ACTION_DELTAS = {\"UP\": (0, -1), \"DOWN\": (0, 1), \"LEFT\": (-1, 0), \"RIGHT\": (1, 0)}\n",
    "        self.DELTA_TO_DIRECTION = {(0, 1): 0, (0, -1): 1, (-1, 0): 2, (1, 0): 3}\n",
    "        \n",
    "        self.load_exploration_memory()\n",
    "        \n",
    "        # === MARKOV TRANSITION SYSTEM ===\n",
    "        self.taught_transitions = []\n",
    "        self.taught_batches = []\n",
    "        self.taught_metadata = {}\n",
    "        self.markov_enabled = True\n",
    "        self.markov_action_count = 0\n",
    "        self.curiosity_action_count = 0\n",
    "        self.last_markov_score = 0.0\n",
    "        self.last_markov_action = None\n",
    "        self.recent_actions_buffer = deque(maxlen=8)\n",
    "        \n",
    "        # === TAUGHT MODEL REFERENCE ===\n",
    "        self.taught_reference = {'utilities': {}, 'weights': {}, 'loaded': False}\n",
    "        \n",
    "        # === BLEND SYSTEM ===\n",
    "        self.blend_tier = 0\n",
    "        self.last_blend_timestep = 0\n",
    "        self.BLEND_COOLDOWN = 50\n",
    "        self.blend_count = 0\n",
    "        self.BLEND_RATIOS = {1: (0.80, 0.20), 2: (0.60, 0.40), 3: (0.40, 0.60)}\n",
    "        self.BLEND_TIER_TRIGGERS = {\n",
    "            1: {'pattern_repeats': 3, 'pos_stagnation': 8, 'consecutive': 12},\n",
    "            2: {'pattern_repeats': 6, 'pos_stagnation': 15, 'consecutive': 15},\n",
    "            3: {'pattern_repeats': 10, 'state_stagnation_mult': 2.0}\n",
    "        }\n",
    "        \n",
    "        # === BATTLE DATA FROM MEMORY ADDRESSES (NEW) ===\n",
    "        # Live battle state read from Lua via \"b\" field in game_state.json\n",
    "        # All values -1 when unavailable (not in battle, or old Lua without \"b\" field)\n",
    "        self.battle_data = DEFAULT_BATTLE_DATA.copy()\n",
    "        \n",
    "        # Buffer of (timestep, battle_data_dict) for every frame while in battle\n",
    "        # Used by battle extraction post-processor to embed into taught_battle_transitions.json\n",
    "        self.battle_data_buffer = []\n",
    "        self.in_battle_last_frame = False\n",
    "        self.current_battle_id = 0\n",
    "        \n",
    "        # === ACTION EXECUTION ===\n",
    "        self.pending_action = None\n",
    "        self.pending_action_frames = 0\n",
    "        self.ACTION_CONFIRM_FRAMES = 3\n",
    "        self.last_confirmed_action = None\n",
    "        \n",
    "        # === TILE INTERACTION ===\n",
    "        self.INTERACTION_VERIFY_FRAMES = 8\n",
    "        self.MIN_SUCCESS_RATE_THRESHOLD = 0.1\n",
    "        self.pending_interaction_verify = None\n",
    "        self.interaction_verify_countdown = 0\n",
    "        \n",
    "        # === MENU TRAP ===\n",
    "        self.menu_trap_frames = 0\n",
    "        self.menu_trap_b_boost = 1.0\n",
    "        self.menu_trap_position = None\n",
    "        self.B_BOOST_INCREMENT = 0.15\n",
    "        self.B_BOOST_MAX = 3.0\n",
    "        self.MENU_TRAP_THRESHOLD = 5\n",
    "        self.original_b_utility = None\n",
    "        \n",
    "        # === MODE SWAPPING ===\n",
    "        self.DEFAULT_MOVE_TO_INTERACT_THRESHOLD = 15\n",
    "        self.DEFAULT_INTERACT_TO_MOVE_THRESHOLD = 25\n",
    "        self.move_to_interact_threshold = self.DEFAULT_MOVE_TO_INTERACT_THRESHOLD\n",
    "        self.interact_to_move_threshold = self.DEFAULT_INTERACT_TO_MOVE_THRESHOLD\n",
    "        self.THRESHOLD_INCREMENT = 15\n",
    "        self.MAX_THRESHOLD = 150\n",
    "        self.frames_in_current_mode = 0\n",
    "        self.swap_chain_count = 0\n",
    "        self.position_at_mode_swap = None\n",
    "        self.last_map_id = None\n",
    "        self.last_battle_state = None\n",
    "        \n",
    "        # === UNPRODUCTIVE SWAP ===\n",
    "        self.UNPRODUCTIVE_SWAP_THRESHOLD = 3\n",
    "        self.unproductive_swap_count = 0\n",
    "        \n",
    "        # === STATE STAGNATION ===\n",
    "        self.STATE_STAGNATION_THRESHOLD = 20\n",
    "        self.state_stagnation_count = 0\n",
    "        self.last_context_state_hash = None\n",
    "        self.stagnation_initiator_action = None\n",
    "        \n",
    "        # === BOTH MODE ===\n",
    "        self.BOTH_MODE_STAGNATION_THRESHOLD = 35\n",
    "        self.BOTH_MODE_SWAP_THRESHOLD = 5\n",
    "        self.last_direction_for_progress = None\n",
    "        self.direction_change_counts_as_progress = True\n",
    "        \n",
    "        # === NOVELTY WEIGHTS ===\n",
    "        self.UNVISITED_TILE_BONUS = 1.5\n",
    "        self.OBSTRUCTION_PENALTY = 0.25\n",
    "        \n",
    "        # === TRANSITIONS & DEBT ===\n",
    "        self.TRANSITION_ATTRACTION_WEIGHT = 0.6\n",
    "        self.TEMP_DEBT_ACCUMULATION = 0.5\n",
    "        self.TEMP_DEBT_DECAY = 0.02\n",
    "        self.TEMP_DEBT_MAX = 15.0\n",
    "        self.MAX_MAP_DEBT = 10.0\n",
    "        self.MAX_LOCATION_DEBT = 5.0\n",
    "        self.DEBT_DECAY_RATE = 0.005\n",
    "        \n",
    "        # === TRANSITION BAN ===\n",
    "        self.transition_bans = {}\n",
    "        self.BAN_VICINITY_RADIUS = 3\n",
    "        self.BAN_COVERAGE_LIFT_THRESHOLD = 0.6\n",
    "        self.BAN_TIMEOUT_STEPS = 300\n",
    "        \n",
    "        # Multi-scale memory\n",
    "        self.visited_maps = {}\n",
    "        self.map_novelty_debt = {}\n",
    "        self.location_memory = {}\n",
    "        self.location_novelty = {}\n",
    "        self.action_execution_count = {}\n",
    "        self.MAX_LOCATIONS = 500\n",
    "        \n",
    "        self.swap_perceptron = ControlSwapPerceptron()\n",
    "        self.error_history = deque(maxlen=100)\n",
    "        self.numeric_error_history = deque(maxlen=100)\n",
    "        self.visual_error_history = deque(maxlen=100)\n",
    "        self._entity_norms_cache = {}\n",
    "        self._cache_valid = False\n",
    "        self.innate_entities_spawned = False\n",
    "        \n",
    "        # === REPETITION ===\n",
    "        self.consecutive_action_count = 0\n",
    "        self.current_repeated_action = None\n",
    "        self.LEARNING_SLOWDOWN_START = 3\n",
    "        self.LEARNING_SLOWDOWN_MAX = 10\n",
    "        self.PENALTY_THRESHOLD = 12\n",
    "        self.HARD_RESET_THRESHOLD = 18\n",
    "        \n",
    "        # === PATTERN ===\n",
    "        self.PATTERN_CHECK_WINDOW = 50\n",
    "        self.PATTERN_MIN_REPEATS = 3\n",
    "        self.PATTERN_MAX_LENGTH = 10\n",
    "        self.detected_pattern = None\n",
    "        self.pattern_repeat_count = 0\n",
    "        \n",
    "        # === PROBE CACHE ===\n",
    "        self._cached_probe_action = None\n",
    "        self._cached_probe_dir = None\n",
    "        self._probe_cache_position = None\n",
    "\n",
    "    # =========================================================================\n",
    "    # BATTLE DATA MANAGEMENT (NEW)\n",
    "    # =========================================================================\n",
    "\n",
    "    def update_battle_data(self, battle_data, in_battle):\n",
    "        \"\"\"\n",
    "        Update battle state from Lua memory reads. Called every frame.\n",
    "        \n",
    "        When in battle, appends (timestep, battle_data) to buffer so the\n",
    "        battle extraction post-processor can embed cursor/species/HP data\n",
    "        into taught_battle_transitions.json frames.\n",
    "        \"\"\"\n",
    "        self.battle_data = battle_data.copy()\n",
    "        \n",
    "        currently_in_battle = in_battle > 0.5\n",
    "        \n",
    "        # Track battle start/end for buffer management\n",
    "        if currently_in_battle and not self.in_battle_last_frame:\n",
    "            self.current_battle_id += 1\n",
    "        \n",
    "        # Buffer battle data every frame while in battle\n",
    "        if currently_in_battle:\n",
    "            self.battle_data_buffer.append({\n",
    "                'timestep': self.timestep,\n",
    "                'battle_id': self.current_battle_id,\n",
    "                'battle_data': battle_data.copy()\n",
    "            })\n",
    "        \n",
    "        self.in_battle_last_frame = currently_in_battle\n",
    "\n",
    "    def get_battle_data_for_timestep(self, timestep):\n",
    "        \"\"\"\n",
    "        Look up battle data for a specific timestep from the buffer.\n",
    "        Used by battle extraction post-processor.\n",
    "        Returns battle_data dict or DEFAULT_BATTLE_DATA if not found.\n",
    "        \"\"\"\n",
    "        for entry in reversed(self.battle_data_buffer):\n",
    "            if entry['timestep'] == timestep:\n",
    "                return entry['battle_data']\n",
    "            if entry['timestep'] < timestep:\n",
    "                break\n",
    "        return DEFAULT_BATTLE_DATA.copy()\n",
    "\n",
    "    def get_all_battle_data_buffer(self):\n",
    "        \"\"\"Return the full battle data buffer for post-processing.\"\"\"\n",
    "        return self.battle_data_buffer\n",
    "\n",
    "    # =========================================================================\n",
    "    # CORE\n",
    "    # =========================================================================\n",
    "    def add(self, p): self.perceptrons.append(p); self._cache_valid = False\n",
    "    def actions(self): return [p for p in self.perceptrons if p.kind == \"action\"]\n",
    "    def entities(self): return [p for p in self.perceptrons if p.kind == \"entity\"]\n",
    "    def get_location_key(self, x, y, mid, bs=5): return (int(mid), int(x//bs)*bs, int(y//bs)*bs)\n",
    "    def is_near_map_edge(self, x, y): return x < 10 or x > 245 or y < 10 or y > 245\n",
    "    def record_action_execution(self, a):\n",
    "        if a: self.action_execution_count[a] = self.action_execution_count.get(a, 0) + 1; self.recent_actions_buffer.append(a)\n",
    "    def get_position_stagnation(self):\n",
    "        if len(self.last_positions) < 2: return 0\n",
    "        cp = self.last_positions[-1]\n",
    "        return sum(1 for p in reversed(list(self.last_positions)[:-1]) if p == cp)\n",
    "    def get_group_weight(self, g): return sum(a.utility for a in self.actions() if a.group == g)\n",
    "    def log_state(self, ls, cs): self.prev_learning_states.append(ls); self.prev_context_states.append(cs)\n",
    "    def update_position(self, x, y): self.last_positions.append((int(x), int(y)))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # MEMORY MANAGEMENT\n",
    "    # =========================================================================\n",
    "    def cleanup_memory(self):\n",
    "        if len(self.location_memory) > self.MAX_LOCATIONS:\n",
    "            sl = sorted(self.location_memory.items(), key=lambda x: x[1], reverse=True)\n",
    "            self.location_memory = dict(sl[:self.MAX_LOCATIONS // 2])\n",
    "            self.location_novelty = {k: v for k, v in self.location_novelty.items() if k in self.location_memory}\n",
    "        if len(self.exploration_memory) > self.MAX_MAPS_IN_MEMORY:\n",
    "            self.save_exploration_memory()\n",
    "            sm = sorted(self.exploration_memory.items(), key=lambda x: x[1].get('last_visited_timestep', 0), reverse=True)\n",
    "            self.exploration_memory = dict(sm[:self.MAX_MAPS_IN_MEMORY // 2])\n",
    "        # Trim battle data buffer if it gets too large (keep last 50000 entries)\n",
    "        if len(self.battle_data_buffer) > 50000:\n",
    "            self.battle_data_buffer = self.battle_data_buffer[-25000:]\n",
    "        self._entity_norms_cache.clear(); self._cache_valid = False; gc.collect()\n",
    "    def get_memory_stats(self):\n",
    "        return {'exploration_maps': len(self.exploration_memory), 'location_memory': len(self.location_memory),\n",
    "                'error_history': len(self.error_history), 'perceptrons': len(self.perceptrons),\n",
    "                'total_tiles': sum(len(m.get('visited_tiles', set())) for m in self.exploration_memory.values()),\n",
    "                'battle_buffer_size': len(self.battle_data_buffer)}\n",
    "\n",
    "    # =========================================================================\n",
    "    # TAUGHT REFERENCE + BLEND\n",
    "    # =========================================================================\n",
    "    def load_taught_reference(self, fp):\n",
    "        try:\n",
    "            if not Path(fp).exists(): print(f\"  No taught reference at {fp}\"); return\n",
    "            with open(fp, 'r') as f: model = json.load(f)\n",
    "            if \"perceptrons\" not in model: return\n",
    "            for sa in model[\"perceptrons\"].get(\"actions\", []):\n",
    "                an = sa.get(\"action\")\n",
    "                if an:\n",
    "                    self.taught_reference['utilities'][an] = sa.get(\"utility\", 1.0)\n",
    "                    if sa.get(\"weights_nonzero\"):\n",
    "                        dim = sa.get(\"weights_shape\", 1376); w = np.zeros(dim)\n",
    "                        for idx, val in sa[\"weights_nonzero\"]:\n",
    "                            if idx < dim: w[idx] = val\n",
    "                        self.taught_reference['weights'][an] = w\n",
    "            self.taught_reference['loaded'] = True\n",
    "            print(f\"  ðŸ“– Taught reference loaded: {list(self.taught_reference['utilities'].keys())}\")\n",
    "        except Exception as e: print(f\"  âš ï¸ Error loading taught reference: {e}\")\n",
    "\n",
    "    def blend_from_taught(self, tier):\n",
    "        if not self.taught_reference['loaded'] or tier not in self.BLEND_RATIOS: return\n",
    "        if self.timestep - self.last_blend_timestep < self.BLEND_COOLDOWN: return\n",
    "        ai_w, tw = self.BLEND_RATIOS[tier]; bw = (tier == 3)\n",
    "        for a in self.actions():\n",
    "            if a.action not in self.taught_reference['utilities']: continue\n",
    "            tu = self.taught_reference['utilities'][a.action]; a.utility = ai_w * a.utility + tw * tu\n",
    "            if tu > 1.0: a.utility = max(a.utility, tu * 0.5)\n",
    "            fl = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "            a.utility = max(min(a.utility, 2.0), fl)\n",
    "            if bw and a.action in self.taught_reference['weights'] and a.weights is not None:\n",
    "                taw = self.taught_reference['weights'][a.action]; md = min(len(a.weights), len(taw))\n",
    "                a.weights[:md] = ai_w * a.weights[:md] + tw * taw[:md]\n",
    "        self.last_blend_timestep = self.timestep; self.blend_tier = tier; self.blend_count += 1\n",
    "\n",
    "    def get_blend_tier(self):\n",
    "        t3 = self.BLEND_TIER_TRIGGERS[3]\n",
    "        if self.detected_pattern and self.pattern_repeat_count >= t3['pattern_repeats']: return 3\n",
    "        if self.state_stagnation_count >= self.STATE_STAGNATION_THRESHOLD * t3['state_stagnation_mult']: return 3\n",
    "        t2 = self.BLEND_TIER_TRIGGERS[2]\n",
    "        if self.detected_pattern and self.pattern_repeat_count >= t2['pattern_repeats']: return 2\n",
    "        if self.get_position_stagnation() >= t2['pos_stagnation']: return 2\n",
    "        if self.consecutive_action_count >= t2['consecutive']: return 2\n",
    "        t1 = self.BLEND_TIER_TRIGGERS[1]\n",
    "        if self.detected_pattern and self.pattern_repeat_count >= t1['pattern_repeats']: return 1\n",
    "        if self.get_position_stagnation() >= t1['pos_stagnation']: return 1\n",
    "        if self.consecutive_action_count >= t1['consecutive']: return 1\n",
    "        return 0\n",
    "\n",
    "    def try_blend_if_needed(self):\n",
    "        if not self.taught_reference['loaded']: return False\n",
    "        tier = self.get_blend_tier()\n",
    "        if tier == 0: return False\n",
    "        if tier <= self.blend_tier and (self.timestep - self.last_blend_timestep) < self.BLEND_COOLDOWN: return False\n",
    "        self.blend_from_taught(tier); return True\n",
    "\n",
    "    # =========================================================================\n",
    "    # MARKOV\n",
    "    # =========================================================================\n",
    "    def load_taught_transitions(self, fp=None):\n",
    "        fp = fp or TAUGHT_TRANSITIONS_FILE\n",
    "        try:\n",
    "            if Path(fp).exists():\n",
    "                with open(fp, 'r') as f: data = json.load(f)\n",
    "                self.taught_transitions = []; self.taught_batches = data.get('batches', [])\n",
    "                for batch in self.taught_batches:\n",
    "                    bt = batch.get('batch_type', 'steady'); ta = batch.get('trigger_action')\n",
    "                    for frame in batch.get('frames', []):\n",
    "                        self.taught_transitions.append({'state': frame.get('state', {}), 'action': frame.get('action'),\n",
    "                            'recent_actions': frame.get('recent_actions', []), 'frame_offset': frame.get('frame_offset', 0),\n",
    "                            'batch_type': bt, 'trigger_action': ta})\n",
    "                self.taught_metadata = data.get('metadata', {})\n",
    "                print(f\"  ðŸ“š Taught transitions: {len(self.taught_batches)} batches, {len(self.taught_transitions)} frames\")\n",
    "            else: self.taught_transitions = []; self.taught_batches = []; self.taught_metadata = {}\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading transitions: {e}\")\n",
    "            self.taught_transitions = []; self.taught_batches = []; self.taught_metadata = {}\n",
    "\n",
    "    def extract_partial_context(self, cs, rp=None):\n",
    "        rx = rp[0] if rp else int(cs[0]*255); ry = rp[1] if rp else int(cs[1]*255); cm = int(cs[2])\n",
    "        mb = self.get_position_stagnation() > 3\n",
    "        nt = False; mem = self.get_current_map_memory(cm)\n",
    "        for t in mem.get('transitions', []):\n",
    "            tp = tuple(t['position']) if isinstance(t['position'], list) else t['position']\n",
    "            if abs(rx - tp[0]) + abs(ry - tp[1]) <= 2: nt = True; break\n",
    "        return {'in_battle': cs[3] > 0.5, 'in_menu': cs[4] > 0.5, 'movement_blocked': mb,\n",
    "                'near_transition': nt, 'tile_probed': not self.should_interact_at_tile(rx, ry, cm)}\n",
    "\n",
    "    def compute_markov_similarity(self, cs, rp=None, taught_frames=None):\n",
    "        frames = taught_frames if taught_frames is not None else self.taught_transitions\n",
    "        smc = taught_frames is not None\n",
    "        if not frames: return 0.0, None, -1\n",
    "        rx = rp[0] if rp else int(cs[0]*255); ry = rp[1] if rp else int(cs[1]*255)\n",
    "        cm = int(cs[2]); cd = int(cs[5]); ib = cs[3] > 0.5; im = cs[4] > 0.5\n",
    "        ca = list(self.action_history); cp = self.extract_partial_context(cs, rp)\n",
    "        bs, ba, bi = 0.0, None, -1\n",
    "        for idx, tr in enumerate(frames):\n",
    "            ts = tr.get('state', {}); ta = tr.get('action'); trc = tr.get('recent_actions', []); bt = tr.get('batch_type', 'steady')\n",
    "            if not ta or ta == \"NONE\": continue\n",
    "            isc = 0.0\n",
    "            if not smc:\n",
    "                if ts.get('map_id') != cm: continue\n",
    "            isc += 0.25\n",
    "            tx, ty = ts.get('x', 0), ts.get('y', 0); pd = abs(rx-tx) + abs(ry-ty)\n",
    "            if pd == 0: isc += MARKOV_POS_EXACT_BONUS\n",
    "            elif pd <= 2: isc += MARKOV_POS_NEAR_BONUS\n",
    "            elif pd <= MARKOV_POS_MAX_DIST: isc += MARKOV_POS_FAR_BONUS\n",
    "            else: continue\n",
    "            if ts.get('direction') == cd: isc += 0.2\n",
    "            tib = ts.get('in_battle', 0) == 1; tim = ts.get('in_menu', 0) == 1\n",
    "            if tib == ib: isc += 0.1\n",
    "            if tim == im: isc += 0.1\n",
    "            ssc = 0.0\n",
    "            if trc and ca:\n",
    "                if len(ca) >= 8 and len(trc) >= 8 and list(ca)[-8:] == trc[-8:]: ssc = MARKOV_SEQ_FULL_WEIGHT\n",
    "                if ssc < MARKOV_SEQ_MEDIUM_WEIGHT and len(ca) >= 5 and len(trc) >= 5 and list(ca)[-5:] == trc[-5:]: ssc = MARKOV_SEQ_MEDIUM_WEIGHT\n",
    "                if ssc < MARKOV_SEQ_SHORT_WEIGHT and len(ca) >= 3 and len(trc) >= 3 and list(ca)[-3:] == trc[-3:]: ssc = MARKOV_SEQ_SHORT_WEIGHT\n",
    "            pm = sum(1 for a, b in [(tib, cp['in_battle']), (tim, cp['in_menu'])] if a == b)\n",
    "            total = MARKOV_IMMEDIATE_WEIGHT * isc + MARKOV_SEQUENTIAL_WEIGHT * ssc + MARKOV_PARTIAL_WEIGHT * (pm / 2)\n",
    "            if bt == \"action_change\": total *= 1.2\n",
    "            if tr.get('frame_offset', 0) == 0: total *= 1.1\n",
    "            if total > bs: bs, ba, bi = total, ta, idx\n",
    "        return bs, ba, bi\n",
    "\n",
    "    def get_markov_action(self, cs, rp=None, taught_frames=None):\n",
    "        if not self.markov_enabled: return False, None, 0.0\n",
    "        frames = taught_frames if taught_frames is not None else self.taught_transitions\n",
    "        if not frames: return False, None, 0.0\n",
    "        sc, ac, ix = self.compute_markov_similarity(cs, rp, taught_frames=frames)\n",
    "        self.last_markov_score = sc\n",
    "        if sc >= MARKOV_FAMILIARITY_THRESHOLD: self.last_markov_action = ac; return True, ac, sc\n",
    "        return False, None, sc\n",
    "\n",
    "    # =========================================================================\n",
    "    # ACTION EXECUTION CONFIRMATION\n",
    "    # =========================================================================\n",
    "    def set_pending_action(self, a): self.pending_action = a; self.pending_action_frames = 0\n",
    "    def confirm_action_executed(self, cs, pcs):\n",
    "        if self.pending_action is None: return True\n",
    "        self.pending_action_frames += 1; ae = False\n",
    "        if pcs is not None:\n",
    "            if self.pending_action in [\"UP\",\"DOWN\",\"LEFT\",\"RIGHT\"]:\n",
    "                ae = cs[0] != pcs[0] or cs[1] != pcs[1] or cs[5] != pcs[5]\n",
    "            elif self.pending_action in [\"A\",\"B\",\"Start\",\"Select\"]:\n",
    "                ae = abs(cs[4]-pcs[4]) > 0.1 or cs[3] != pcs[3] or cs[2] != pcs[2]\n",
    "        if ae or self.pending_action_frames >= self.ACTION_CONFIRM_FRAMES:\n",
    "            self.last_confirmed_action = self.pending_action; self.pending_action = None; self.pending_action_frames = 0; return True\n",
    "        return False\n",
    "    def should_send_new_action(self):\n",
    "        return self.pending_action is None or self.pending_action_frames >= self.ACTION_CONFIRM_FRAMES\n",
    "\n",
    "    # =========================================================================\n",
    "    # EXPLORATION MEMORY\n",
    "    # =========================================================================\n",
    "    def load_exploration_memory(self):\n",
    "        try:\n",
    "            if self.EXPLORATION_MEMORY_FILE.exists():\n",
    "                with open(self.EXPLORATION_MEMORY_FILE, 'r') as f: data = json.load(f)\n",
    "                self.exploration_memory = {}\n",
    "                for mk, md in data.items():\n",
    "                    self.exploration_memory[int(mk.replace('map_', ''))] = self._deserialize_map_memory(md)\n",
    "                print(f\"  Loaded exploration: {len(self.exploration_memory)} maps\")\n",
    "            else: self.exploration_memory = {}\n",
    "        except Exception as e: print(f\"  Error loading exploration: {e}\"); self.exploration_memory = {}\n",
    "\n",
    "    def _deserialize_map_memory(self, d):\n",
    "        ti = {}\n",
    "        for tk, td in d.get('tile_interactions', {}).items():\n",
    "            ti[tk] = {'directions_tried': set(td.get('directions_tried', [])),\n",
    "                      'direction_attempts': {int(k): v for k, v in td.get('direction_attempts', {}).items()},\n",
    "                      'direction_successes': {int(k): v for k, v in td.get('direction_successes', {}).items()},\n",
    "                      'exhausted': td.get('exhausted', False)}\n",
    "        return {'visited_tiles': set(tuple(t) for t in d.get('visited_tiles', [])),\n",
    "                'obstructions': set(tuple(t) for t in d.get('obstructions', [])),\n",
    "                'interactable_objects': d.get('interactable_objects', []),\n",
    "                'last_visited_timestep': d.get('last_visited_timestep', 0),\n",
    "                'transitions': d.get('transitions', []), 'temp_debt': d.get('temp_debt', 0.0),\n",
    "                'tile_interactions': ti}\n",
    "\n",
    "    def save_exploration_memory(self):\n",
    "        try:\n",
    "            data = {f'map_{mid}': self._serialize_map_memory(md) for mid, md in self.exploration_memory.items()}\n",
    "            with open(self.EXPLORATION_MEMORY_FILE, 'w') as f: json.dump(data, f)\n",
    "        except Exception as e: print(f\"  Error saving exploration: {e}\")\n",
    "\n",
    "    def _serialize_map_memory(self, d):\n",
    "        sti = {}\n",
    "        for tk, td in d.get('tile_interactions', {}).items():\n",
    "            sti[tk] = {'directions_tried': list(td.get('directions_tried', set())),\n",
    "                       'direction_attempts': {str(k): v for k, v in td.get('direction_attempts', {}).items()},\n",
    "                       'direction_successes': {str(k): v for k, v in td.get('direction_successes', {}).items()},\n",
    "                       'exhausted': td.get('exhausted', False)}\n",
    "        return {'visited_tiles': [list(t) for t in d['visited_tiles']], 'obstructions': [list(t) for t in d['obstructions']],\n",
    "                'interactable_objects': d['interactable_objects'], 'last_visited_timestep': d['last_visited_timestep'],\n",
    "                'transitions': d.get('transitions', []), 'temp_debt': d.get('temp_debt', 0.0), 'tile_interactions': sti}\n",
    "\n",
    "    def get_current_map_memory(self, mid):\n",
    "        if mid not in self.exploration_memory:\n",
    "            self.exploration_memory[mid] = {'visited_tiles': set(), 'obstructions': set(), 'interactable_objects': [],\n",
    "                'last_visited_timestep': self.timestep, 'transitions': [], 'temp_debt': 0.0, 'tile_interactions': {}}\n",
    "        return self.exploration_memory[mid]\n",
    "\n",
    "    def record_visited_tile(self, x, y, mid):\n",
    "        m = self.get_current_map_memory(mid); m['visited_tiles'].add((int(x), int(y))); m['last_visited_timestep'] = self.timestep\n",
    "    def record_obstruction(self, x, y, mid, d):\n",
    "        dx, dy = self.DIRECTION_DELTAS_INT.get(d, (0,0)); self.get_current_map_memory(mid)['obstructions'].add((int(x+dx), int(y+dy)))\n",
    "\n",
    "    def merge_taught_exploration(self, fp):\n",
    "        if not Path(fp).exists(): print(f\"  No taught exploration at {fp}\"); return\n",
    "        try:\n",
    "            with open(fp, 'r') as f: td = json.load(f)\n",
    "            ta, ia = 0, 0\n",
    "            for mk, md in td.items():\n",
    "                mid = int(mk.replace('map_', '')); tm = self._deserialize_map_memory(md); am = self.get_current_map_memory(mid)\n",
    "                am['visited_tiles'].update(tm['visited_tiles']); am['obstructions'].update(tm['obstructions'])\n",
    "                for tt in tm.get('transitions', []):\n",
    "                    tp = tuple(tt['position']) if isinstance(tt['position'], list) else tt['position']\n",
    "                    if not any((tuple(e['position']) if isinstance(e['position'], list) else e['position']) == tp and e['direction'] == tt['direction'] for e in am['transitions']):\n",
    "                        am['transitions'].append(tt); ta += 1\n",
    "                for ti in tm.get('interactable_objects', []):\n",
    "                    if ti not in am['interactable_objects']: am['interactable_objects'].append(ti); ia += 1\n",
    "            print(f\"  Merged: {ta} transitions, {ia} interactables\")\n",
    "        except Exception as e: print(f\"  Error merging: {e}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # TILE INTERACTION\n",
    "    # =========================================================================\n",
    "    def get_tile_interaction_key(self, x, y): return f\"{int(x)}_{int(y)}\"\n",
    "    def get_tile_interaction_state(self, x, y, mid):\n",
    "        m = self.get_current_map_memory(mid); tk = self.get_tile_interaction_key(x, y)\n",
    "        if tk not in m['tile_interactions']:\n",
    "            m['tile_interactions'][tk] = {'directions_tried': set(), 'direction_attempts': {0:0,1:0,2:0,3:0},\n",
    "                'direction_successes': {0:0,1:0,2:0,3:0}, 'exhausted': False}\n",
    "        return m['tile_interactions'][tk]\n",
    "    def should_interact_at_tile(self, x, y, mid):\n",
    "        ts = self.get_tile_interaction_state(x, y, mid)\n",
    "        if ts['exhausted']: return False\n",
    "        if len(ts['directions_tried']) < 4: return True\n",
    "        return any(ts['direction_attempts'].get(d,0) > 0 and ts['direction_successes'].get(d,0)/ts['direction_attempts'][d] >= self.MIN_SUCCESS_RATE_THRESHOLD for d in range(4))\n",
    "    def get_untried_directions(self, x, y, mid):\n",
    "        return [d for d in range(4) if d not in self.get_tile_interaction_state(x, y, mid)['directions_tried']]\n",
    "    def get_best_interaction_direction(self, x, y, mid):\n",
    "        ts = self.get_tile_interaction_state(x, y, mid)\n",
    "        u = self.get_untried_directions(x, y, mid)\n",
    "        if u: return u[0]\n",
    "        bd, br = None, 0.0\n",
    "        for d in range(4):\n",
    "            a = ts['direction_attempts'].get(d, 0)\n",
    "            if a > 0:\n",
    "                r = ts['direction_successes'].get(d, 0) / a\n",
    "                if r > br: br, bd = r, d\n",
    "        return bd\n",
    "    def get_best_probe_action(self, rx, ry, cm, cd):\n",
    "        ck = (rx, ry, cm, cd)\n",
    "        if self._probe_cache_position == ck: return self._cached_probe_action, self._cached_probe_dir\n",
    "        if not self.should_interact_at_tile(rx, ry, cm): r = (None, None)\n",
    "        else:\n",
    "            u = self.get_untried_directions(rx, ry, cm)\n",
    "            if not u:\n",
    "                bd = self.get_best_interaction_direction(rx, ry, cm)\n",
    "                r = ('A', cd) if bd is not None and cd == bd else (self.INT_TO_ACTION[bd], bd) if bd is not None else (None, None)\n",
    "            elif cd in u: r = ('A', cd)\n",
    "            else: r = (self.INT_TO_ACTION[u[0]], u[0])\n",
    "        self._probe_cache_position = ck; self._cached_probe_action, self._cached_probe_dir = r; return r\n",
    "    def record_tile_interaction_attempt(self, x, y, mid, d, success):\n",
    "        ts = self.get_tile_interaction_state(x, y, mid); ts['directions_tried'].add(d)\n",
    "        ts['direction_attempts'][d] = ts['direction_attempts'].get(d, 0) + 1\n",
    "        if success:\n",
    "            ts['direction_successes'][d] = ts['direction_successes'].get(d, 0) + 1\n",
    "            m = self.get_current_map_memory(mid); dn = self.DIRECTION_NAMES.get(d, str(d))\n",
    "            io = [int(x), int(y), dn]\n",
    "            if io not in m['interactable_objects']: m['interactable_objects'].append(io); print(f\"  ðŸŽ¯ INTERACTABLE: ({x},{y}) {dn}\")\n",
    "        self._check_tile_exhaustion(x, y, mid)\n",
    "    def _check_tile_exhaustion(self, x, y, mid):\n",
    "        ts = self.get_tile_interaction_state(x, y, mid)\n",
    "        if len(ts['directions_tried']) >= 4 and not any(ts['direction_successes'].get(d,0) > 0 for d in range(4)):\n",
    "            ts['exhausted'] = True\n",
    "    def start_interaction_verification(self, x, y, mid, d):\n",
    "        self.pending_interaction_verify = {'x': x, 'y': y, 'map_id': mid, 'direction': d}\n",
    "        self.interaction_verify_countdown = self.INTERACTION_VERIFY_FRAMES\n",
    "    def check_interaction_verification(self, cs, pcs):\n",
    "        if self.pending_interaction_verify is None: return\n",
    "        self.interaction_verify_countdown -= 1; success = False\n",
    "        if pcs is not None:\n",
    "            in_overworld = pcs[3] <= 0.5 and pcs[4] <= 0.5\n",
    "            if in_overworld:\n",
    "                success = abs(cs[4]-pcs[4]) > 0.1 or (cs[3] > 0.5 and pcs[3] <= 0.5) or int(cs[2]) != int(pcs[2])\n",
    "        if success or self.interaction_verify_countdown <= 0:\n",
    "            i = self.pending_interaction_verify\n",
    "            self.record_tile_interaction_attempt(i['x'], i['y'], i['map_id'], i['direction'], success)\n",
    "            self.pending_interaction_verify = None\n",
    "    def get_tile_interaction_stats(self, mid):\n",
    "        m = self.get_current_map_memory(mid); ti = m.get('tile_interactions', {})\n",
    "        return {'probed': len(ti), 'exhausted': sum(1 for t in ti.values() if t.get('exhausted', False)),\n",
    "                'with_success': sum(1 for t in ti.values() if any(t.get('direction_successes',{}).get(d,0) > 0 for d in range(4)))}\n",
    "    def get_exploration_coverage(self, mid):\n",
    "        m = self.get_current_map_memory(mid); v = len(m['visited_tiles']); o = len(m['obstructions'])\n",
    "        return v / (v + o) if v > 0 and v + o >= 10 else 0.0\n",
    "\n",
    "    # =========================================================================\n",
    "    # TRANSITIONS, BANS, DEBT\n",
    "    # =========================================================================\n",
    "    def record_transition(self, fp, fm, tm, d, at):\n",
    "        m = self.get_current_map_memory(fm)\n",
    "        for t in m['transitions']:\n",
    "            if t['position'] == list(fp) and t['direction'] == d: t['use_count'] += 1; t['last_used'] = self.timestep; return\n",
    "        m['transitions'].append({'position': list(fp), 'direction': d, 'action': at, 'destination_map': tm, 'use_count': 1, 'last_used': self.timestep})\n",
    "        print(f\"  ðŸšª TRANSITION: Map {fm} ({fp}) â†’ Map {tm}\")\n",
    "    def get_transition_attraction(self, cm):\n",
    "        m = self.get_current_map_memory(cm); ts = m.get('transitions', [])\n",
    "        if not ts: return 0.0, None\n",
    "        cd = self.map_novelty_debt.get(cm, 0.0); ctd = self.get_temp_debt(cm); cc = self.get_exploration_coverage(cm)\n",
    "        ba, bt = 0.0, None\n",
    "        for t in ts:\n",
    "            if self.is_transition_banned(cm, t['position'], t['direction']): continue\n",
    "            dm = t['destination_map']; dd = self.map_novelty_debt.get(dm, 0.0); dtd = self.get_temp_debt(dm); dc = self.get_exploration_coverage(dm)\n",
    "            a = (cd + ctd*2.0 - dd - dtd*2.0)*0.5 + (cc - dc)*0.5\n",
    "            if t['use_count'] < 3: a *= 1.5\n",
    "            if a > ba: ba, bt = a, t\n",
    "        return ba * self.TRANSITION_ATTRACTION_WEIGHT, bt\n",
    "    def create_transition_ban(self, mid, tp, db):\n",
    "        self.transition_bans[mid] = {'banned_tile': tp, 'banned_direction': db, 'vicinity_radius': self.BAN_VICINITY_RADIUS,\n",
    "            'vicinity_active': False, 'created_at': self.timestep}\n",
    "    def is_transition_banned(self, mid, pos, d):\n",
    "        if mid not in self.transition_bans: return False\n",
    "        b = self.transition_bans[mid]; bt = tuple(b['banned_tile']) if isinstance(b['banned_tile'], list) else b['banned_tile']\n",
    "        pos = tuple(pos) if isinstance(pos, list) else pos\n",
    "        if pos == bt and d == b['banned_direction']: return True\n",
    "        if b['vicinity_active'] and abs(pos[0]-bt[0])+abs(pos[1]-bt[1]) <= b['vicinity_radius'] and d == b['banned_direction']: return True\n",
    "        return False\n",
    "    def is_position_banned(self, mid, x, y, d): return self.is_transition_banned(mid, (x,y), d)\n",
    "    def update_transition_ban(self, mid, cp):\n",
    "        if mid not in self.transition_bans: return\n",
    "        b = self.transition_bans[mid]; bt = tuple(b['banned_tile']) if isinstance(b['banned_tile'], list) else b['banned_tile']\n",
    "        if not b['vicinity_active'] and abs(cp[0]-bt[0])+abs(cp[1]-bt[1]) >= 3: b['vicinity_active'] = True\n",
    "    def check_ban_lift_conditions(self, mid):\n",
    "        if mid not in self.transition_bans: return\n",
    "        b = self.transition_bans[mid]; m = self.get_current_map_memory(mid)\n",
    "        nb = [t for t in m.get('transitions',[]) if not self.is_transition_banned(mid, t['position'], t['direction'])]\n",
    "        if nb or self.get_exploration_coverage(mid) >= self.BAN_COVERAGE_LIFT_THRESHOLD or self.timestep - b['created_at'] >= self.BAN_TIMEOUT_STEPS:\n",
    "            del self.transition_bans[mid]\n",
    "    def get_temp_debt(self, mid):\n",
    "        m = self.get_current_map_memory(mid); rd = m.get('temp_debt', 0.0)\n",
    "        if mid != self.current_map_id:\n",
    "            return max(0.0, rd - (self.timestep - m.get('last_visited_timestep', 0)) * self.TEMP_DEBT_DECAY)\n",
    "        return rd\n",
    "    def accumulate_temp_debt(self, mid):\n",
    "        m = self.get_current_map_memory(mid); m['temp_debt'] = min(self.TEMP_DEBT_MAX, m.get('temp_debt', 0.0) + self.TEMP_DEBT_ACCUMULATION)\n",
    "    def decay_all_debts(self):\n",
    "        for mid in list(self.map_novelty_debt.keys()):\n",
    "            if mid != self.current_map_id:\n",
    "                self.map_novelty_debt[mid] *= (1.0 - self.DEBT_DECAY_RATE)\n",
    "                if self.map_novelty_debt[mid] < 0.1: del self.map_novelty_debt[mid]\n",
    "    def detect_obstruction(self, pc, cs, rp, prp):\n",
    "        if pc is None or prp is None or self.last_action not in ['UP','DOWN','LEFT','RIGHT']: return False\n",
    "        if rp == prp: self.record_obstruction(rp[0], rp[1], int(cs[2]), int(cs[5])); return True\n",
    "        return False\n",
    "\n",
    "    # =========================================================================\n",
    "    # MENU TRAP\n",
    "    # =========================================================================\n",
    "    def update_menu_trap_tracking(self, cs, at, rp=None):\n",
    "        cp = rp if rp else (round(cs[0]*255), round(cs[1]*255))\n",
    "        if self.menu_trap_position is not None and cp != self.menu_trap_position: self.reset_menu_trap_boost(); return\n",
    "        if self.get_context_state_hash(cs) == self.last_context_state_hash and at in [\"A\",\"B\",\"Start\",\"Select\"]:\n",
    "            self.menu_trap_frames += 1; self.menu_trap_position = cp\n",
    "            if self.menu_trap_frames > self.MENU_TRAP_THRESHOLD:\n",
    "                if self.original_b_utility is None:\n",
    "                    for a in self.actions():\n",
    "                        if a.action == 'B': self.original_b_utility = a.utility; break\n",
    "                self.menu_trap_b_boost = min(self.B_BOOST_MAX, self.menu_trap_b_boost + self.B_BOOST_INCREMENT)\n",
    "        elif cp != self.menu_trap_position: self.reset_menu_trap_boost()\n",
    "    def reset_menu_trap_boost(self):\n",
    "        if self.menu_trap_b_boost > 1.0 and self.original_b_utility is not None:\n",
    "            for a in self.actions():\n",
    "                if a.action == 'B': a.utility = self.original_b_utility; break\n",
    "        self.menu_trap_frames = 0; self.menu_trap_b_boost = 1.0; self.menu_trap_position = None; self.original_b_utility = None\n",
    "\n",
    "    # =========================================================================\n",
    "    # STAGNATION, PATTERN, MODE\n",
    "    # =========================================================================\n",
    "    def get_context_state_hash(self, cs):\n",
    "        return (round(cs[0],2), round(cs[1],2), int(cs[2]), int(cs[3]), round(cs[4],2), int(cs[5]))\n",
    "    def check_state_stagnation(self, cs):\n",
    "        ch = self.get_context_state_hash(cs)\n",
    "        if ch == self.last_context_state_hash:\n",
    "            self.state_stagnation_count += 1\n",
    "            if self.state_stagnation_count == 1 and self.last_action: self.stagnation_initiator_action = self.last_action\n",
    "        else: self.state_stagnation_count = 0; self.stagnation_initiator_action = None\n",
    "        self.last_context_state_hash = ch\n",
    "        return self.state_stagnation_count >= self.STATE_STAGNATION_THRESHOLD\n",
    "    def apply_stagnation_initiator_penalty(self):\n",
    "        if self.stagnation_initiator_action is None: return\n",
    "        for a in self.actions():\n",
    "            if a.action == self.stagnation_initiator_action:\n",
    "                fl = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "                a.utility = max(fl, a.utility * 0.5); break\n",
    "        self.stagnation_initiator_action = None\n",
    "    def should_force_random(self):\n",
    "        f = self.get_position_stagnation() >= 8 or self.consecutive_action_count >= 15 or \\\n",
    "            (self.detected_pattern and self.pattern_repeat_count >= 4) or \\\n",
    "            self.state_stagnation_count >= self.STATE_STAGNATION_THRESHOLD * 2\n",
    "        if f: self.try_blend_if_needed()\n",
    "        return f\n",
    "    def get_forced_random_action_name(self):\n",
    "        c = [\"UP\",\"DOWN\",\"LEFT\",\"RIGHT\",\"A\",\"B\"]\n",
    "        if self.current_repeated_action in c: c.remove(self.current_repeated_action)\n",
    "        if self.detected_pattern:\n",
    "            for a in self.detected_pattern:\n",
    "                if a in c: c.remove(a)\n",
    "        return random.choice(c or [\"UP\",\"DOWN\",\"LEFT\",\"RIGHT\"])\n",
    "    def check_productive_change(self, cs):\n",
    "        cm = int(cs[2]); cb = cs[3] > 0.5; cp = (cs[0], cs[1]); p, r = False, \"\"\n",
    "        if self.last_map_id is not None and cm != self.last_map_id: p, r = True, \"map change\"\n",
    "        if self.last_battle_state is not None and cb != self.last_battle_state: p, r = True, \"battle change\"\n",
    "        if self.position_at_mode_swap is not None:\n",
    "            d = np.sqrt((cp[0]-self.position_at_mode_swap[0])**2 + (cp[1]-self.position_at_mode_swap[1])**2)\n",
    "            if d > 0.03: p, r = True, f\"moved {d*255:.1f}\"\n",
    "        cd = int(cs[5])\n",
    "        if self.direction_change_counts_as_progress and self.last_direction_for_progress is not None and cd != self.last_direction_for_progress:\n",
    "            self.state_stagnation_count = max(0, self.state_stagnation_count - 5)\n",
    "        self.last_direction_for_progress = cd; self.last_map_id = cm; self.last_battle_state = cb\n",
    "        return p, r\n",
    "    def on_productive_change(self, r):\n",
    "        self.move_to_interact_threshold = self.DEFAULT_MOVE_TO_INTERACT_THRESHOLD\n",
    "        self.interact_to_move_threshold = self.DEFAULT_INTERACT_TO_MOVE_THRESHOLD\n",
    "        self.swap_chain_count = 0; self.state_stagnation_count = 0; self.stagnation_initiator_action = None; self.unproductive_swap_count = 0\n",
    "        if self.blend_tier > 0: self.blend_tier = 0\n",
    "    def on_mode_swap(self, fm, tm):\n",
    "        self.swap_chain_count += 1; self.frames_in_current_mode = 0; self.unproductive_swap_count += 1\n",
    "        if self.unproductive_swap_count >= self.UNPRODUCTIVE_SWAP_THRESHOLD:\n",
    "            self._reset_highest_to_third(tm); self.unproductive_swap_count = 0\n",
    "        if tm == \"interact\": self.interact_to_move_threshold = min(self.MAX_THRESHOLD, self.interact_to_move_threshold + self.THRESHOLD_INCREMENT)\n",
    "        else: self.move_to_interact_threshold = min(self.MAX_THRESHOLD, self.move_to_interact_threshold + self.THRESHOLD_INCREMENT)\n",
    "    def _reset_highest_to_third(self, mode):\n",
    "        if mode in [\"battle\",\"both\"]: return\n",
    "        g = \"move\" if mode == \"move\" else \"interact\"; ga = sorted([a for a in self.actions() if a.group == g], key=lambda a: a.utility, reverse=True)\n",
    "        if len(ga) >= 3:\n",
    "            fl = self.INTERACT_UTILITY_FLOOR if g == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "            ga[0].utility = max(ga[2].utility * 0.9, fl)\n",
    "    def should_use_both_mode(self):\n",
    "        return self.state_stagnation_count > self.BOTH_MODE_STAGNATION_THRESHOLD or self.unproductive_swap_count > self.BOTH_MODE_SWAP_THRESHOLD\n",
    "    def determine_control_mode(self, cs, raw_position=None):\n",
    "        if cs[3] > 0.5: return \"battle\"\n",
    "        self.frames_in_current_mode += 1; ps = self.get_position_stagnation()\n",
    "        p, r = self.check_productive_change(cs)\n",
    "        if p: self.on_productive_change(r)\n",
    "        if self.should_use_both_mode(): return \"both\"\n",
    "        if self.check_state_stagnation(cs):\n",
    "            self.apply_stagnation_initiator_penalty()\n",
    "            nm = \"interact\" if self.control_mode == \"move\" else \"move\"\n",
    "            self.control_mode = nm; self.position_at_mode_swap = (cs[0], cs[1])\n",
    "            self.on_mode_swap(self.control_mode, nm); self.state_stagnation_count = 0; return self.control_mode\n",
    "        rx = raw_position[0] if raw_position else int(cs[0]*255); ry = raw_position[1] if raw_position else int(cs[1]*255); cm = int(cs[2])\n",
    "        tp = self.should_interact_at_tile(rx, ry, cm); ud = self.get_untried_directions(rx, ry, cm)\n",
    "        if tp and ud and self.control_mode == \"move\" and self.frames_in_current_mode >= 3:\n",
    "            self.control_mode = \"interact\"; self.position_at_mode_swap = (cs[0], cs[1]); self.frames_in_current_mode = 0; return self.control_mode\n",
    "        if self.control_mode == \"move\" and ps >= self.move_to_interact_threshold:\n",
    "            self.control_mode = \"interact\"; self.position_at_mode_swap = (cs[0], cs[1]); self.on_mode_swap(\"move\", \"interact\")\n",
    "        elif self.control_mode == \"interact\":\n",
    "            if (not tp or not ud) and self.frames_in_current_mode >= 5:\n",
    "                self.control_mode = \"move\"; self.position_at_mode_swap = (cs[0], cs[1]); self.frames_in_current_mode = 0\n",
    "            elif self.frames_in_current_mode >= self.interact_to_move_threshold:\n",
    "                self.control_mode = \"move\"; self.position_at_mode_swap = (cs[0], cs[1]); self.on_mode_swap(\"interact\", \"move\")\n",
    "        return self.control_mode\n",
    "\n",
    "    # =========================================================================\n",
    "    # REPETITION & PATTERN\n",
    "    # =========================================================================\n",
    "    def track_consecutive_action(self, an):\n",
    "        if an == self.current_repeated_action: self.consecutive_action_count += 1\n",
    "        else: self.current_repeated_action = an; self.consecutive_action_count = 1\n",
    "    def get_learning_multiplier(self, an):\n",
    "        if an != self.current_repeated_action or self.consecutive_action_count < self.LEARNING_SLOWDOWN_START: return 1.0\n",
    "        return max(0.05, 1.0 - 0.95 * min(1.0, (self.consecutive_action_count - self.LEARNING_SLOWDOWN_START) / (self.LEARNING_SLOWDOWN_MAX - self.LEARNING_SLOWDOWN_START)))\n",
    "    def detect_pattern(self):\n",
    "        if len(self.action_history) < 6: return None, 0\n",
    "        recent = list(self.action_history)[-self.PATTERN_CHECK_WINDOW:]\n",
    "        for pl in range(1, self.PATTERN_MAX_LENGTH + 1):\n",
    "            if len(recent) < pl * self.PATTERN_MIN_REPEATS: continue\n",
    "            cand = tuple(recent[-pl:]); rc, ix = 0, len(recent) - pl\n",
    "            while ix >= 0 and tuple(recent[ix:ix+pl]) == cand: rc += 1; ix -= pl\n",
    "            if rc >= self.PATTERN_MIN_REPEATS: return cand, rc\n",
    "        return None, 0\n",
    "    def apply_pattern_penalty(self):\n",
    "        pat, rc = self.detect_pattern()\n",
    "        if pat is None: self.detected_pattern = None; self.pattern_repeat_count = 0; return\n",
    "        self.detected_pattern, self.pattern_repeat_count = pat, rc\n",
    "        pf = max(0.3, 1.0 - rc * 0.15)\n",
    "        for an in set(pat):\n",
    "            for a in self.actions():\n",
    "                if a.action == an:\n",
    "                    fl = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "                    a.utility = max(fl, a.utility * pf); break\n",
    "    def apply_repetition_penalty(self):\n",
    "        if self.current_repeated_action is None: return\n",
    "        for a in self.actions():\n",
    "            if a.action == self.current_repeated_action:\n",
    "                fl = self.INTERACT_UTILITY_FLOOR if a.group == \"interact\" else self.MOVE_UTILITY_FLOOR\n",
    "                if self.consecutive_action_count >= self.HARD_RESET_THRESHOLD:\n",
    "                    a.utility = fl; self.consecutive_action_count = 0\n",
    "                elif self.consecutive_action_count >= self.PENALTY_THRESHOLD:\n",
    "                    a.utility = max(a.utility * 0.5, fl)\n",
    "                break\n",
    "\n",
    "    # =========================================================================\n",
    "    # EXPLORATION TRACKING\n",
    "    # =========================================================================\n",
    "    def update_exploration_tracking(self, cs, pcs, rp=None, prp=None):\n",
    "        cm = int(cs[2]); rx = rp[0] if rp else int(cs[0]*255); ry = rp[1] if rp else int(cs[1]*255); cp = (rx, ry)\n",
    "        if self.current_map_id is not None and cm != self.current_map_id:\n",
    "            pm = self.current_map_id\n",
    "            if pcs is not None and prp is not None:\n",
    "                self.record_transition(prp, pm, cm, int(pcs[5]), 'interact' if self.last_action == 'A' else 'walk')\n",
    "            if prp is not None:\n",
    "                ed = int(cs[5]) if pcs is not None else 0\n",
    "                self.create_transition_ban(cm, cp, (ed + 2) % 4)\n",
    "            self.on_map_change(cm)\n",
    "        self.current_map_id = cm; self.record_visited_tile(rx, ry, cm); self.accumulate_temp_debt(cm)\n",
    "        self.update_transition_ban(cm, cp); self.check_ban_lift_conditions(cm)\n",
    "        if pcs is not None and prp is not None: self.detect_obstruction(pcs, cs, rp, prp)\n",
    "        self.check_interaction_verification(cs, pcs); self.last_direction = int(cs[5])\n",
    "        if self.timestep % 300 == 0: self.decay_all_debts()\n",
    "    def on_map_change(self, nm):\n",
    "        self.save_exploration_memory(); self.control_mode = \"move\"; self.frames_in_current_mode = 0\n",
    "        m = self.get_current_map_memory(nm)\n",
    "        print(f\"  ðŸ—ºï¸ MAP CHANGE â†’ {nm}: {len(m['visited_tiles'])} visited, {len(m['obstructions'])} obs\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # ENTITY & LEARNING\n",
    "    # =========================================================================\n",
    "    def spawn_innate_entities(self, ls):\n",
    "        if self.innate_entities_spawned: return\n",
    "        for et, ix in [(\"sense_menu\",[5,6]),(\"sense_battle\",[3,4]),(\"sense_movement\",[0,1]),(\"sense_map_transition\",[2])]:\n",
    "            e = Perceptron(\"entity\", entity_type=et); e.ensure_weights(len(ls)); e.weights = np.zeros(len(ls))\n",
    "            for i in ix:\n",
    "                if i < len(e.weights): e.weights[i] = 0.5 if len(ix) > 1 else 1.0\n",
    "            self.add(e)\n",
    "        self.innate_entities_spawned = True\n",
    "    def enforce_utility_floors(self):\n",
    "        for a in self.actions():\n",
    "            a.utility = max(a.utility, self.MOVE_UTILITY_FLOOR if a.group == \"move\" else self.INTERACT_UTILITY_FLOOR)\n",
    "    def stagnation_level(self, w=10):\n",
    "        if len(self.prev_learning_states) < w: return 0.0\n",
    "        r = list(self.prev_learning_states)[-w:]\n",
    "        return 1.0 - np.tanh(np.mean([np.linalg.norm(r[i][:min(len(r[i]),len(r[i-1]))] - r[i-1][:min(len(r[i]),len(r[i-1]))]) for i in range(1, len(r))]) * 2.0)\n",
    "    def predict_future_error(self, st, ac, cs, rp=None):\n",
    "        en = np.mean([e.predict(st) * e.utility for e in self.entities()]) if self.entities() else 0.5\n",
    "        comb = en * 0.7 + ac.utility * 0.3; cm = int(cs[2])\n",
    "        loc = self.get_location_key(*(rp if rp else (cs[0]*255, cs[1]*255)), cm)\n",
    "        td = min(self.map_novelty_debt.get(cm, 0.0), self.MAX_MAP_DEBT) + self.get_temp_debt(cm) + min(self.location_novelty.get(loc, 0.0), self.MAX_LOCATION_DEBT) * 0.5\n",
    "        comb *= 1.0 / (1.0 + td * 5.0)\n",
    "        if ac.action == self.current_repeated_action and self.consecutive_action_count > self.LEARNING_SLOWDOWN_START:\n",
    "            comb *= 1.0 / (1.0 + (self.consecutive_action_count - self.LEARNING_SLOWDOWN_START) * 0.15)\n",
    "        if self.detected_pattern and ac.action in self.detected_pattern:\n",
    "            comb *= 1.0 / (1.0 + self.pattern_repeat_count * 0.2)\n",
    "        return comb + np.random.randn() * 0.05\n",
    "    def compute_multi_modal_error(self, s, ns):\n",
    "        ml = min(len(s), len(ns)); d = [abs(ns[i]-s[i]) for i in range(min(8, ml))]\n",
    "        w = [0.5,0.5,10.0,5.0,3.0,2.0,1.5,0.3]\n",
    "        we = sum(di*wi for di, wi in zip(d, w[:len(d)])) + (np.linalg.norm(ns[8:ml]-s[8:ml])*2.0 if ml > 8 else 0.0)\n",
    "        return we, sum(d), (np.linalg.norm(ns[8:ml]-s[8:ml]) if ml > 8 else 0.0)\n",
    "\n",
    "    def learn(self, ls, nls, cs, ncs, dead=False, raw_position=None, next_raw_position=None):\n",
    "        if ls.shape != nls.shape:\n",
    "            md = max(len(ls), len(nls)); ls = np.pad(ls, (0, max(0, md-len(ls)))); nls = np.pad(nls, (0, max(0, md-len(nls))))\n",
    "        if not self.innate_entities_spawned: self.spawn_innate_entities(ls)\n",
    "        pc = self.prev_context_states[-1] if self.prev_context_states else None\n",
    "        pr = getattr(self, '_last_raw_position', None)\n",
    "        self.update_exploration_tracking(cs, pc, raw_position, pr); self._last_raw_position = raw_position\n",
    "        we, ne, ve = self.compute_multi_modal_error(ls, nls)\n",
    "        self.error_history.append(we); self.numeric_error_history.append(ne); self.visual_error_history.append(ve)\n",
    "        cm = int(cs[2]); loc = self.get_location_key(*(raw_position if raw_position else (cs[0]*255, cs[1]*255)), cm)\n",
    "        self.visited_maps[cm] = self.visited_maps.get(cm, 0) + 1\n",
    "        if len(self.location_memory) < self.MAX_LOCATIONS: self.location_memory[loc] = self.location_memory.get(loc, 0) + 1\n",
    "        if self.visited_maps[cm] > 10: self.map_novelty_debt[cm] = min(self.MAX_MAP_DEBT, self.map_novelty_debt.get(cm, 0.0) + 0.05*(self.visited_maps[cm]-10))\n",
    "        if self.location_memory.get(loc, 0) > 15: self.location_novelty[loc] = min(self.MAX_LOCATION_DEBT, self.location_novelty.get(loc, 0.0) + 0.1*(self.location_memory.get(loc,0)-15))\n",
    "        if self.visited_maps[cm] > 30: we *= 0.5\n",
    "        if self.location_memory.get(loc, 0) > 25: we *= 0.7\n",
    "        stag = self.stagnation_level(); lm = self.get_learning_multiplier(self.last_action) if self.last_action else 1.0\n",
    "        if self.detected_pattern and self.last_action and self.last_action in self.detected_pattern: lm *= 0.5\n",
    "        for p in self.perceptrons:\n",
    "            m = lm if (p.kind == \"action\" and p.action == self.last_action) else 1.0\n",
    "            if p.kind == \"action\" and self.detected_pattern and p.action in self.detected_pattern: m *= 0.5\n",
    "            p.update(ls, we * m, stagnation=stag)\n",
    "        for a in self.actions():\n",
    "            if a.action in ['Start','Select'] and a.weights is not None: a.weights *= 0.999\n",
    "        self.apply_repetition_penalty(); self.apply_pattern_penalty(); self.enforce_utility_floors()\n",
    "        if pc is not None and np.linalg.norm(cs[:2] - pc[:2]) > 0.001 and self.last_action and self.consecutive_action_count < self.PENALTY_THRESHOLD:\n",
    "            for a in self.actions():\n",
    "                if a.action == self.last_action:\n",
    "                    a.utility = min(a.utility * (1.15 if raw_position and self.is_near_map_edge(*raw_position) else 1.08), 2.0); break\n",
    "        if self.timestep % 1000 == 0: self.cleanup_memory()\n",
    "        if self.timestep % self.SAVE_INTERVAL == 0: self.save_exploration_memory()\n",
    "        self.action_history.append(self.last_action)\n",
    "\n",
    "    # =========================================================================\n",
    "    # SAVE/LOAD\n",
    "    # =========================================================================\n",
    "    def save_model_checkpoint(self, filepath=None):\n",
    "        if filepath is None: filepath = BASE_PATH / \"taught_model_checkpoint.json\"\n",
    "        model = {\"timestep\": self.timestep, \"perceptrons\": {\"actions\": [], \"entities\": []},\n",
    "            \"debt_tracking\": {\"map_novelty_debt\": {str(k): v for k, v in self.map_novelty_debt.items()},\n",
    "                \"location_novelty\": {str(k): v for k, v in self.location_novelty.items()},\n",
    "                \"visited_maps\": {str(k): v for k, v in self.visited_maps.items()}},\n",
    "            \"control_mode\": self.control_mode,\n",
    "            \"markov_stats\": {\"markov_action_count\": self.markov_action_count, \"curiosity_action_count\": self.curiosity_action_count},\n",
    "            \"blend_stats\": {\"blend_count\": self.blend_count, \"last_blend_tier\": self.blend_tier},\n",
    "            \"battle_stats\": {\"battles_recorded\": self.current_battle_id, \"battle_buffer_size\": len(self.battle_data_buffer)}}\n",
    "        for a in self.actions():\n",
    "            model[\"perceptrons\"][\"actions\"].append({\"action\": a.action, \"group\": a.group, \"utility\": float(a.utility),\n",
    "                \"weights_shape\": len(a.weights) if a.weights is not None else 0,\n",
    "                \"weights_nonzero\": [[i, float(v)] for i, v in enumerate(a.weights) if abs(v) > 1e-10] if a.weights is not None else [],\n",
    "                \"learning_rate\": float(a.learning_rate), \"familiarity\": float(a.familiarity)})\n",
    "        for e in self.entities():\n",
    "            model[\"perceptrons\"][\"entities\"].append({\"entity_type\": e.entity_type, \"utility\": float(e.utility),\n",
    "                \"weights_shape\": len(e.weights) if e.weights is not None else 0,\n",
    "                \"weights_nonzero\": [[i, float(v)] for i, v in enumerate(e.weights) if abs(v) > 1e-10] if e.weights is not None else [],\n",
    "                \"familiarity\": float(e.familiarity)})\n",
    "        try:\n",
    "            with open(filepath, 'w') as f: json.dump(model, f, indent=2)\n",
    "            print(f\"ðŸ’¾ Model saved: step {self.timestep} â†’ {filepath}\")\n",
    "        except Exception as e: print(f\"âŒ Save error: {e}\")\n",
    "\n",
    "    def load_taught_model(self, fp):\n",
    "        if not Path(fp).exists(): return 0\n",
    "        try:\n",
    "            with open(fp, 'r') as f: model = json.load(f)\n",
    "            if \"perceptrons\" not in model: return 0\n",
    "            for sa in model[\"perceptrons\"][\"actions\"]:\n",
    "                for a in self.actions():\n",
    "                    if a.action == sa[\"action\"]:\n",
    "                        a.utility = sa[\"utility\"]; a.learning_rate = sa.get(\"learning_rate\", 0.01); a.familiarity = sa.get(\"familiarity\", 0.0)\n",
    "                        if sa.get(\"weights_nonzero\"):\n",
    "                            dim = sa.get(\"weights_shape\", 1376); a.weights = np.zeros(dim)\n",
    "                            for idx, val in sa[\"weights_nonzero\"]:\n",
    "                                if idx < dim: a.weights[idx] = val\n",
    "                        break\n",
    "            for se in model[\"perceptrons\"].get(\"entities\", []):\n",
    "                for e in self.entities():\n",
    "                    if e.entity_type == se.get(\"entity_type\"):\n",
    "                        e.utility = se.get(\"utility\", 1.0); e.familiarity = se.get(\"familiarity\", 0.0)\n",
    "                        if se.get(\"weights_nonzero\"):\n",
    "                            dim = se.get(\"weights_shape\", 1376); e.weights = np.zeros(dim)\n",
    "                            for idx, val in se[\"weights_nonzero\"]:\n",
    "                                if idx < dim: e.weights[idx] = val\n",
    "                        break\n",
    "            if \"debt_tracking\" in model:\n",
    "                d = model[\"debt_tracking\"]; self.map_novelty_debt = {int(k): v for k, v in d.get(\"map_novelty_debt\", {}).items()}\n",
    "                self.visited_maps = {int(k): v for k, v in d.get(\"visited_maps\", {}).items()}\n",
    "                for k, v in d.get(\"location_novelty\", {}).items():\n",
    "                    try: self.location_novelty[eval(k)] = v\n",
    "                    except: pass\n",
    "            ms = model.get(\"markov_stats\", {}); self.markov_action_count = ms.get(\"markov_action_count\", 0); self.curiosity_action_count = ms.get(\"curiosity_action_count\", 0)\n",
    "            bs = model.get(\"blend_stats\", {}); self.blend_count = bs.get(\"blend_count\", 0); self.blend_tier = bs.get(\"last_blend_tier\", 0)\n",
    "            bts = model.get(\"battle_stats\", {}); self.current_battle_id = bts.get(\"battles_recorded\", 0)\n",
    "            self.timestep = model.get(\"timestep\", 0); return self.timestep\n",
    "        except Exception as e: print(f\"  âš ï¸ Load error: {e}\"); return 0\n",
    "    def save_model(self, fp=None): self.save_model_checkpoint(fp)\n",
    "    def load_model(self, fp=None): return self.load_taught_model(fp or (BASE_PATH / \"taught_model_checkpoint.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07840e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Teaching Mode Main Loop + Auto Post-Processing on Shutdown\n",
    "# ============================================================================\n",
    "# CHANGES FROM PREVIOUS:\n",
    "# 1. read_game_state() now returns 6 values â€” unpack battle_data\n",
    "# 2. brain.update_battle_data() called every frame with battle_data + in_battle\n",
    "# 3. run_battle_extraction() now embeds battle data (bc,mc,ps,es,ph,pm,eh,pc)\n",
    "#    into each frame of taught_battle_transitions.json using the brain's\n",
    "#    battle_data_buffer. This gives the AI cursor/species/HP for Markov matching.\n",
    "# 4. Battle logging in main loop shows species/HP when in battle\n",
    "# 5. All 5 taught files ready to copy to AI agent\n",
    "# ============================================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================================================================\n",
    "# POST-PROCESSOR 1: per_map_analysis (UNCHANGED)\n",
    "# =========================================================================\n",
    "def run_per_map_analysis():\n",
    "    if not TAUGHT_TRANSITIONS_FILE.exists():\n",
    "        print(\"  âš ï¸ No taught_transitions.json â€” skipping per_map_analysis\")\n",
    "        return\n",
    "    with open(TAUGHT_TRANSITIONS_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    batches = data.get('batches', [])\n",
    "    if not batches:\n",
    "        print(\"  âš ï¸ No batches â€” skipping per_map_analysis\")\n",
    "        return\n",
    "    all_frames = []\n",
    "    for batch in batches:\n",
    "        for frame in batch.get('frames', []):\n",
    "            all_frames.append(frame)\n",
    "    print(f\"  Analyzing {len(all_frames)} frames...\")\n",
    "    frames_by_map = defaultdict(list)\n",
    "    for i, frame in enumerate(all_frames):\n",
    "        mid = frame.get('state', {}).get('map_id')\n",
    "        if mid is not None:\n",
    "            frames_by_map[mid].append((i, frame))\n",
    "    per_map = {}\n",
    "    for map_id, indexed_frames in frames_by_map.items():\n",
    "        mk = str(map_id)\n",
    "        ta = defaultdict(lambda: defaultdict(int))\n",
    "        td = defaultdict(lambda: defaultdict(int))\n",
    "        tt = defaultdict(int)\n",
    "        for i, fr in indexed_frames:\n",
    "            s = fr.get('state', {}); x, y = s.get('x', 0), s.get('y', 0)\n",
    "            tk = f\"{x}_{y}\"; act = fr.get('action', 'NONE'); dr = s.get('direction', 0)\n",
    "            ta[tk][act] += 1; td[tk][str(dr)] += 1; tt[tk] += 1\n",
    "        ap = {}\n",
    "        for tk in ta:\n",
    "            total = tt[tk]\n",
    "            if total == 0: continue\n",
    "            probs = {a: round(c/total, 3) for a, c in ta[tk].items()}\n",
    "            probs['total_frames'] = total; probs['direction_facing'] = dict(td[tk]); ap[tk] = probs\n",
    "        mg = defaultdict(set)\n",
    "        for idx in range(len(indexed_frames) - 1):\n",
    "            _, f1 = indexed_frames[idx]; _, f2 = indexed_frames[idx+1]\n",
    "            s1, s2 = f1.get('state', {}), f2.get('state', {})\n",
    "            if s1.get('map_id') != s2.get('map_id'): continue\n",
    "            x1, y1 = s1.get('x',0), s1.get('y',0); x2, y2 = s2.get('x',0), s2.get('y',0)\n",
    "            if (x1,y1) != (x2,y2):\n",
    "                t1, t2 = f\"{x1}_{y1}\", f\"{x2}_{y2}\"; mg[t1].add(t2); mg[t2].add(t1)\n",
    "        mg_s = {k: sorted(list(v)) for k, v in mg.items()}\n",
    "        dp = []\n",
    "        for idx in range(1, len(indexed_frames)):\n",
    "            _, fp = indexed_frames[idx-1]; gi, fc = indexed_frames[idx]\n",
    "            ap2, ac = fp.get('action','NONE'), fc.get('action','NONE')\n",
    "            if ap2 != ac and ac != 'NONE' and ap2 != 'NONE':\n",
    "                s = fc.get('state', {})\n",
    "                dp.append({'position': [s.get('x',0), s.get('y',0)], 'from_action': ap2, 'to_action': ac,\n",
    "                    'frame': gi, 'facing': s.get('direction',0),\n",
    "                    'context': {'in_battle': s.get('in_battle',0), 'in_menu': s.get('in_menu',0)}})\n",
    "        dd = defaultdict(lambda: {'visits': 0, 'frames': [], 'current_run': 0}); lt = None\n",
    "        for i, fr in indexed_frames:\n",
    "            s = fr.get('state', {}); tk = f\"{s.get('x',0)}_{s.get('y',0)}\"\n",
    "            if tk == lt: dd[tk]['current_run'] += 1\n",
    "            else:\n",
    "                if lt is not None and dd[lt]['current_run'] > 0: dd[lt]['frames'].append(dd[lt]['current_run'])\n",
    "                dd[tk]['visits'] += 1; dd[tk]['current_run'] = 1; lt = tk\n",
    "        if lt is not None and dd[lt]['current_run'] > 0: dd[lt]['frames'].append(dd[lt]['current_run'])\n",
    "        dtimes = {}\n",
    "        for tk, d in dd.items():\n",
    "            runs = d['frames']\n",
    "            if not runs: continue\n",
    "            total = sum(runs)\n",
    "            dtimes[tk] = {'total_frames': total, 'visits': d['visits'], 'avg_dwell': round(total/len(runs),1), 'max_dwell': max(runs)}\n",
    "        ps = []; cs = None\n",
    "        for idx in range(len(indexed_frames)):\n",
    "            gi, fr = indexed_frames[idx]; s = fr.get('state', {}); act = fr.get('action', 'NONE')\n",
    "            x, y = s.get('x',0), s.get('y',0)\n",
    "            if act not in ('UP','DOWN','LEFT','RIGHT'):\n",
    "                if cs and len(cs['tiles']) >= 3:\n",
    "                    cs['end'] = cs['tiles'][-1]; cs['length'] = len(cs['tiles']); cs['frame_end'] = gi; ps.append(cs)\n",
    "                cs = None; continue\n",
    "            if cs is None or act != cs['primary_action']:\n",
    "                if cs and len(cs['tiles']) >= 3:\n",
    "                    cs['end'] = cs['tiles'][-1]; cs['length'] = len(cs['tiles']); cs['frame_end'] = gi-1; ps.append(cs)\n",
    "                cs = {'start': [x,y], 'end': [x,y], 'tiles': [[x,y]], 'primary_action': act, 'actions': [act], 'length': 1, 'frame_start': gi, 'frame_end': gi}\n",
    "            else:\n",
    "                pos = [x, y]\n",
    "                if pos != cs['tiles'][-1]: cs['tiles'].append(pos)\n",
    "                cs['actions'].append(act)\n",
    "        if cs and len(cs['tiles']) >= 3:\n",
    "            cs['end'] = cs['tiles'][-1]; cs['length'] = len(cs['tiles']); cs['frame_end'] = indexed_frames[-1][0]; ps.append(cs)\n",
    "        per_map[mk] = {'action_probabilities': ap, 'movement_graph': mg_s, 'decision_points': dp, 'dwell_times': dtimes, 'path_segments': ps}\n",
    "        print(f\"    Map {map_id}: {len(ap)} tiles, {len(dp)} decisions, {len(ps)} paths\")\n",
    "    data['per_map_analysis'] = per_map\n",
    "    with open(TAUGHT_TRANSITIONS_FILE, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    print(f\"  âœ… per_map_analysis â†’ {TAUGHT_TRANSITIONS_FILE.name}\")\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# POST-PROCESSOR 2: taught_nav_targets.json (UNCHANGED)\n",
    "# =========================================================================\n",
    "NAV_TARGETS_PATH = BASE_PATH / \"taught_nav_targets.json\"\n",
    "ANALYSIS_WINDOW_AFTER = 40\n",
    "RECENT_WINDOW = 100\n",
    "MIN_FORWARD_PROGRESS = 0.5\n",
    "DEDUP_RADIUS_NAV = 2\n",
    "BACKTRACK_WINDOW = 50\n",
    "BACKTRACK_PROXIMITY = 3\n",
    "\n",
    "def run_nav_target_extraction():\n",
    "    if not TAUGHT_TRANSITIONS_FILE.exists():\n",
    "        print(\"  âš ï¸ No taught_transitions.json â€” writing empty nav targets\")\n",
    "        _write_empty_nav_targets(); return\n",
    "    with open(TAUGHT_TRANSITIONS_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    all_frames = []\n",
    "    for batch in data.get('batches', []):\n",
    "        for frame in batch.get('frames', []): all_frames.append(frame)\n",
    "    if not all_frames:\n",
    "        print(\"  âš ï¸ No frames â€” writing empty nav targets\"); _write_empty_nav_targets(); return\n",
    "    print(f\"  Scanning {len(all_frames)} frames for novelty...\")\n",
    "    novelty_points = []\n",
    "    for i, frame in enumerate(all_frames):\n",
    "        s = frame.get('state', {}); x, y = s.get('x',0), s.get('y',0)\n",
    "        mid = s.get('map_id',0); d = s.get('direction',0)\n",
    "        ib, im = s.get('in_battle',0), s.get('in_menu',0)\n",
    "        act = frame.get('action', 'NONE')\n",
    "        ps = all_frames[i-1].get('state', {}) if i > 0 else {}\n",
    "        pmid, pib = ps.get('map_id', mid), ps.get('in_battle', 0)\n",
    "        if i > 0 and mid != pmid:\n",
    "            px, py = ps.get('x', x), ps.get('y', y)\n",
    "            novelty_points.append({'position': [px,py], 'map_id': pmid, 'direction': ps.get('direction',d),\n",
    "                'frame_index': i, 'novelty_type': 'map_transition', 'destination_map': mid}); continue\n",
    "        if ib == 1 and pib == 0:\n",
    "            novelty_points.append({'position': [x,y], 'map_id': mid, 'direction': d,\n",
    "                'frame_index': i, 'novelty_type': 'battle', 'destination_map': None}); continue\n",
    "        if act == 'A' and ib == 0 and im == 0:\n",
    "            triggered = False\n",
    "            for j in range(i+1, min(i+9, len(all_frames))):\n",
    "                fs = all_frames[j].get('state', {})\n",
    "                if fs.get('in_menu', 0) != im or fs.get('map_id', mid) != mid: triggered = True; break\n",
    "            if triggered:\n",
    "                novelty_points.append({'position': [x,y], 'map_id': mid, 'direction': d,\n",
    "                    'frame_index': i, 'novelty_type': 'interaction', 'destination_map': None}); continue\n",
    "        if ib == 0 and im == 0 and i > RECENT_WINDOW:\n",
    "            was_recent = any(all_frames[j].get('state',{}).get('map_id')==mid and all_frames[j].get('state',{}).get('x')==x and all_frames[j].get('state',{}).get('y')==y for j in range(max(0,i-RECENT_WINDOW), max(0,i-5)))\n",
    "            if not was_recent:\n",
    "                too_close = novelty_points and novelty_points[-1]['map_id']==mid and abs(novelty_points[-1]['position'][0]-x)+abs(novelty_points[-1]['position'][1]-y)<=DEDUP_RADIUS_NAV\n",
    "                if not too_close:\n",
    "                    novelty_points.append({'position': [x,y], 'map_id': mid, 'direction': d,\n",
    "                        'frame_index': i, 'novelty_type': 'new_area', 'destination_map': None})\n",
    "    tc = defaultdict(int)\n",
    "    for np_item in novelty_points: tc[np_item['novelty_type']] += 1\n",
    "    print(f\"    Novelty points: {len(novelty_points)} ({', '.join(f'{t}:{c}' for t,c in tc.items())})\")\n",
    "    scored = []\n",
    "    for np_item in novelty_points:\n",
    "        fi = np_item['frame_index']; mid = np_item['map_id']; px, py = np_item['position']\n",
    "        before = set()\n",
    "        for j in range(max(0,fi-RECENT_WINDOW), fi):\n",
    "            js = all_frames[j].get('state', {})\n",
    "            if js.get('in_battle',0)==0 and js.get('in_menu',0)==0:\n",
    "                before.add((js.get('map_id',0), js.get('x',0), js.get('y',0)))\n",
    "        after_new, after_total = 0, 0\n",
    "        for j in range(fi+1, min(fi+1+ANALYSIS_WINDOW_AFTER, len(all_frames))):\n",
    "            js = all_frames[j].get('state', {})\n",
    "            if js.get('in_battle',0)==1 or js.get('in_menu',0)==1: continue\n",
    "            after_total += 1\n",
    "            if (js.get('map_id',0), js.get('x',0), js.get('y',0)) not in before: after_new += 1\n",
    "        fwd = after_new / after_total if after_total > 0 else 0.0\n",
    "        bt = False\n",
    "        if np_item['novelty_type'] == 'map_transition':\n",
    "            for j in range(fi+1, min(fi+1+BACKTRACK_WINDOW, len(all_frames))):\n",
    "                if all_frames[j].get('state',{}).get('map_id') == mid: bt = True; break\n",
    "        else:\n",
    "            for j in range(fi+5, min(fi+1+BACKTRACK_WINDOW, len(all_frames))):\n",
    "                js = all_frames[j].get('state', {})\n",
    "                if js.get('map_id')==mid and abs(js.get('x',0)-px)+abs(js.get('y',0)-py)<=BACKTRACK_PROXIMITY: bt = True; break\n",
    "        if bt or fwd < MIN_FORWARD_PROGRESS: continue\n",
    "        np_item['forward_progress_score'] = round(fwd, 3); scored.append(np_item)\n",
    "    print(f\"    After filtering: {len(scored)} targets\")\n",
    "    deduped = []\n",
    "    by_map = defaultdict(list)\n",
    "    for t in scored: by_map[t['map_id']].append(t)\n",
    "    for mid, targets in by_map.items():\n",
    "        targets.sort(key=lambda t: t['forward_progress_score'], reverse=True)\n",
    "        kept = []\n",
    "        for t in targets:\n",
    "            tx, ty = t['position']\n",
    "            if not any(abs(tx-k['position'][0])+abs(ty-k['position'][1])<=DEDUP_RADIUS_NAV for k in kept): kept.append(t)\n",
    "        deduped.extend(kept)\n",
    "    deduped.sort(key=lambda t: t['frame_index'])\n",
    "    tbm = defaultdict(list); go = []\n",
    "    for order, t in enumerate(deduped, 1):\n",
    "        mk = str(t['map_id'])\n",
    "        tbm[mk].append({'position': t['position'], 'direction': t['direction'], 'order': order,\n",
    "            'progress_type': t['novelty_type'], 'forward_progress_score': t['forward_progress_score'],\n",
    "            'destination_map': t.get('destination_map'), 'frame_index': t['frame_index']})\n",
    "        go.append({'map_id': t['map_id'], 'position': t['position'], 'order': order})\n",
    "    output = {'targets_by_map': dict(tbm), 'global_order': go,\n",
    "        'metadata': {'total_targets': len(deduped), 'maps_with_targets': sorted(set(t['map_id'] for t in deduped)),\n",
    "            'analysis_window_after': ANALYSIS_WINDOW_AFTER, 'min_forward_progress': MIN_FORWARD_PROGRESS,\n",
    "            'dedup_radius': DEDUP_RADIUS_NAV, 'generated_from_frames': len(all_frames)}}\n",
    "    with open(NAV_TARGETS_PATH, 'w') as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    print(f\"  âœ… taught_nav_targets.json â†’ {len(deduped)} targets across {len(tbm)} maps\")\n",
    "\n",
    "def _write_empty_nav_targets():\n",
    "    with open(NAV_TARGETS_PATH, 'w') as f:\n",
    "        json.dump({'targets_by_map': {}, 'global_order': [], 'metadata': {'total_targets': 0, 'maps_with_targets': [],\n",
    "            'analysis_window_after': ANALYSIS_WINDOW_AFTER, 'min_forward_progress': MIN_FORWARD_PROGRESS,\n",
    "            'dedup_radius': DEDUP_RADIUS_NAV, 'generated_from_frames': 0}}, f, indent=2)\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# POST-PROCESSOR 3: taught_battle_transitions.json\n",
    "# NOW EMBEDS BATTLE DATA (bc, mc, ps, es, ph, pm, eh, pc) per frame\n",
    "# =========================================================================\n",
    "BATTLE_TRANSITIONS_PATH = BASE_PATH / \"taught_battle_transitions.json\"\n",
    "\n",
    "POKEMON_CENTER_MAPS = {1, 2, 3, 4}\n",
    "\n",
    "def run_battle_extraction():\n",
    "    \"\"\"\n",
    "    Extract all battle frames from taught_transitions.json into\n",
    "    taught_battle_transitions.json.\n",
    "    \n",
    "    NEW: Each battle frame now includes a 'battle_data' field with\n",
    "    cursor/species/HP from the brain's battle_data_buffer, so the AI\n",
    "    agent can use these signals for Markov matching.\n",
    "    \n",
    "    Produces:\n",
    "    - battle_sequences: grouped by individual battles with outcomes\n",
    "    - flat_frames: flattened for AI's Markov scanning\n",
    "    - metadata: battle counts, common sequences, outcomes\n",
    "    \"\"\"\n",
    "    if not TAUGHT_TRANSITIONS_FILE.exists():\n",
    "        print(\"  âš ï¸ No taught_transitions.json â€” writing empty battle transitions\")\n",
    "        _write_empty_battle_transitions(); return\n",
    "    \n",
    "    with open(TAUGHT_TRANSITIONS_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    all_frames = []\n",
    "    for batch in data.get('batches', []):\n",
    "        bt = batch.get('batch_type', 'steady')\n",
    "        for frame in batch.get('frames', []):\n",
    "            frame['_batch_type'] = bt\n",
    "            all_frames.append(frame)\n",
    "    \n",
    "    if not all_frames:\n",
    "        print(\"  âš ï¸ No frames â€” writing empty battle transitions\")\n",
    "        _write_empty_battle_transitions(); return\n",
    "    \n",
    "    print(f\"  Scanning {len(all_frames)} frames for battles...\")\n",
    "    \n",
    "    # Build battle data lookup from brain's buffer\n",
    "    # Index by battle_id for fast lookup\n",
    "    battle_buffer = brain.get_all_battle_data_buffer()\n",
    "    buffer_by_battle_id = defaultdict(list)\n",
    "    for entry in battle_buffer:\n",
    "        buffer_by_battle_id[entry['battle_id']].append(entry)\n",
    "    \n",
    "    print(f\"    Battle data buffer: {len(battle_buffer)} entries across {len(buffer_by_battle_id)} battles\")\n",
    "    \n",
    "    # === STEP 1: Find battle sequences ===\n",
    "    battle_sequences = []\n",
    "    current_battle = None\n",
    "    battle_id = 0\n",
    "    \n",
    "    for i, frame in enumerate(all_frames):\n",
    "        s = frame.get('state', {})\n",
    "        ib = s.get('in_battle', 0)\n",
    "        \n",
    "        if ib == 1 and current_battle is None:\n",
    "            battle_id += 1\n",
    "            current_battle = {\n",
    "                'battle_id': battle_id,\n",
    "                'start_frame': i,\n",
    "                'end_frame': i,\n",
    "                'map_id': s.get('map_id', 0),\n",
    "                'frames': [],\n",
    "                'recent_actions_buffer': [],\n",
    "                'frame_index_in_battle': 0\n",
    "            }\n",
    "        \n",
    "        if ib == 1 and current_battle is not None:\n",
    "            action = frame.get('action', 'NONE')\n",
    "            recent = frame.get('recent_actions', [])\n",
    "            \n",
    "            if len(recent) < 8:\n",
    "                recent = (['NONE'] * (8 - len(recent))) + recent\n",
    "            elif len(recent) > 8:\n",
    "                recent = recent[-8:]\n",
    "            \n",
    "            # Look up battle data from buffer for this battle\n",
    "            # Match by battle_id and frame index within the battle\n",
    "            bd_short = _lookup_battle_data(\n",
    "                buffer_by_battle_id, battle_id,\n",
    "                current_battle['frame_index_in_battle']\n",
    "            )\n",
    "            \n",
    "            battle_frame = {\n",
    "                'state': {\n",
    "                    'map_id': s.get('map_id', 0),\n",
    "                    'x': s.get('x', 0),\n",
    "                    'y': s.get('y', 0),\n",
    "                    'direction': s.get('direction', 0),\n",
    "                    'in_battle': 1,\n",
    "                    'in_menu': s.get('in_menu', 0)\n",
    "                },\n",
    "                'action': action if action else 'NONE',\n",
    "                'recent_actions': recent,\n",
    "                'frame_offset': frame.get('frame_offset', 0),\n",
    "                'batch_type': frame.get('_batch_type', 'steady'),\n",
    "                'battle_data': bd_short  # NEW: cursor/species/HP data\n",
    "            }\n",
    "            \n",
    "            current_battle['frames'].append(battle_frame)\n",
    "            current_battle['end_frame'] = i\n",
    "            current_battle['frame_index_in_battle'] += 1\n",
    "            if action and action != 'NONE':\n",
    "                current_battle['recent_actions_buffer'].append(action)\n",
    "        \n",
    "        elif ib == 0 and current_battle is not None:\n",
    "            duration = len(current_battle['frames'])\n",
    "            \n",
    "            if duration >= 2:\n",
    "                outcome = _detect_battle_outcome(current_battle, all_frames, i)\n",
    "                \n",
    "                battle_seq = {\n",
    "                    'battle_id': current_battle['battle_id'],\n",
    "                    'start_frame': current_battle['start_frame'],\n",
    "                    'end_frame': current_battle['end_frame'],\n",
    "                    'map_id': current_battle['map_id'],\n",
    "                    'duration_frames': duration,\n",
    "                    'outcome': outcome,\n",
    "                    'frames': current_battle['frames']\n",
    "                }\n",
    "                battle_sequences.append(battle_seq)\n",
    "            \n",
    "            current_battle = None\n",
    "    \n",
    "    if current_battle is not None and len(current_battle['frames']) >= 2:\n",
    "        battle_sequences.append({\n",
    "            'battle_id': current_battle['battle_id'],\n",
    "            'start_frame': current_battle['start_frame'],\n",
    "            'end_frame': current_battle['end_frame'],\n",
    "            'map_id': current_battle['map_id'],\n",
    "            'duration_frames': len(current_battle['frames']),\n",
    "            'outcome': 'unknown',\n",
    "            'frames': current_battle['frames']\n",
    "        })\n",
    "    \n",
    "    # === STEP 2: Build flat_frames ===\n",
    "    flat_frames = []\n",
    "    for seq in battle_sequences:\n",
    "        for frame in seq['frames']:\n",
    "            flat_frame = dict(frame)\n",
    "            flat_frame['battle_id'] = seq['battle_id']\n",
    "            flat_frames.append(flat_frame)\n",
    "    \n",
    "    # === STEP 3: Compute metadata ===\n",
    "    outcomes = defaultdict(int)\n",
    "    maps_with_battles = set()\n",
    "    for seq in battle_sequences:\n",
    "        outcomes[seq['outcome']] += 1\n",
    "        maps_with_battles.add(seq['map_id'])\n",
    "    \n",
    "    avg_length = (sum(s['duration_frames'] for s in battle_sequences) / \n",
    "                  len(battle_sequences)) if battle_sequences else 0\n",
    "    \n",
    "    # Count frames with battle data\n",
    "    frames_with_bd = sum(1 for f in flat_frames \n",
    "                         if f.get('battle_data') and f['battle_data'].get('bc', -1) != -1)\n",
    "    \n",
    "    seq_counts = defaultdict(int)\n",
    "    for seq in battle_sequences:\n",
    "        actions = [f['action'] for f in seq['frames'] if f['action'] != 'NONE']\n",
    "        for win_size in [2, 3, 4]:\n",
    "            for j in range(len(actions) - win_size + 1):\n",
    "                window = tuple(actions[j:j+win_size])\n",
    "                seq_counts[window] += 1\n",
    "    \n",
    "    common_seqs = sorted(seq_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    most_common = []\n",
    "    for seq_tuple, count in common_seqs:\n",
    "        context = _guess_sequence_context(list(seq_tuple))\n",
    "        most_common.append({\n",
    "            'sequence': list(seq_tuple),\n",
    "            'count': count,\n",
    "            'context': context\n",
    "        })\n",
    "    \n",
    "    metadata = {\n",
    "        'total_battle_frames': len(flat_frames),\n",
    "        'battles_recorded': len(battle_sequences),\n",
    "        'avg_battle_length': round(avg_length, 1),\n",
    "        'outcomes': dict(outcomes),\n",
    "        'maps_with_battles': sorted(maps_with_battles),\n",
    "        'most_common_sequences': most_common,\n",
    "        'frames_with_battle_data': frames_with_bd,\n",
    "        'battle_data_coverage': round(frames_with_bd / max(1, len(flat_frames)), 3)\n",
    "    }\n",
    "    \n",
    "    # === STEP 4: Write output ===\n",
    "    output = {\n",
    "        'battle_sequences': battle_sequences,\n",
    "        'flat_frames': flat_frames,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "    \n",
    "    with open(BATTLE_TRANSITIONS_PATH, 'w') as f:\n",
    "        json.dump(output, f)\n",
    "    \n",
    "    print(f\"  âœ… taught_battle_transitions.json:\")\n",
    "    print(f\"     Battles: {len(battle_sequences)} | Frames: {len(flat_frames)}\")\n",
    "    print(f\"     Outcomes: {dict(outcomes)}\")\n",
    "    print(f\"     Avg length: {avg_length:.1f} frames\")\n",
    "    print(f\"     Battle data coverage: {frames_with_bd}/{len(flat_frames)} ({metadata['battle_data_coverage']:.0%})\")\n",
    "    if most_common:\n",
    "        print(f\"     Top sequences:\")\n",
    "        for s in most_common[:3]:\n",
    "            print(f\"       {s['sequence']} x{s['count']} ({s['context']})\")\n",
    "\n",
    "\n",
    "def _lookup_battle_data(buffer_by_battle_id, battle_id, frame_index):\n",
    "    \"\"\"\n",
    "    Look up battle data from the brain's buffer for a specific battle frame.\n",
    "    \n",
    "    The buffer stores one entry per teaching-loop timestep while in battle.\n",
    "    The taught_transitions frames are sampled at different rates (dense vs sparse),\n",
    "    so we can't do exact 1:1 matching. Instead we use the frame_index within the\n",
    "    battle to pick the closest buffer entry.\n",
    "    \n",
    "    Returns short-key dict matching AI agent's \"b\" field format:\n",
    "    {bc, mc, ps, es, ph, pm, eh, pc}\n",
    "    \"\"\"\n",
    "    entries = buffer_by_battle_id.get(battle_id, [])\n",
    "    \n",
    "    if not entries:\n",
    "        return {'bc': -1, 'mc': -1, 'ps': -1, 'es': -1, \n",
    "                'ph': -1, 'pm': -1, 'eh': -1, 'pc': -1}\n",
    "    \n",
    "    # Pick the entry closest to this frame_index\n",
    "    # Buffer has many more entries than transition frames (buffer = every loop tick,\n",
    "    # transitions = sampled at dense/sparse intervals), so we scale the index\n",
    "    if frame_index < len(entries):\n",
    "        entry = entries[frame_index]\n",
    "    elif len(entries) > 0:\n",
    "        # Scale: map frame_index into buffer range\n",
    "        scaled = min(frame_index, len(entries) - 1)\n",
    "        entry = entries[scaled]\n",
    "    else:\n",
    "        return {'bc': -1, 'mc': -1, 'ps': -1, 'es': -1,\n",
    "                'ph': -1, 'pm': -1, 'eh': -1, 'pc': -1}\n",
    "    \n",
    "    bd = entry.get('battle_data', {})\n",
    "    \n",
    "    return {\n",
    "        'bc': bd.get('battle_cursor', -1),\n",
    "        'mc': bd.get('move_cursor', -1),\n",
    "        'ps': bd.get('player_species', -1),\n",
    "        'es': bd.get('enemy_species', -1),\n",
    "        'ph': bd.get('player_hp', -1),\n",
    "        'pm': bd.get('player_max_hp', -1),\n",
    "        'eh': bd.get('enemy_hp', -1),\n",
    "        'pc': bd.get('party_cursor', -1),\n",
    "    }\n",
    "\n",
    "\n",
    "def _detect_battle_outcome(battle, all_frames, end_index):\n",
    "    \"\"\"\n",
    "    Detect battle outcome. Now also checks HP data from battle_data if available.\n",
    "    \n",
    "    Priority:\n",
    "    1. HP-based detection (enemy HP=0 â†’ win, player HP=0 â†’ loss)\n",
    "    2. Run pattern detection (action sequence)\n",
    "    3. Pokemon Center teleport detection (loss)\n",
    "    4. Default: win\n",
    "    \"\"\"\n",
    "    # Check HP from last battle frame's battle_data\n",
    "    frames = battle.get('frames', [])\n",
    "    if frames:\n",
    "        last_bd = frames[-1].get('battle_data', {})\n",
    "        eh = last_bd.get('eh', -1)\n",
    "        ph = last_bd.get('ph', -1)\n",
    "        \n",
    "        if eh == 0 and eh != -1:\n",
    "            return 'win'\n",
    "        if ph == 0 and ph != -1:\n",
    "            return 'loss'\n",
    "        # Both alive at end = likely ran\n",
    "        if eh > 0 and ph > 0:\n",
    "            # Confirm with action pattern check below\n",
    "            pass\n",
    "    \n",
    "    # Run detection from action patterns\n",
    "    actions = battle.get('recent_actions_buffer', [])\n",
    "    if len(actions) >= 3:\n",
    "        last_actions = actions[-6:] if len(actions) >= 6 else actions\n",
    "        run_patterns = [\n",
    "            ['DOWN', 'RIGHT', 'A'],\n",
    "            ['DOWN', 'A'],\n",
    "            ['RIGHT', 'DOWN', 'A'],\n",
    "        ]\n",
    "        last_str = last_actions\n",
    "        for pattern in run_patterns:\n",
    "            plen = len(pattern)\n",
    "            for k in range(len(last_str) - plen + 1):\n",
    "                if last_str[k:k+plen] == pattern:\n",
    "                    if k >= len(last_str) - plen - 2:\n",
    "                        return 'run'\n",
    "    \n",
    "    # Loss detection: Pokemon Center teleport\n",
    "    if end_index + 5 < len(all_frames):\n",
    "        for j in range(end_index, min(end_index + 10, len(all_frames))):\n",
    "            post_map = all_frames[j].get('state', {}).get('map_id', -1)\n",
    "            if post_map in POKEMON_CENTER_MAPS:\n",
    "                if post_map != battle.get('map_id', -1):\n",
    "                    return 'loss'\n",
    "    \n",
    "    return 'win'\n",
    "\n",
    "\n",
    "def _guess_sequence_context(seq):\n",
    "    if seq == ['A', 'A', 'A', 'A']:\n",
    "        return 'mashing_A_through_text_or_selecting_fight'\n",
    "    if seq == ['A', 'A']:\n",
    "        return 'selecting_fight_and_move'\n",
    "    if 'DOWN' in seq and 'A' in seq:\n",
    "        return 'navigating_menu_then_selecting'\n",
    "    if seq == ['B', 'B']:\n",
    "        return 'cancelling_or_backing_out'\n",
    "    if all(a == 'A' for a in seq):\n",
    "        return 'mashing_A'\n",
    "    return 'battle_input_sequence'\n",
    "\n",
    "\n",
    "def _write_empty_battle_transitions():\n",
    "    with open(BATTLE_TRANSITIONS_PATH, 'w') as f:\n",
    "        json.dump({\n",
    "            'battle_sequences': [],\n",
    "            'flat_frames': [],\n",
    "            'metadata': {\n",
    "                'total_battle_frames': 0,\n",
    "                'battles_recorded': 0,\n",
    "                'avg_battle_length': 0,\n",
    "                'outcomes': {},\n",
    "                'maps_with_battles': [],\n",
    "                'most_common_sequences': [],\n",
    "                'frames_with_battle_data': 0,\n",
    "                'battle_data_coverage': 0.0\n",
    "            }\n",
    "        }, f, indent=2)\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# MAIN TEACHING LOOP\n",
    "# =========================================================================\n",
    "brain = Brain()\n",
    "\n",
    "for b in [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]:\n",
    "    brain.add(Perceptron(\"action\", action=b, group=\"move\"))\n",
    "for b in [\"A\", \"B\", \"Start\", \"Select\"]:\n",
    "    brain.add(Perceptron(\"action\", action=b, group=\"interact\"))\n",
    "\n",
    "TAUGHT_MODEL_SAVE = BASE_PATH / \"taught_model_checkpoint.json\"\n",
    "TAUGHT_EXPLORATION_SAVE = BASE_PATH / \"taught_exploration_memory.json\"\n",
    "brain.EXPLORATION_MEMORY_FILE = TAUGHT_EXPLORATION_SAVE\n",
    "\n",
    "# Resume if existing\n",
    "if TAUGHT_MODEL_SAVE.exists():\n",
    "    loaded_ts = brain.load_taught_model(TAUGHT_MODEL_SAVE)\n",
    "    print(f\"ðŸŽ“ RESUME: Loaded taught model from timestep {loaded_ts}\")\n",
    "    print(f\"   Utilities: {[f'{a.action}:{a.utility:.3f}' for a in brain.actions()]}\")\n",
    "else:\n",
    "    print(\"ðŸŽ“ FRESH START: No existing taught model\")\n",
    "\n",
    "if TAUGHT_EXPLORATION_SAVE.exists():\n",
    "    brain.load_exploration_memory()\n",
    "    print(f\"   Exploration: {len(brain.exploration_memory)} maps loaded\")\n",
    "\n",
    "prev_context_state = None\n",
    "prev_raw_position = None\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEACHING MODE â€” Human plays, Brain learns\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Model â†’ {TAUGHT_MODEL_SAVE.name}\")\n",
    "print(f\"  Exploration â†’ {TAUGHT_EXPLORATION_SAVE.name}\")\n",
    "print(f\"  Transitions â†’ {TAUGHT_TRANSITIONS_FILE.name} (Lua)\")\n",
    "print(f\"  Nav targets â†’ {NAV_TARGETS_PATH.name} (auto)\")\n",
    "print(f\"  Battle data â†’ {BATTLE_TRANSITIONS_PATH.name} (auto)\")\n",
    "print(\"=\"*70)\n",
    "print(\"BATTLE DATA (NEW):\")\n",
    "print(f\"  Lua writes 'b' field with cursor/species/HP every frame\")\n",
    "print(f\"  Python buffers battle data for post-processing\")\n",
    "print(f\"  Battle extraction embeds bc,mc,ps,es,ph,pm,eh,pc per frame\")\n",
    "print(\"=\"*70)\n",
    "print(\"Play the game. Ctrl+C to stop, save, and post-process.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def run_all_post_processing():\n",
    "    \"\"\"Run all 3 post-processors.\"\"\"\n",
    "    print(\"\\n  ðŸ“Š Running per_map_analysis...\")\n",
    "    try: run_per_map_analysis()\n",
    "    except Exception as e: print(f\"    âš ï¸ per_map_analysis failed: {e}\")\n",
    "    \n",
    "    print(\"  ðŸ“Š Running nav target extraction...\")\n",
    "    try: run_nav_target_extraction()\n",
    "    except Exception as e: print(f\"    âš ï¸ Nav targets failed: {e}\")\n",
    "    \n",
    "    print(\"  ðŸ“Š Running battle extraction...\")\n",
    "    try: run_battle_extraction()\n",
    "    except Exception as e: print(f\"    âš ï¸ Battle extraction failed: {e}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read game state â€” now returns 6 values\n",
    "        context_state, palette_state, tile_state, dead, raw_position, battle_data = read_game_state()\n",
    "        \n",
    "        if np.sum(np.abs(context_state)) < 0.001:\n",
    "            time.sleep(0.02); continue\n",
    "        \n",
    "        raw_x, raw_y = raw_position\n",
    "        in_battle = context_state[3]\n",
    "        current_map = int(context_state[2])\n",
    "        current_dir = int(context_state[5])\n",
    "        \n",
    "        # Update battle data every frame â€” buffers when in battle\n",
    "        brain.update_battle_data(battle_data, in_battle)\n",
    "        \n",
    "        brain.update_position(raw_x, raw_y)\n",
    "        derived = compute_derived_features(context_state, prev_context_state)\n",
    "        learning_state = build_learning_state(derived, palette_state, tile_state, in_battle)\n",
    "        brain.log_state(learning_state, context_state)\n",
    "\n",
    "        time.sleep(0.02)\n",
    "\n",
    "        next_ctx, next_pal, next_til, next_dead, next_raw_pos, next_battle_data = read_game_state()\n",
    "        next_derived = compute_derived_features(next_ctx, context_state)\n",
    "        next_learning_state = build_learning_state(next_derived, next_pal, next_til, next_ctx[3])\n",
    "\n",
    "        brain.learn(learning_state, next_learning_state, context_state, next_ctx,\n",
    "                    dead=dead, raw_position=raw_position, next_raw_position=next_raw_pos)\n",
    "\n",
    "        prev_context_state = context_state.copy()\n",
    "        prev_raw_position = raw_position\n",
    "        brain.timestep += 1\n",
    "\n",
    "        # Logging\n",
    "        if brain.timestep % 100 == 0:\n",
    "            mem = brain.get_current_map_memory(current_map)\n",
    "            vc = len(mem['visited_tiles']); oc = len(mem['obstructions'])\n",
    "            ic = len(mem['interactable_objects']); cov = brain.get_exploration_coverage(current_map)\n",
    "            ts = brain.get_tile_interaction_stats(current_map)\n",
    "            dn = brain.DIRECTION_NAMES.get(current_dir, '?')\n",
    "            tr = mem.get('transitions', [])\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Step {brain.timestep} | Map {current_map} | ({raw_x},{raw_y}) {dn} | Battle:{int(in_battle)}\")\n",
    "            print(f\"  Visited:{vc} Obs:{oc} Coverage:{cov:.0%} Interactables:{ic}\")\n",
    "            print(f\"  Probed:{ts['probed']} Exhausted:{ts['exhausted']} Success:{ts['with_success']}\")\n",
    "            if tr: print(f\"  Transitions: {len(tr)} known\")\n",
    "            \n",
    "            # Battle data status\n",
    "            if in_battle > 0.5:\n",
    "                bd = brain.battle_data\n",
    "                cursor_names = {0: 'FIGHT', 1: 'BAG', 2: 'PKMN', 3: 'RUN'}\n",
    "                bc_str = cursor_names.get(bd.get('battle_cursor', -1), f\"?({bd.get('battle_cursor', -1)})\")\n",
    "                mc_str = f\"Move {bd.get('move_cursor', -1)}\" if bd.get('move_cursor', -1) >= 0 else \"N/A\"\n",
    "                print(f\"  âš”ï¸ BATTLE #{brain.current_battle_id}: Cursor:{bc_str} Move:{mc_str}\")\n",
    "                if bd.get('player_species', -1) > 0:\n",
    "                    hp_str = f\"{bd['player_hp']}/{bd['player_max_hp']}\" if bd.get('player_max_hp', -1) > 0 else f\"{bd.get('player_hp', '?')}\"\n",
    "                    print(f\"     Player: species {bd['player_species']} HP {hp_str}\")\n",
    "                if bd.get('enemy_species', -1) > 0:\n",
    "                    print(f\"     Enemy:  species {bd['enemy_species']} HP {bd.get('enemy_hp', '?')}\")\n",
    "            \n",
    "            print(f\"  Battle buffer: {len(brain.battle_data_buffer)} entries ({brain.current_battle_id} battles)\")\n",
    "            \n",
    "            au = sorted([(a.action, a.utility) for a in brain.actions()], key=lambda x: x[1], reverse=True)\n",
    "            print(f\"  Utilities: {' '.join(f'{k}:{v:.2f}' for k,v in au)}\")\n",
    "\n",
    "        # Periodic save (model + exploration every 500)\n",
    "        if brain.timestep % 500 == 0 and brain.timestep > 0:\n",
    "            brain.save_model_checkpoint(TAUGHT_MODEL_SAVE)\n",
    "            brain.save_exploration_memory()\n",
    "            print(f\"  ðŸ’¾ Auto-saved at step {brain.timestep}\")\n",
    "        \n",
    "        # Periodic post-processing (every 2000 steps)\n",
    "        if brain.timestep % 2000 == 0 and brain.timestep > 0:\n",
    "            print(f\"\\n  ðŸ“Š Periodic post-processing at step {brain.timestep}...\")\n",
    "            run_all_post_processing()\n",
    "            print(f\"  ðŸ“Š Post-processing complete\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nðŸ›‘ Stopping teaching...\")\n",
    "    \n",
    "    print(\"\\nðŸ“ Step 1/2: Saving model + exploration...\")\n",
    "    brain.save_model_checkpoint(TAUGHT_MODEL_SAVE)\n",
    "    brain.save_exploration_memory()\n",
    "    print(f\"   âœ… {TAUGHT_MODEL_SAVE.name}\")\n",
    "    print(f\"   âœ… {TAUGHT_EXPLORATION_SAVE.name}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ Step 2/2: Running all post-processors...\")\n",
    "    run_all_post_processing()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âœ… TEACHING COMPLETE\")\n",
    "    print(f\"   Timestep: {brain.timestep}\")\n",
    "    print(f\"   Maps: {len(brain.exploration_memory)}\")\n",
    "    print(f\"   Tiles: {sum(len(m['visited_tiles']) for m in brain.exploration_memory.values())}\")\n",
    "    print(f\"   Battles buffered: {brain.current_battle_id}\")\n",
    "    print(f\"   Battle data entries: {len(brain.battle_data_buffer)}\")\n",
    "    print(f\"\\nðŸ“¦ Files ready to copy to AI agent:\")\n",
    "    print(f\"   1. {TAUGHT_MODEL_SAVE.name}\")\n",
    "    print(f\"   2. {TAUGHT_TRANSITIONS_FILE.name}\")\n",
    "    print(f\"   3. {TAUGHT_EXPLORATION_SAVE.name}\")\n",
    "    print(f\"   4. {NAV_TARGETS_PATH.name}\")\n",
    "    print(f\"   5. {BATTLE_TRANSITIONS_PATH.name}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
